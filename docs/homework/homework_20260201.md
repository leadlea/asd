# 宿題（統合版）: 特徴量テーブル & 組み合わせてできること（2026-02-01）
> **先生へ：この1ファイルだけ見ていただければOK** です。  
> 「(1) 特徴量リスト（定義・出力粒度・分母）」→「(2) 組み合わせてできること（スコア化／クラスタ／LLM解釈＋根拠）」の順で、**再現可能な根拠**まで含めて整理しました。

---

## 0) gold の意味（raw と S3 の関係）
**gold = raw（原本）を直接触らず、curated（utterances）から “再現可能に生成する” 中間成果物**です。  
研究で扱いやすい最小構成（segments / pairs / metrics_*）に変換して、analysis（summary/rank/examples/labels）へ接続します。

```mermaid
flowchart TD
  %% goldの位置づけ（rawを直接触らず、curatedから再現可能に生成）
  subgraph RAW["raw（格納庫：原本/バックアップ）"]
    raw1["CEJC/CSJ 原本（S3）"]
  end

  subgraph CUR["curated/v1（発話テーブル）"]
    utt["utterances.parquet（発話単位）"]
  end

  subgraph GOLD["gold/v13（再現可能な中間成果物：最小構成）"]
    seg["segments（発話+タグ）\n- sfp_group\n- is_question"]
    pr["pairs（話者交替 prev→resp）\n- resp_is_aizuchi\n- resp_first_token\n- prev_sfp_group など"]
    msfp["metrics_sfp（会話×話者 集計）\n- SFP比率/疑問率/coverage等"]
    mresp["metrics_resp（会話×話者 集計）\n- RESP_NE_AIZUCHI_RATE\n- RESP_NE_ENTROPY/YO_ENTROPY\n- n_pairs_after_NE など"]
    mpg["metrics_pausegap（会話×話者 集計）\n- pause/gap/overlap/speech 等（Phase4）"]
  end

  subgraph ANA["analysis/v1（研究アウトプット）"]
    sum["summary（分母/品質の俯瞰）"]
    rank["rank（外れ/上位下位）"]
    ex["examples（具体例の抽出）"]
    lab["labels（LLM要約/解釈） + provenance（prompt_features_used_json）"]
  end

  raw1 -. "原本は直接加工しない" .-> utt
  utt --> seg
  seg --> pr
  seg --> msfp
  pr  --> mresp
  mpg --> sum
  msfp --> sum
  mresp --> rank
  rank --> ex
  ex --> lab
````

---

## 1) (1) 特徴量リスト（定義・出力粒度・分母まで）

まずは「どのテーブルが、どの粒度で、何を、どの分母で出しているか」を **横スクロール無しで**見える形に整理しました。

### 1.1 生成タイプ（3分類）

* **RAW**：rawデータそのまま（列の再配置や抽出のみ）
* **SIMPLE**：ちょっとだけ加工（単純集計/比率/1語目抽出など）
* **NEW**：まるっきり新規アイデアで計算（entropy / scoring / clustering / LLM provenance）

---

### 1.2 特徴量テーブル（一覧）

| 層        | テーブル                          |      出力粒度 | 生成タイプ  | 何が入るか（最小要約）                                                                                | 分母/安定性（重要）                                                |
| -------- | ----------------------------- | --------: | ------ | ------------------------------------------------------------------------------------------ | --------------------------------------------------------- |
| curated  | curated/v1 **utterances**     |        発話 | RAW    | 必須: `conversation_id/speaker_id/text`（任意: start/end_time, utterance_id, corpus, unit_type） | 入力なので分母なし                                                 |
| gold     | gold/v13 **segments**         |     発話+タグ | SIMPLE | `sfp_group`（NE/YO/NE_Q等） / `is_question` を付与、`utt_index` を付与                               | 分母=発話数（会話×話者の `n_utt`）                                    |
| gold     | gold/v13 **pairs**            |    話者交替ペア | SIMPLE | 話者交替のみ抽出し、`resp_is_aizuchi` / `resp_first_token` / `prev_sfp_group` 等を付与                   | 分母= `n_pairs_total`、条件付きは `n_pairs_after_NE` など           |
| gold     | gold/v13 **metrics_sfp**      |     会話×話者 | SIMPLE | segments 由来の「SFP比率」「疑問率」「coverage」等                                                        | 分母= `n_utt`（発話数）                                          |
| gold     | gold/v13 **metrics_resp**     |     会話×話者 | NEW    | pairs 由来の「NE後相槌率」「応答1語目entropy」「カウント」                                                      | 分母= `n_pairs_after_NE/YO`（analysisで `min_ne_events` で足切り） |
| gold     | gold/v13 **metrics_pausegap** |     会話×話者 | NEW    | TextGrid由来の pause/gap/overlap/speech の統計（Phase4）                                           | 分母= `n_segments` / `n_resp_events` / `total_time` 等       |
| analysis | analysis/v1 **summary**       | dataset集計 | SIMPLE | dataset別の件数、率、分母の俯瞰                                                                        | “空欄”は再集計で埋める運用                                            |
| analysis | analysis/v1 **rank**          |     会話×話者 | NEW    | 指標（例: `RESP_NE_AIZUCHI_RATE`）で上位下位ランキング                                                    | reliable（例: `n_pairs_after_NE>=20`）のみ                     |
| analysis | analysis/v1 **examples**      |        例文 | NEW    | rank上位/下位から具体例抽出（NE直後応答など）                                                                 | reliable前提＋`k-per-speaker`                                |
| analysis | analysis/v1 **labels（LLM）**   |      例×説明 | NEW    | LLM要約/解釈 + **根拠provenance**（`prompt_features_used_json`）                                   | 監査可能（根拠列を保持）                                              |

> 詳細（列名や式）は表の下の `<details>` に畳み込んでいます。先生にはまずこの表だけで全体像が通る構成です。

---

### 1.3 “raw列がどれだけ gold で使われるか”の対応（最小）

curated/v1 utterances（実体確認済み）に存在する列と、gold生成での扱い：

* **必須（gold生成で必ず使う）**

  * `conversation_id`, `speaker_id`, `text`
* **任意（ある場合だけ使う：安定ソート等）**

  * `start_time`, `end_time`（会話内の並び順の安定化）
  * `utterance_id`（tie-breaker用途）
* **任意（メタ情報として保持/参照可能）**

  * `corpus`, `unit_type`（分析での補助、または将来拡張のフック）

---

<details>
<summary><strong>【実体確認】curated utterances の列（CEJC/CSJ）</strong></summary>

今回確認した curated/v1 utterances の列（CEJC/CSJともに cols=8）：

```text
conversation_id
utterance_id
speaker_id
start_time
end_time
text
corpus
unit_type
```

</details>

---

<details>
<summary><strong>【エビデンス】gold生成の計算ロジック（build_pragmatics_gold_from_utterances.py）</strong></summary>

### segments（発話+タグ）
- 出力列: conversation_id, utt_index, speaker_id, start_time, end_time, text, sfp_group, is_question
- 会話内ソート後、utt_index は必ず cumcount() で再採番（入力utt_indexがあっても出力は会話内0..）。
- is_question は「?終端」または末尾が (か/かな/かね/でしょう/でしょ/だろう/だろ/の) のとき True。
- sfp_group は末尾形（ね/よね/よ/の/な/もん系）+ 疑問判定で NE/NE_Q/YO/NO/NA/MON を決定。角タグのみは NONE、(…) 始まりは NONLEX。

### pairs（話者交替 prev→resp）
- 同一会話内の連続発話で speaker_id が変わる箇所だけ抽出（同一話者連続は除外）。
- resp_first_token は resp_text を相槌用正規化して先頭トークンを採用（日本語トークン [ぁ-んァ-ン一-龥ー]+、長音「ー」保持）。
- resp_is_aizuchi は辞書 + ルールで判定。--loose-aizuchi で辞書が拡張される。

### metrics_sfp（会話×話者）
- n_utt = count(segments)
- n_sfp_* = count_if(sfp_group==*)
- rate_sfp_X = n_sfp_X / n_utt
- n_valid = n_utt - n_sfp_OTHER - n_sfp_NONLEX - n_sfp_NONE
- coverage = n_valid / n_utt
- rate_question = mean(is_question)

### metrics_resp（会話×応答側話者）
- n_pairs_total = count(pairs)
- n_pairs_after_NE = count_if(prev_sfp_group in {NE, NE_Q})
- RESP_NE_AIZUCHI_RATE = mean(resp_is_aizuchi | prev_sfp_group in {NE, NE_Q})
- RESP_NE_ENTROPY = -Σ p(token)log2 p(token)  （resp_first_tokenの空は除外）
</details>

---

<details>
<summary><strong>【エビデンス】metrics_pausegap（PG_*）の計算式（build_metrics_pausegap_v0.py）</strong></summary>

### 共通：speech区間→pause
- speech区間は gap_tol=0.05 秒で近接区間をマージしてから pause を計算。
- pause = next.start - cur.end（>0 のみ）
- pause_mean / pause_p50 / pause_p90 は pause リストの平均・中央値・90%点。

### CEJC：応答gap/overlap（話者交替イベント単位）
- 会話内の全speechイベント（start/end, speaker）をstart順に並べ、
  隣接イベントで話者が交替したときの g = next.start - prev.end を「応答側話者」に帰属。
  - g>=0 → resp_gap に追加
  - g<0  → resp_overlaps += 1
  - n_resp_events（応答イベント数）も応答側話者で +1
- resp_gap_mean/p50/p90 は resp_gap の統計。
- resp_overlap_rate = resp_overlaps / n_resp_events
- ※このv0では overlap_rate も同じ値を入れており、「会話全体の厳密なoverlap率」ではなく“応答イベントの重なり率（近似）”。

### CEJC：speech_ratio
- speech_time = Σ(speech区間長)
- total_time は variantごとの最大時間を足し上げ（variantを独立とみなす）
- speech_ratio = speech_time / total_time

### CSJ（v0）
- TRN tierから無音('#','')を除外して speech区間化。
- pauseは同様に算出。
- v0では resp_gap/overlap 系は未算出（NaN/0固定）。
</details>

---

<details>
<summary><strong>【エビデンス】analysis生成（summary / rank / PG_* 付与）のロジック（analyze_gold_to_analysis_v1.py）</strong></summary>

### reliable（信頼性フィルタ）
- reliable は `n_pairs_after_NE >= min_ne_events` を満たす行のみ。
- `min_ne_events` は実行時引数 `--min-ne-events`（デフォルト=10）。運用で20にする場合は引数で20指定。

### rank（NE後相槌率ランキング）
- score列は固定で `RESP_NE_AIZUCHI_RATE`。
- reliable内で降順 top50 / 昇順 bottom50 を作成し、S3へ parquet 出力。

### summary（dataset別の平均値）
- conversation_id / speaker_id / dataset を除いた numeric列について `<col>_mean` を1行に集約。

### Phase4: pausegap の安全マージ + PG_* 列の作成
- metrics_pausegap を metrics_resp に LEFT JOIN。
- speaker_id の `A01F0055:L` と `L` の不一致を吸収するため、両者のキーを `:` 以降のsuffixに正規化してマージ。
- pausegap由来の主要列を、summary用に `PG_*` 列へコピー（例: `total_time -> PG_total_time`）。
</details>

---

<details>
<summary><strong>【エビデンス】FILL（フィラー）特徴量の計算式（build_fill_metrics_for_labels.py）</strong></summary>

### フィラー辞書（登録状況）
- eto=(えっと|えーっと|ええと|えーと)
- e=(えー+|ええ+)
- ano=(あの), sono=(その), maa=(まあ|まぁ), nanka=(なんか), hora=(ほら)
※ eto を除去してから e を数えることで二重カウントを回避。

### 集計粒度
- speaker_key（labelsの speaker_id に合わせる）
- labels側 speaker_id が `conversation_id:speaker_id` 形式である前提で utterances を conversation_id で絞り込み、speaker_id単体/連結キーのどちらが合うかを自動判定して一致行のみ集計。

### 定義（話者単位）
- FILL_text_len = Σ len(text)
- FILL_n_rows   = 発話行数
- FILL_has_any  = フィラーが1回以上出た発話行数（0/1フラグの合計）
- FILL_cnt_*    = 各フィラーの総出現回数
- FILL_cnt_total = Σ(FILL_cnt_e, FILL_cnt_eto, FILL_cnt_ano, FILL_cnt_sono, FILL_cnt_maa, FILL_cnt_nanka, FILL_cnt_hora)
- FILL_rate_per_100chars = FILL_cnt_total / (FILL_text_len/100)
- FILL_z_log_rate_per_100chars = zscore(log(FILL_rate_per_100chars + 1e-12))（対象話者集合内でのμ,σ）
</details>

---

<details>
<summary><strong>【エビデンス】IX_* 指標定義（scripts/phase7/rebuild_metrics_interaction_v1.py）</strong></summary>

## 0) 入力

* Gold:

  * `pairs`（話者交替ペア; prev→resp）
  * `segments`（質問フラグ補助用: `is_question` 等）
* 主キー（集計単位）
  **conversation_id × resp側 speaker_id**

## 1) 前処理

### 1.1 テキスト正規化

* `normalize_ws(x)`：空白正規化
  **式**：`normalize_ws(x) = trim(replace_regex(str(x), r"\s+", " "))`

### 1.2 トークン化 `tokenize_jp(text)`

* fugashi利用できる場合：品詞 `pos1 ∈ {名詞, 動詞, 形容詞, 副詞}` の `surface` を採用
* fugashi無し fallback：空白除去後の文字列 `t` から **文字2-gram**
  **式**：`tokens = [ t[i:i+2] for i = 0..len(t)-2 ]`

### 1.3 Jaccard

* `J(A,B) = |A ∩ B| / |A ∪ B|`（ただし `A=B=∅` のとき `0`）
* **式**：`IX_lex_overlap_i = J(tokens(prev_i), tokens(resp_i))`

## 2) per-pair（pairs 1行ごと）

各ペア行 i について：

* `prev_i = normalize_ws(prev_text_i)`
* `resp_i = normalize_ws(resp_text_i)`

### 2.1 聞き返し/修復マーカー（OIR）

* `IX_is_oirmarker_i ∈ {0,1}`
* `RE_OIR.search(resp_i)` が真なら 1
  （例：`えっ|え？|ん？|何？|もう一回|聞こえ|聞き取れ|どういう(こと)?|つまり|ってこと|今(なんて)?` 等）
* **式**：`IX_is_oirmarker_i = 1{ RE_OIR(resp_i) }`

### 2.2 yes/no 応答

* `IX_is_yesno_i ∈ {0,1}`
* `RE_YESNO.match(resp_i)` が真なら 1
  （先頭一致：`はい/ええ/うん/うーん/ううん/いいえ/いや/そう/そうです/そうだ/そうですね`）
* **式**：`IX_is_yesno_i = 1{ RE_YESNO(resp_i) }`

### 2.3 直前が質問か

* `IX_prev_is_question_i ∈ {0,1}`
* **式（基本）**：`IX_prev_is_question_i = 1{ prev_is_question_i = True }`
* **重要な落とし穴（実装由来）**：
  `pairs` に質問フラグ列が無い場合、`prev_segment_id` が無いと `segments` から補完できず、`IX_prev_is_question=0` になり得る。

### 2.4 話題逸脱 proxy

* **式**：`IX_topic_drift_i = 1 - IX_lex_overlap_i`

## 3) speaker集計（conversation_id × resp側 speaker）

キー：`(c,s)`。対象集合 `P(c,s)` を「resp側 speaker_id = s のペア行集合」とする。

### 3.1 ペア数

* **式**：`IX_n_pairs(c,s) = |P(c,s)|`

### 3.2 率（平均）

一般形：`mean_X(c,s) = (1/|P|) * Σ_{i∈P} X_i`

* `IX_prev_question_rate(c,s) = mean IX_prev_is_question`
* `IX_oirmarker_rate(c,s)     = mean IX_is_oirmarker`
* `IX_yesno_rate(c,s)         = mean IX_is_yesno`
* `IX_lex_overlap_mean(c,s)   = mean IX_lex_overlap`
* `IX_topic_drift_mean(c,s)   = mean IX_topic_drift`

### 3.3 分位点（pandas quantile）

* `IX_lex_overlap_p10(c,s) = Q0.10({IX_lex_overlap_i})`
* `IX_topic_drift_p90(c,s) = Q0.90({IX_topic_drift_i})`

## 4) 条件付き（直前が質問のペアのみ）

`Pq(c,s) = { i∈P(c,s) | IX_prev_is_question_i=1 }`

* `IX_n_pairs_after_question = |Pq|`
* `IX_oirmarker_after_question_rate = mean_{i∈Pq} IX_is_oirmarker`（|Pq|=0なら欠損/None）
* `IX_yesno_after_question_rate     = mean_{i∈Pq} IX_is_yesno`（|Pq|=0なら欠損/None）
* `IX_lex_overlap_after_question_mean= mean_{i∈Pq} IX_lex_overlap`（|Pq|=0なら欠損/None）

</details>

---

<details>
<summary><strong>【エビデンス】IX_* を labels に結合する処理（scripts/phase7/merge_labels_with_interaction_metrics_v1.py）</strong></summary>

## 0) 入力

* `labels_in`（labels parquet）
* `ix_cejc` / `ix_csj`（`rebuild_metrics_interaction_v1.py` の出力）

## 1) corpus_root の決定（labels側）

* labels に `dataset` があれば `dataset` から推定、無ければ `corpus` から推定
* **式**（実装のロジック）：

  * `corpus_root = "cejc"` if `dataset` startswith `"cejc"` or equals `"cejc"`
  * `corpus_root = "csj"`  if `dataset` startswith `"csj"`  or equals `"csj"`
  * それ以外は `""`（空）

## 2) speaker_id 正規化（suffix化）

labels側の speaker_id は形式が混在し得るため、`:` 以降の suffix を join 用に採用。

* **speaker_suffix(x)**
  **式**：`speaker_id_norm = str(x).split(":")[-1]`

例：

* `"T007_007:IC06"` → `"IC06"`
* `"D01M0047:R"` → `"R"`
* `"IC06"` → `"IC06"`

labels側：

* `speaker_id` があればそれを使用（無ければ `speaker_key`）
* `speaker_id_norm = speaker_suffix(labels[speaker_id or speaker_key])`

IX側：

* CEJC/CSJ それぞれ `speaker_id_norm = speaker_suffix(ix.speaker_id)` を作る
* `corpus_root` を固定付与（cejc / csj）

## 3) 結合キー

* **key_cols = (corpus_root, conversation_id, speaker_id_norm)**

## 4) 結合対象列

* IX側の列は `IX_` で始まる列を全て採用：
  `ix_cols = [c for c in ix.columns if c.startswith("IX_")]`

## 5) 結合の種類（left join）

* **式（操作）**：
  `merged = labels LEFT JOIN ix[key_cols + ix_cols] ON key_cols`

→ labels の行は落とさず、該当する IX_* がある場合だけ埋まる。

## 6) join率のログ（品質チェック）

* `IX_n_pairs` が存在する場合：
  **non-null率**：`mean( merged["IX_n_pairs"].notna() )` を表示
  併せて corpus_root ごとの件数も表示

## 7) 注意点（実装上の含意）

* suffix join は `"conversation_id"` とセットなので、`IC01` のような話者IDが他会話と衝突しても **conversation_id が違えば衝突しない**。
* 逆に言うと、`conversation_id` の命名揺れがあると join が落ちる（このとき non-null率が下がる）。

</details>

---

<details>
<summary><strong>【エビデンス】labels HTML/UI が参照するデータ構造と統計（patch_labels_html_safe_plus.py）</strong></summary>

### UIが読む構造（DATA/STATS）
- parquet各行を sanitize() して rows(JSON) に変換し、HTML内の <script id="DATA"> を差し替える。
- FILL_*, PG_*, IX_* 列は、UI互換のため入れ子に復元：
  - r.fill = {FILL_*}, r.pg = {PG_*}, r.ix = {IX_*}

### PCA/クラスタ表示（計算ではなくUI仕様）
- PCAカードを注入し、CL_pca_x/y がある行を散布図表示。
- 点の色分けは CL_fillpg_cluster（凡例も cluster id から生成）。

### 上部summaryカード（STATS）で算出される統計
- pg_summary: PG_pause_mean / PG_resp_gap_mean / PG_overlap_rate / PG_resp_overlap_rate / PG_speech_ratio の平均値。
- fill_summary: FILL_rate_per_100chars の mean/median/p90、FILL_cnt_* の上位タイプ、FILL_has_any の平均など。

※注意：FILL_has_any は「フィラーが出た発話行数（count）」として集計されているため、
UIの any_turn_rate_mean は割合ではなく mean(FILL_has_any) になっている（率が必要なら FILL_has_any / FILL_n_rows を別途定義）。
</details>

---

## 2) metrics_resp の定義（式まで：1行で理解できる）

**metrics_resp は pairs を条件（NE/YO等）で絞って、応答側話者単位に集計**します。

### metrics_resp の式（1行で理解できる説明）

* `n_pairs_total`：その話者が **応答側**になった話者交替ペア数
* `n_pairs_after_NE`：直前発話が **NE/NE_Q** のペア数（条件付き分母）
* `RESP_NE_AIZUCHI_RATE`：NE/NE_Q直後に `resp_is_aizuchi==True` で返した割合

  * `RESP_NE_AIZUCHI_RATE = mean(resp_is_aizuchi | prev_sfp_group ∈ {NE, NE_Q})`
* `RESP_NE_ENTROPY`：NE/NE_Q直後の `resp_first_token` 分布の **Shannon entropy(log2)**

  * 応答が「うん/はい/そう」などに固定化していると低くなりやすい（多様なら高い）
* `RESP_YO_ENTROPY`：YO直後の `resp_first_token` 分布の entropy

### reliability（信頼性足切り）

analysis/rank/examples では原則 **`min_ne_events=20`（= `n_pairs_after_NE >= 20`）** を採用し、観測が薄い話者を除外します。

<details>
<summary><strong>【実体確認】gold/v13 metrics_resp の列（CEJC/CSJ）</strong></summary>

metrics_resp（cols=8、CEJC/CSJで同一）：

```text
conversation_id
speaker_id
n_pairs_total
n_pairs_after_NE
n_pairs_after_YO
RESP_NE_AIZUCHI_RATE
RESP_NE_ENTROPY
RESP_YO_ENTROPY
```

</details>

---

## 3) dataset split（cejc_dyad / csj_dialog 等）はどこで決まるか

* gold（metrics_resp等）自体は `dataset` 列を持ちません（実体確認: `has_dataset=False`）。
* analysis 側で `segments` を使い、会話ごとの **話者数 `n_speakers = nunique(speaker_id)`** から split します：

  * `cejc_dyad`: `n_speakers == 2`
  * `csj_dialog`: `n_speakers >= 2`

---

## 4) (2) 組み合わせてできること（スコア化／クラスタリング／LLM解釈＋根拠）

ここからが先生のリクエスト(2)に対応する部分です。「できる」だけでなく、**すでに手元で確認した根拠（数値）**も添えます。

### 4.1 信頼性フィルタ（reliable）

* 研究運用では **`min_ne_events=20`** を採用

  * `reliable = metrics_resp[n_pairs_after_NE >= 20]`
* 今回の確認: **reliable rows = 526（CEJC+CSJ合算）**

---

### 4.2 スコア化（例：相槌率↑ + 低エントロピー↑）

一例として「NE後は相槌が多い」かつ「応答語彙が固定化している（entropy低）」を強調する合成スコア：

* `score_example = z(RESP_NE_AIZUCHI_RATE) + (-z(RESP_NE_ENTROPY))`

上位例（手元確認の抜粋）：

```text
corpus conversation_id speaker_id  n_pairs_after_NE  RESP_NE_AIZUCHI_RATE  RESP_NE_ENTROPY  score_example
cejc   T006_005        IC01        39               1.000000              1.696182         5.527754
cejc   S002_005        IC02        20               0.850000              1.816642         4.386513
cejc   C001_004        IC01        21               0.857143              2.030087         4.114151
cejc   K009_012        IC03        24               0.833333              1.976287         4.041697
cejc   T006_009        IC01        23               0.826087              1.994841         3.967581
```

→ ここから `examples`（NE直後の具体例）を紐付けると、「なぜ高い/低いか」を例文で説明できます。

---

### 4.3 クラスタリング（タイプ分け）

CEJC reliable（`n_pairs_after_NE>=20`）で、以下の3指標を使ってタイプ分けの例を実施：

* 特徴: `[RESP_NE_AIZUCHI_RATE, RESP_NE_ENTROPY, RESP_YO_ENTROPY]`
* 標準化 → PCA(2次元) → KMeans(4クラスタ)

クラスタ件数（手元確認）：

```text
cluster  count
0        132
1        119
2        180
3         89
```

→ 各クラスタの平均プロファイル + 代表会話（examples）を出せば、**“タイプの言語学的説明”** に落とせます。

---

### 4.4 LLMサマライズ解釈 + provenance（根拠追跡）

LLM（labels）は「説明」だけでなく **根拠の監査（provenance）** が肝です。

* labels parquet（例）：

  * `artifacts/.../labels_tb500_UIFINAL_...__FIXED.parquet`
* `prompt_features_used_json` が **500/500 非空（non-null rate=1.0）**
  → 「LLMが何の特徴を根拠に説明したか」を追跡できます
* `labels_json` / `top_contrib_json` も保持
  → “説明文 + 根拠特徴 + 寄与上位” をセットで提示可能
