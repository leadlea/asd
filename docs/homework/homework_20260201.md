# 宿題（統合版）: 特徴量テーブル & 組み合わせてできること（2026-02-01）
> **先生へ：この1ファイルだけ見ていただければOK** です。  
> 「(1) 特徴量リスト（定義・出力粒度・分母）」→「(2) 組み合わせてできること（スコア化／クラスタ／LLM解釈＋根拠）」の順で、**再現可能な根拠**まで含めて整理しました。  
> **追記（2026-02-02）：** 先生のご指摘に合わせて、**辞書（正規表現/語彙）・計算式・閾値（理由込み）**を、表の該当箇所から辿れる形で **省略無し**で追記しました。

---

## 0) gold の意味（raw と S3 の関係）
**gold = raw（原本）を直接触らず、curated（utterances）から “再現可能に生成する” 中間成果物**です。  
研究で扱いやすい最小構成（segments / pairs / metrics_*）に変換して、analysis（summary/rank/examples/labels）へ接続します。

```mermaid
flowchart TD
  %% goldの位置づけ（rawを直接触らず、curatedから再現可能に生成）
  subgraph RAW["raw（格納庫：原本/バックアップ）"]
    raw1["CEJC/CSJ 原本（S3）"]
  end

  subgraph CUR["curated/v1（発話テーブル）"]
    utt["utterances.parquet（発話単位）"]
  end

  subgraph GOLD["gold/v13（再現可能な中間成果物：最小構成）"]
    seg["segments（発話+タグ）\n- sfp_group\n- is_question"]
    pr["pairs（話者交替 prev→resp）\n- resp_is_aizuchi\n- resp_first_token\n- prev_sfp_group など"]
    msfp["metrics_sfp（会話×話者 集計）\n- SFP比率/疑問率/coverage等"]
    mresp["metrics_resp（会話×話者 集計）\n- RESP_NE_AIZUCHI_RATE\n- RESP_NE_ENTROPY/YO_ENTROPY\n- n_pairs_after_NE など"]
    mpg["metrics_pausegap（会話×話者 集計）\n- pause/gap/overlap/speech 等（Phase4）"]
  end

  subgraph ANA["analysis/v1（研究アウトプット）"]
    sum["summary（分母/品質の俯瞰）"]
    rank["rank（外れ/上位下位）"]
    ex["examples（具体例の抽出）"]
    lab["labels（LLM要約/解釈） + provenance（prompt_features_used_json）"]
  end

  raw1 -. "原本は直接加工しない" .-> utt
  utt --> seg
  seg --> pr
  seg --> msfp
  pr  --> mresp
  mpg --> sum
  msfp --> sum
  mresp --> rank
  rank --> ex
  ex --> lab
````

---

## 1) (1) 特徴量リスト（定義・出力粒度・分母まで）

まずは「どのテーブルが、どの粒度で、何を、どの分母で出しているか」を **横スクロール無しで**見える形に整理しました。

### 1.1 生成タイプ（3分類）

* **RAW**：rawデータそのまま（列の再配置や抽出のみ）
* **SIMPLE**：ちょっとだけ加工（単純集計/比率/1語目抽出など）
* **NEW**：まるっきり新規アイデアで計算（entropy / scoring / clustering / LLM provenance）

---

### 1.2 特徴量テーブル（一覧）

| 層        | テーブル                          |      出力粒度 | 生成タイプ  | 何が入るか（最小要約）                                                                                | 分母/安定性（重要）                                                |
| -------- | ----------------------------- | --------: | ------ | ------------------------------------------------------------------------------------------ | --------------------------------------------------------- |
| curated  | curated/v1 **utterances**     |        発話 | RAW    | 必須: `conversation_id/speaker_id/text`（任意: start/end_time, utterance_id, corpus, unit_type） | 入力なので分母なし                                                 |
| gold     | gold/v13 **segments**         |     発話+タグ | SIMPLE | `sfp_group`（NE/YO/NE_Q等） / `is_question` を付与、`utt_index` を付与                               | 分母=発話数（会話×話者の `n_utt`）                                    |
| gold     | gold/v13 **pairs**            |    話者交替ペア | SIMPLE | 話者交替のみ抽出し、`resp_is_aizuchi` / `resp_first_token` / `prev_sfp_group` 等を付与                   | 分母= `n_pairs_total`、条件付きは `n_pairs_after_NE` など           |
| gold     | gold/v13 **metrics_sfp**      |     会話×話者 | SIMPLE | segments 由来の「SFP比率」「疑問率」「coverage」等                                                        | 分母= `n_utt`（発話数）                                          |
| gold     | gold/v13 **metrics_resp**     |     会話×話者 | NEW    | pairs 由来の「NE後相槌率」「応答1語目entropy」「カウント」                                                      | 分母= `n_pairs_after_NE/YO`（analysisで `min_ne_events` で足切り） |
| gold     | gold/v13 **metrics_pausegap** |     会話×話者 | NEW    | TextGrid由来の pause/gap/overlap/speech の統計（Phase4）                                           | 分母= `n_segments` / `n_resp_events` / `total_time` 等       |
| analysis | analysis/v1 **summary**       | dataset集計 | SIMPLE | dataset別の件数、率、分母の俯瞰                                                                        | “空欄”は再集計で埋める運用                                            |
| analysis | analysis/v1 **rank**          |     会話×話者 | NEW    | 指標（例: `RESP_NE_AIZUCHI_RATE`）で上位下位ランキング                                                    | reliable（例: `n_pairs_after_NE>=20`）のみ                     |
| analysis | analysis/v1 **examples**      |        例文 | NEW    | rank上位/下位から具体例抽出（NE直後応答など）                                                                 | reliable前提＋`k-per-speaker`                                |
| analysis | analysis/v1 **labels（LLM）**   |      例×説明 | NEW    | LLM要約/解釈 + **根拠provenance**（`prompt_features_used_json`）                                   | 監査可能（根拠列を保持）                                              |

> 詳細（列名・辞書・式・閾値・理由）は、この表の直下の `<details>`（1.2.A〜）に **省略無し**で整理しています。先生にはまずこの表だけで全体像が通る構成です。

---

## 1.2.A 辞書・計算式・閾値（理由込み） — 表の完全版

### 1.2.A-0 全体方針（この節の読み方）

* **辞書**：語彙リスト／正規表現（regex）／カテゴリ割当ルール（末尾形など）を **そのまま貼れる形**で列挙
* **計算式**：変数定義→式の順に **1行で追える形**で列挙（entropy 等は定義まで明記）
* **閾値**：値＋理由を明記（統計の安定性、時間アラインのノイズ、可視化の解釈性など）

---

<details>
<summary><strong>1.2.A-1 curated/v1 utterances（辞書・式・閾値）</strong></summary>

### 目的

* gold生成の入力となる「発話テーブル」をそのまま保持（RAW）。

### 辞書

* なし（入力テーブル）。

### 計算式

* なし（入力テーブル）。

### 閾値

* なし。

</details>

---

<details>
<summary><strong>1.2.A-2 gold/v13 segments（辞書・式・閾値）</strong></summary>

## A) 出力列（確定）

```
conversation_id, utt_index, speaker_id, start_time, end_time, text, sfp_group, is_question
```

## B) 会話内ソートと utt_index 再採番（安定性）

### 計算（擬似コード）

1. 会話内でソートキーを作る

* 優先度（存在する列だけ使用）

  1. `start_time`（昇順）
  2. `end_time`（昇順）
  3. `utterance_id`（昇順; tie-breaker）
  4. 元行index（昇順; 最後のtie-breaker）

2. ソート後に再採番

* `utt_index = cumcount()`（会話内で 0..）

### 閾値

* なし（安定ソートは順序の安定化）。

## C) is_question（疑問フラグ）

### 辞書（疑問終端語）

`QUESTION_ENDINGS`（末尾一致。**省略無し**）

```text
か
かな
かね
でしょう
でしょ
だろう
だろ
の
```

### 計算式（Trueになる条件）

以下のいずれかを満たすとき `is_question=True`：

1. `text` が `?` または `？` で終わる
2. `text` の末尾が `QUESTION_ENDINGS` のいずれかに一致する

形式化：

* `is_question(text) = 1{ endswith(text, "?") OR endswith(text, "？") OR endswith_any(text, QUESTION_ENDINGS) }`

### 閾値

* なし（終端一致のルール）。

### 理由

* 句読点 `? / ？` が無い転記（口語）でも、「か/かな…」終端で疑問を拾うため。

## D) sfp_group（終助詞・文末表現カテゴリ）

### 前処理（末尾抽出の前に行う規則）

1. `text` が `None` または空文字 → `sfp_group="NONE"`
2. `text` が **角括弧タグのみ**（例：`<笑>`、`<息>`、`<咳>` 等） → `sfp_group="NONE"`

   * 判定regex（角括弧タグのみの形式。省略無し）

     ```
     ^\s*<[^>]+>\s*$
     ```
3. `text` が **丸括弧から始まる**（例：`(笑)`, `(小声)` 等） → `sfp_group="NONLEX"`

   * 判定regex

     ```
     ^\s*\([^)]*\)
     ```

### 辞書（末尾形 → グループ割当）

#### 末尾形の正規表現（末尾一致; 省略無し）

* `RE_NE`（ね系）

```
(ね|ねえ|ねー|ねぇ)$
```

* `RE_YONE`（よね系）

```
(よね|よねえ|よねー|よねぇ)$
```

* `RE_YO`（よ系）

```
(よ|よぉ|よー)$
```

* `RE_NO`（の系）

```
(の)$
```

* `RE_NA`（な系）

```
(な|なぁ|なー)$
```

* `RE_MON`（もん系）

```
(もん|だもん|ですもん|だもんね|ですもんね)$
```

* `RE_OTHER`（上記に当てはまらないが文末表現がある、とみなす場合に使う“保険”枠）
  ※ここでは**固定の辞書は置かず**、上のいずれにも該当しない場合は `OTHER` 扱いとする。

#### グループ決定ロジック（優先順位・省略無し）

以下の順で判定して `sfp_group` を決める：

1. **NONLEX / NONE** の判定（前処理）
2. `is_question=True` の場合：

   * `RE_NE` または `RE_YONE` に一致 → `NE_Q`
   * それ以外 → `OTHER_Q`（疑問だが NE/YO 以外の疑問終端）
3. `is_question=False` の場合：

   * `RE_YONE` に一致 → `NE`（※「よね」は対人調整として NE 扱いに寄せる運用）
   * `RE_NE` に一致 → `NE`
   * `RE_YO` に一致 → `YO`
   * `RE_NO` に一致 → `NO`
   * `RE_NA` に一致 → `NA`
   * `RE_MON` に一致 → `MON`
   * 上記すべてに不一致 → `OTHER`

### 閾値

* なし（末尾一致ルール）。

### 理由

* 研究上の「調整／同意要求（ね）」と「提示・断定（よ）」の区別をまず粗く切り、疑問は `*_Q` として別扱いにするため。
* `OTHER_Q` を置く理由は、「疑問の拾い漏れ」を避けつつ、NE/YO 以外の疑問終端（例：名詞止め＋？）を分離するため。

</details>

---

<details>
<summary><strong>1.2.A-3 gold/v13 pairs（辞書・式・閾値）</strong></summary>

## A) 対象（話者交替ペアのみ）

### 定義

同一会話内の連続発話 `(u_{t-1}, u_t)` に対し、

* `speaker_id(u_{t-1}) != speaker_id(u_t)` のときのみ抽出する。
* `speaker_id(u_{t-1}) == speaker_id(u_t)` は除外（同一話者連続をペアにしない）。

## B) 出力列（最小）

```
conversation_id
prev_utt_index, resp_utt_index
prev_speaker_id, resp_speaker_id
prev_text, resp_text
prev_sfp_group
resp_is_aizuchi
resp_first_token
```

## C) resp_first_token（応答の1語目）

### 辞書（トークン抽出 regex）

日本語トークンは **連続文字列**として抽出（省略無し）：

```
TOKEN_RE = [ぁ-んァ-ン一-龥ー]+
```

### 前処理（相槌用の正規化）

以下を順に適用して `resp_text_norm` を作る：

1. `normalize_ws`：空白正規化

* `normalize_ws(x) = trim(replace_regex(str(x), r"\s+", " "))`

2. 句読点・記号の前後空白は除去（「先頭トークン抽出」を安定させるため）

* `replace_regex(resp_text_norm, r"\s*([、,。．!！?？])\s*", r"\1")`

3. 先頭に来る可能性が高い括弧注記の削除（省略無し）

* 先頭の `( ... )` を1回だけ落とす：
  `replace_regex(resp_text_norm, r"^\([^)]*\)", "")`

### 計算式（先頭トークン）

* `resp_first_token = first_match(TOKEN_RE, resp_text_norm)`
* マッチが無い場合は `resp_first_token=""`（空）

## D) resp_is_aizuchi（相槌フラグ）

### 辞書（相槌語彙・省略無し）

#### 1) 単独相槌（単語として成立するもの）

```
はい
ええ
うん
うーん
ううん
いいえ
いや
そう
そうだ
そうです
そうですね
そうだね
そうなんだ
なるほど
へえ
へー
ほー
ふーん
あー
おー
えー
まー
うんうん
そうそう
```

#### 2) 文字ゆらぎ（長音/小書き）を許容する相槌

上の語彙を「表記ゆらぎ吸収」するために、以下の置換正規化を **前処理として適用**する：

* 長音の正規化：`ー+` を `ー` に圧縮

  * `replace_regex(text, r"ー+", "ー")`

* 連続同一文字の圧縮（例：`うーーん`）

  * `replace_regex(text, r"(.)\1{2,}", r"\1\1")`
    （3回以上の連続を2回に圧縮）

#### 3) 判定regex（先頭一致; 省略無し）

相槌語彙に一致し、後続が句読点/空白/文末なら相槌とみなす：

```
RE_AIZUCHI = ^(はい|ええ|うん|うーん|ううん|いいえ|いや|そう|そうだ|そうです|そうですね|そうだね|そうなんだ|なるほど|へえ|へー|ほー|ふーん|あー|おー|えー|まー|うんうん|そうそう)([、,。．!！?？\s]|$)
```

### 計算式

* `resp_is_aizuchi = 1{ RE_AIZUCHI.match(resp_text_norm) }`

### 閾値

* なし（辞書＋正規表現の一致）。

### 理由

* `resp_first_token` だけで相槌を判定すると、「はい、でも…」等で安定する一方、「なるほどですね」などが取りこぼされる。
  そこで **先頭一致＋後続境界（句読点/空白/文末）**で「相槌として独立している」ケースを拾う。

### オプション：--loose-aizuchi（拡張辞書）

運用上「相槌寄り」を広く拾う場合の追加語彙（省略無し）：

```
うん、そう
うん、はい
ええ、そう
はい、そう
そう、そう
```

（この追加は、研究目的に応じて **高再現率モード** を使うため。精度を重視する場合はOFF。）

</details>

---

<details>
<summary><strong>1.2.A-4 gold/v13 metrics_sfp（辞書・式・閾値）</strong></summary>

## A) 集計粒度

* `conversation_id × speaker_id`

## B) 必要入力

* segments

## C) 計算式（省略無し）

### 1) カウント

* `n_utt = count(segments)`
* `n_sfp_NE = count_if(sfp_group == "NE")`
* `n_sfp_NE_Q = count_if(sfp_group == "NE_Q")`
* `n_sfp_YO = count_if(sfp_group == "YO")`
* `n_sfp_NO = count_if(sfp_group == "NO")`
* `n_sfp_NA = count_if(sfp_group == "NA")`
* `n_sfp_MON = count_if(sfp_group == "MON")`
* `n_sfp_OTHER = count_if(sfp_group == "OTHER" OR sfp_group == "OTHER_Q")`
* `n_sfp_NONLEX = count_if(sfp_group == "NONLEX")`
* `n_sfp_NONE = count_if(sfp_group == "NONE")`

### 2) 比率

* `rate_sfp_X = n_sfp_X / n_utt`（X は上記グループ）

### 3) coverage（分析に使える割合）

* `n_valid = n_utt - n_sfp_OTHER - n_sfp_NONLEX - n_sfp_NONE`
* `coverage = n_valid / n_utt`

### 4) 疑問率

* `rate_question = mean(is_question)`
  （`is_question` は 0/1 とする）

## D) 閾値

* なし（集計式のみ）。

## E) 理由

* coverage は「終助詞・疑問が付与できた比率」を示す。
  転記仕様やタグ多寡で `sfp_group` が落ちると coverage が下がるため、品質の俯瞰に使う。

</details>

---

<details>
<summary><strong>1.2.A-5 gold/v13 metrics_resp（辞書・式・閾値）</strong></summary>

## A) 集計粒度

* `conversation_id × resp側 speaker_id`（応答側）

## B) 必要入力

* pairs

## C) 事前定義（条件集合）

* `COND_NE = { "NE", "NE_Q" }`
* `COND_YO = { "YO" }`

## D) 計算式（省略無し）

### 1) ペア数

* `n_pairs_total = count(pairs)`（resp側 speakerで集計）
* `n_pairs_after_NE = count_if(prev_sfp_group ∈ COND_NE)`
* `n_pairs_after_YO = count_if(prev_sfp_group ∈ COND_YO)`

### 2) NE直後の相槌率

* `RESP_NE_AIZUCHI_RATE = mean( resp_is_aizuchi | prev_sfp_group ∈ COND_NE )`
  具体化：
  `RESP_NE_AIZUCHI_RATE = (1/n_pairs_after_NE) * Σ 1{resp_is_aizuchi=1 AND prev_sfp_group∈COND_NE}`
  （`n_pairs_after_NE=0` の場合は欠損）

### 3) entropy（Shannon entropy; log2）

#### 3-1) token集合

* 対象は `prev_sfp_group ∈ COND_NE` を満たす行の `resp_first_token`
* ただし `resp_first_token=""` は除外

#### 3-2) 確率分布

* `p(t) = count(token=t) / Σ count(token=*)`

#### 3-3) entropy

* `RESP_NE_ENTROPY = - Σ_{t} p(t) * log2(p(t))`
  （トークン集合が空の場合は欠損）

### 4) YO直後の entropy（同定義）

* 条件を `prev_sfp_group ∈ COND_YO` に置き換えるだけ
* `RESP_YO_ENTROPY = - Σ_{t} p_YO(t) * log2(p_YO(t))`

## E) 閾値

* なし（goldでは計算するだけで足切りしない）。

## F) 理由

* entropy を **1語目**で取る理由：応答の「型（はい/うん/そう…）」固定化を、最小限の仮定で捉えるため。
* 1語目に限定すると、形態素解析無しでも頑健に動く（正規表現で抽出可能）。

</details>

---

<details>
<summary><strong>1.2.A-6 gold/v13 metrics_pausegap（辞書・式・閾値）</strong></summary>

## A) 目的

TextGrid/TRN 由来の speech 区間から、pause/gap/overlap/speech を統計化（Phase4）。

## B) 閾値（最重要）

### gap_tol（近接区間マージの許容ギャップ）

* `gap_tol = 0.05` 秒（50ms）

### 理由（なぜ 0.05 秒か）

* 音声アライン／ラベリングの境界誤差（フレーム単位のブレ）が数十ms出るため、
  **50ms未満の“微小な無音”は同一発話継続の揺れ**としてマージした方が pause が過剰に増えない。
* 0.05 は、話速・区間抽出ノイズを吸収しつつ、実質的な pause（100ms〜）を残す妥協点。

## C) 共通：speech区間→pause

### 1) speechマージ

隣接する speech 区間 `(s_i, e_i)` と `(s_{i+1}, e_{i+1})` について
`(s_{i+1} - e_i) <= gap_tol` のときマージする。

### 2) pause定義

マージ後の連続区間列について
`pause_i = start_{i+1} - end_i`（`pause_i > 0` のみ採用）

### 3) 統計

* `pause_mean = mean(pause_list)`
* `pause_p50 = median(pause_list)`
* `pause_p90 = quantile(pause_list, 0.90)`

## D) CEJC：応答gap/overlap（話者交替イベント単位）

### 定義

会話内の全speechイベント（start/end, speaker）を start 順に並べ、隣接イベントで話者が交替したとき
`g = next.start - prev.end` を計算し、「応答側話者」に帰属する。

* `g >= 0` → `resp_gap` に追加
* `g < 0`  → `resp_overlaps += 1`
* `n_resp_events`（応答イベント数）も応答側話者で +1

### 統計

* `resp_gap_mean = mean(resp_gap_list)`
* `resp_gap_p50 = median(resp_gap_list)`
* `resp_gap_p90 = quantile(resp_gap_list, 0.90)`
* `resp_overlap_rate = resp_overlaps / n_resp_events`

## E) CEJC：speech_ratio

* `speech_time = Σ(speech区間長)`
* `total_time` は variantごとの最大時間を足し上げ（variantを独立とみなす）
* `speech_ratio = speech_time / total_time`

## F) CSJ（v0）

* TRN tierから無音 `'#'` と `''` を除外して speech区間化。
* pauseは同様に算出。
* v0では `resp_gap/overlap` 系は未算出（欠損または0固定の運用）。

</details>

---

<details>
<summary><strong>1.2.A-7 analysis/v1 summary（辞書・式・閾値）</strong></summary>

## A) 目的

dataset別の件数・分母・主要指標の平均値を俯瞰する。

## B) 計算式（省略無し）

* dataset別に、`conversation_id / speaker_id / dataset` を除いた numeric列について
  `col_mean = mean(col)` を1行に集約。

## C) 閾値

* なし。

## D) 理由

* 研究の入口で「分母が足りているか」「値域が破綻していないか」を一目でチェックできるため。

</details>

---

<details>
<summary><strong>1.2.A-8 analysis/v1 rank（辞書・式・閾値）</strong></summary>

## A) 目的

任意の指標（例：`RESP_NE_AIZUCHI_RATE`）で上位下位を抽出し、例文抽出につなげる。

## B) 計算式（省略無し）

* 対象：`metrics_resp`（必要に応じ `metrics_pausegap` をJOINしたもの）
* `score = RESP_NE_AIZUCHI_RATE`（このrankでは固定）
* reliable 内で

  * `top50 = sort_desc(score).head(50)`
  * `bottom50 = sort_asc(score).head(50)`

## C) 閾値（信頼性フィルタ）

* `reliable = 1{ n_pairs_after_NE >= min_ne_events }`

### 既定値

* `min_ne_events = 10`

### 研究運用推奨

* `min_ne_events = 20`

### 理由（なぜ 20 か）

* **比率**（相槌率）の標準誤差は概ね `sqrt(p(1-p)/n)` で n が小さいと不安定。
  n=20 なら p=0.5 でも標準誤差 ≈ 0.111。
  n=10 だと ≈ 0.158 で、ランキングがノイズで上下しやすい。
* **entropy**は「出現分布」の推定なので、nが小さいと過小評価（低entropy）になりやすい。
  20以上を最低ラインとして、観測薄を排除する。

</details>

---

<details>
<summary><strong>1.2.A-9 analysis/v1 examples（辞書・式・閾値）</strong></summary>

## A) 目的

rank上位/下位の話者について、具体的なペア例文を抽出する。

## B) 計算式（省略無し）

* `examples` は `pairs` を参照し、以下の条件で抽出する：

  * `conversation_id` と `speaker_id`（応答側）を固定
  * `prev_sfp_group ∈ {"NE","NE_Q"}`（NE直後例を主対象）
  * `k-per-speaker` 件を抽出（同一話者から取りすぎない）

## C) 閾値

* `k-per-speaker`（既定運用値）

  * `k-per-speaker = 5`

### 理由

* 少数例でも「どういう応答が多いか」を把握できる最小単位が5程度。
* 例が多すぎると人手確認の負荷が上がるため、まずは 5 を基準にする。

</details>

---

<details>
<summary><strong>1.2.A-10 analysis/v1 labels（LLM）— provenance含む（辞書・式・閾値）</strong></summary>

## A) 目的

例文＋特徴量から LLM がサマライズ・解釈を作り、かつ「何を根拠にしたか」を監査できるようにする。

## B) 出力（最低限）

* `labels_text`（サマライズ）
* `labels_json`（構造化）
* `top_contrib_json`（寄与上位）
* `prompt_features_used_json`（根拠の特徴量ID/列名）

## C) 計算式（省略無し）

LLM に入力する特徴量集合 `F` を決め、出力に必ず `prompt_features_used_json=F` を入れる。

* `prompt_features_used_json = json_dump(feature_names_used_in_prompt)`

## D) 閾値

* `prompt_features_used_json` は **欠損不可**（non-null を必須）

### 理由

* 監査可能性（explainability）の最低条件として「LLMが参照した特徴量」を必ず残す。

</details>

---

## 1.3 “raw列がどれだけ gold で使われるか”の対応（最小）

curated/v1 utterances（実体確認済み）に存在する列と、gold生成での扱い：

* **必須（gold生成で必ず使う）**

  * `conversation_id`, `speaker_id`, `text`
* **任意（ある場合だけ使う：安定ソート等）**

  * `start_time`, `end_time`（会話内の並び順の安定化）
  * `utterance_id`（tie-breaker用途）
* **任意（メタ情報として保持/参照可能）**

  * `corpus`, `unit_type`（分析での補助、または将来拡張のフック）

---

<details>
<summary><strong>【実体確認】curated utterances の列（CEJC/CSJ）</strong></summary>

今回確認した curated/v1 utterances の列（CEJC/CSJともに cols=8）：

```text
conversation_id
utterance_id
speaker_id
start_time
end_time
text
corpus
unit_type
```

</details>

---

## 2) metrics_resp の定義（式まで：1行で理解できる）

**metrics_resp は pairs を条件（NE/YO等）で絞って、応答側話者単位に集計**します。

### metrics_resp の式（1行で理解できる説明）

* `n_pairs_total`：その話者が **応答側**になった話者交替ペア数
* `n_pairs_after_NE`：直前発話が **NE/NE_Q** のペア数（条件付き分母）
* `RESP_NE_AIZUCHI_RATE`：NE/NE_Q直後に `resp_is_aizuchi==True` で返した割合

  * `RESP_NE_AIZUCHI_RATE = mean(resp_is_aizuchi | prev_sfp_group ∈ {NE, NE_Q})`
* `RESP_NE_ENTROPY`：NE/NE_Q直後の `resp_first_token` 分布の **Shannon entropy(log2)**

  * 応答が「うん/はい/そう」などに固定化していると低くなりやすい（多様なら高い）
* `RESP_YO_ENTROPY`：YO直後の `resp_first_token` 分布の entropy

### reliability（信頼性足切り）

analysis/rank/examples では原則 **`min_ne_events=20`（= `n_pairs_after_NE >= 20`）** を採用し、観測が薄い話者を除外します。
※ `min_ne_events` の理由は 1.2.A-8 に明記。

<details>
<summary><strong>【実体確認】gold/v13 metrics_resp の列（CEJC/CSJ）</strong></summary>

metrics_resp（cols=8、CEJC/CSJで同一）：

```text
conversation_id
speaker_id
n_pairs_total
n_pairs_after_NE
n_pairs_after_YO
RESP_NE_AIZUCHI_RATE
RESP_NE_ENTROPY
RESP_YO_ENTROPY
```

</details>

---

## 3) dataset split（cejc_dyad / csj_dialog 等）はどこで決まるか

* gold（metrics_resp等）自体は `dataset` 列を持ちません（実体確認: `has_dataset=False`）。
* analysis 側で `segments` を使い、会話ごとの **話者数 `n_speakers = nunique(speaker_id)`** から split します：

  * `cejc_dyad`: `n_speakers == 2`
  * `csj_dialog`: `n_speakers >= 2`

---

## 4) (2) 組み合わせてできること（スコア化／クラスタリング／LLM解釈＋根拠）

ここからが先生のリクエスト(2)に対応する部分です。「できる」だけでなく、**すでに手元で確認した根拠（数値）**も添えます。

### 4.1 信頼性フィルタ（reliable）

* 研究運用では **`min_ne_events=20`** を採用

  * `reliable = metrics_resp[n_pairs_after_NE >= 20]`
* 今回の確認: **reliable rows = 526（CEJC+CSJ合算）**

---

### 4.2 スコア化（例：相槌率↑ + 低エントロピー↑）

一例として「NE後は相槌が多い」かつ「応答語彙が固定化している（entropy低）」を強調する合成スコア：

* `score_example = z(RESP_NE_AIZUCHI_RATE) + (-z(RESP_NE_ENTROPY))`

上位例（手元確認の抜粋）：

```text
corpus conversation_id speaker_id  n_pairs_after_NE  RESP_NE_AIZUCHI_RATE  RESP_NE_ENTROPY  score_example
cejc   T006_005        IC01        39               1.000000              1.696182         5.527754
cejc   S002_005        IC02        20               0.850000              1.816642         4.386513
cejc   C001_004        IC01        21               0.857143              2.030087         4.114151
cejc   K009_012        IC03        24               0.833333              1.976287         4.041697
cejc   T006_009        IC01        23               0.826087              1.994841         3.967581
```

→ ここから `examples`（NE直後応答の具体例）を紐付けると、「なぜ高い/低いか」を例文で説明できます。

---

### 4.3 クラスタリング（タイプ分け）

CEJC reliable（`n_pairs_after_NE>=20`）で、以下の3指標を使ってタイプ分けの例を実施：

* 特徴: `[RESP_NE_AIZUCHI_RATE, RESP_NE_ENTROPY, RESP_YO_ENTROPY]`
* 標準化 → PCA(2次元) → KMeans(4クラスタ)

クラスタ件数（手元確認）：

```text
cluster  count
0        132
1        119
2        180
3         89
```

#### 閾値（ここでの “4クラスタ” の理由）

* `k=4` は「相槌率×固定化×YO応答多様性」を人間が解釈しやすい粒度に抑えるため。
  2〜3だと粗すぎ、5以上だと「説明ラベル（タイプ名）」が付けにくくなることが多い。
  まず 4 を基準にし、必要なら `k` は研究目的に合わせて動かす。

---

### 4.4 LLMサマライズ解釈 + provenance（根拠追跡）

LLM（labels）は「説明」だけでなく **根拠の監査（provenance）** が肝です。

* labels parquet（例）：

  * `artifacts/.../labels_tb500_UIFINAL_...__FIXED.parquet`
* `prompt_features_used_json` が **500/500 非空（non-null rate=1.0）**
  → 「LLMが何の特徴を根拠に説明したか」を追跡できます
* `labels_json` / `top_contrib_json` も保持
  → “説明文 + 根拠特徴 + 寄与上位” をセットで提示可能

---

## 5) 先生に見せる時の「一言まとめ」（読み上げ用）

* **gold は、rawを直接触らず curated（発話テーブル）から再現可能に生成する中間成果物**。
* gold の最小構成（segments/pairs/metrics_*）により、
  **(1) 特徴量の定義（粒度と分母）を明確化**し、
  **(2) スコア化・クラスタ・LLM解釈（根拠provenance付き）**まで一気通貫で回せる。

---

## Appendix A) 追加：FILL（フィラー）特徴量（辞書・式・閾値）

<details>
<summary><strong>Appendix A-1 FILL 辞書（省略無し）</strong></summary>

### フィラー辞書（登録状況）

* eto=(えっと|えーっと|ええと|えーと)
* e=(えー+|ええ+)
* ano=(あの)
* sono=(その)
* maa=(まあ|まぁ)
* nanka=(なんか)
* hora=(ほら)

### 二重カウント回避ルール（省略無し）

1. eto を先に数える
2. eto をテキストから除去した上で e を数える

</details>

<details>
<summary><strong>Appendix A-2 FILL 計算式（省略無し）</strong></summary>

### 集計粒度

* speaker_key（labelsの speaker_id に合わせる）

### 定義（話者単位）

* FILL_text_len = Σ len(text)

* FILL_n_rows   = 発話行数

* FILL_has_any  = フィラーが1回以上出た発話行数（0/1フラグの合計）

* FILL_cnt_eto  = count_regex(eto)

* FILL_cnt_e    = count_regex(e) after removing eto matches

* FILL_cnt_ano  = count_regex(ano)

* FILL_cnt_sono = count_regex(sono)

* FILL_cnt_maa  = count_regex(maa)

* FILL_cnt_nanka= count_regex(nanka)

* FILL_cnt_hora = count_regex(hora)

* FILL_cnt_total = FILL_cnt_e + FILL_cnt_eto + FILL_cnt_ano + FILL_cnt_sono + FILL_cnt_maa + FILL_cnt_nanka + FILL_cnt_hora

* FILL_rate_per_100chars = FILL_cnt_total / (FILL_text_len/100)

### 数値安定化（log + zscore）

* epsilon = 1e-12
* FILL_z_log_rate_per_100chars = zscore( log(FILL_rate_per_100chars + epsilon) )

</details>

<details>
<summary><strong>Appendix A-3 FILL 閾値（省略無し）</strong></summary>

* epsilon = 1e-12
  理由：log(0) を避け、極端に小さい rate でも数値が発散しないようにするため。

</details>

---

## Appendix B) 追加：IX_*（相互行為指標）— 辞書・式・閾値

<details>
<summary><strong>Appendix B-1 IX 辞書（OIR/YESNO/正規化）— 省略無し</strong></summary>

### 正規化（空白）

* normalize_ws(x) = trim(replace_regex(str(x), r"\s+", " "))

### OIR（聞き返し/修復マーカー）辞書（正規表現; 省略無し）

```
RE_OIR = (えっ|え？|ん？|何？|もう一回|聞こえ|聞き取れ|どういう(こと)?|つまり|ってこと|今(なんて)?)
```

### YES/NO 応答辞書（正規表現; 先頭一致; 省略無し）

```
RE_YESNO = ^(はい|ええ|うん|うーん|ううん|いいえ|いや|そう|そうです|そうだ|そうですね)
```

</details>

<details>
<summary><strong>Appendix B-2 IX 計算式（省略無し）</strong></summary>

## 0) 入力

* pairs（prev→resp）
* segments（質問フラグ補助: is_question）

## 1) トークン化 tokenize_jp(text)

### fugashi利用可の場合

* pos1 ∈ {名詞, 動詞, 形容詞, 副詞} の surface を採用

### fugashi無し fallback（省略無し）

* 空白除去後の文字列 t に対し **文字2-gram**
* tokens = [ t[i:i+2] for i = 0..len(t)-2 ]

## 2) Jaccard

* J(A,B) = |A ∩ B| / |A ∪ B|
  ただし A=B=∅ のとき 0

* IX_lex_overlap_i = J(tokens(prev_i), tokens(resp_i))

## 3) per-pair 指標

* IX_is_oirmarker_i = 1{ RE_OIR.search(resp_i) }
* IX_is_yesno_i     = 1{ RE_YESNO.match(resp_i) }
* IX_prev_is_question_i = 1{ prev_is_question_i = True }
* IX_topic_drift_i = 1 - IX_lex_overlap_i

## 4) speaker集計（conversation_id × resp側 speaker）

* IX_n_pairs(c,s) = |P(c,s)|

平均（mean）

* IX_prev_question_rate = mean(IX_prev_is_question)
* IX_oirmarker_rate     = mean(IX_is_oirmarker)
* IX_yesno_rate         = mean(IX_is_yesno)
* IX_lex_overlap_mean   = mean(IX_lex_overlap)
* IX_topic_drift_mean   = mean(IX_topic_drift)

分位点（quantile）

* IX_lex_overlap_p10  = Q0.10({IX_lex_overlap_i})
* IX_topic_drift_p90  = Q0.90({IX_topic_drift_i})

条件付き（直前が質問のペアのみ）

* Pq(c,s) = { i∈P(c,s) | IX_prev_is_question_i=1 }
* IX_n_pairs_after_question = |Pq|
* IX_oirmarker_after_question_rate = mean_{i∈Pq} IX_is_oirmarker（|Pq|=0なら欠損）
* IX_yesno_after_question_rate     = mean_{i∈Pq} IX_is_yesno（|Pq|=0なら欠損）
* IX_lex_overlap_after_question_mean= mean_{i∈Pq} IX_lex_overlap（|Pq|=0なら欠損）

</details>

<details>
<summary><strong>Appendix B-3 IX 閾値（省略無し）</strong></summary>

* 分位点 p10/p90 は固定（0.10 / 0.90）
  理由：会話ごとの分布の「端」を、外れの影響を受けにくい形で捉えるため。
  平均だけだと分布の歪みが見えにくいので、低側/高側の代表として 10%/90% を採用。

</details>

---

## Appendix C) 追加：閾値一覧（この文書に出てくる全て）

| 名称                |      値 | 使う場所              | 目的          | 理由（省略無し）                                            |
| ----------------- | -----: | ----------------- | ----------- | --------------------------------------------------- |
| gap_tol           | 0.05 秒 | metrics_pausegap  | speech区間マージ | 音声アライン/ラベリングの境界誤差（数十ms）を吸収し、微小無音で pause が過剰増加するのを防ぐ |
| min_ne_events（既定） |     10 | analysis reliable | 最低観測数       | 探索段階で行数を確保しつつ、最低限の安定性を持たせる                          |
| min_ne_events（推奨） |     20 | analysis reliable | 観測薄の除外      | 比率推定の標準誤差と entropy の過小評価を抑え、rankがノイズ支配になるのを避ける      |
| k-per-speaker     |      5 | examples          | 例文抽出量       | 人手確認の負荷を上げず、タイプ把握に十分な最小例数として 5 を基準にする               |
| epsilon（FILL）     |  1e-12 | FILL log          | log安定化      | log(0) の回避と、極小値の発散防止                                |
| KMeans k          |      4 | clustering例       | タイプ分け       | 解釈可能性（ラベル付け可能な粒度）を優先し、粗すぎず細かすぎない中庸として 4 を基準にする      |
