# 宿題（統合版）: 特徴量テーブル & 組み合わせてできること（2026-02-01）
> **先生へ：この1ファイルだけ見ていただければOK** です。  
> 「(1) 特徴量リスト（定義・出力粒度・分母）」→「(2) 組み合わせてできること（スコア化／クラスタ／LLM解釈＋根拠）」の順で、**再現可能な根拠**まで含めて整理しました。

---

## 0) gold の意味（raw と S3 の関係）
**gold = raw（原本）を直接触らず、curated（utterances）から “再現可能に生成する” 中間成果物**です。  
研究で扱いやすい最小構成（segments / pairs / metrics_*）に変換して、analysis（summary/rank/examples/labels）へ接続します。

```mermaid
flowchart TD
  %% goldの位置づけ（rawを直接触らず、curatedから再現可能に生成）
  subgraph RAW["raw（格納庫：原本/バックアップ）"]
    raw1["CEJC/CSJ 原本（S3）"]
  end

  subgraph CUR["curated/v1（発話テーブル）"]
    utt["utterances.parquet（発話単位）"]
  end

  subgraph GOLD["gold/v13（再現可能な中間成果物：最小構成）"]
    seg["segments（発話+タグ）\n- sfp_group\n- is_question"]
    pr["pairs（話者交替 prev→resp）\n- resp_is_aizuchi\n- resp_first_token\n- prev_sfp_group など"]
    msfp["metrics_sfp（会話×話者 集計）\n- SFP比率/疑問率/coverage等"]
    mresp["metrics_resp（会話×話者 集計）\n- RESP_NE_AIZUCHI_RATE\n- RESP_NE_ENTROPY/YO_ENTROPY\n- n_pairs_after_NE など"]
    mpg["metrics_pausegap（会話×話者 集計）\n- pause/gap/overlap/speech 等（Phase4）"]
  end

  subgraph ANA["analysis/v1（研究アウトプット）"]
    sum["summary（分母/品質の俯瞰）"]
    rank["rank（外れ/上位下位）"]
    ex["examples（具体例の抽出）"]
    lab["labels（LLM要約/解釈） + provenance（prompt_features_used_json）"]
  end

  raw1 -. "原本は直接加工しない" .-> utt
  utt --> seg
  seg --> pr
  seg --> msfp
  pr  --> mresp
  mpg --> sum
  msfp --> sum
  mresp --> rank
  rank --> ex
  ex --> lab
````

---

## 1) (1) 特徴量リスト（定義・出力粒度・分母まで）

まずは「どのテーブルが、どの粒度で、何を、どの分母で出しているか」を **横スクロール無しで**見える形に整理しました。

### 1.1 生成タイプ（3分類）

* **RAW**：rawデータそのまま（列の再配置や抽出のみ）
* **SIMPLE**：ちょっとだけ加工（単純集計/比率/1語目抽出など）
* **NEW**：まるっきり新規アイデアで計算（entropy / scoring / clustering / LLM provenance）

---

### 1.2 特徴量テーブル（一覧）

| 層        | テーブル                          |      出力粒度 | 生成タイプ  | 何が入るか（最小要約）                                                                                | 分母/安定性（重要）                                                |
| -------- | ----------------------------- | --------: | ------ | ------------------------------------------------------------------------------------------ | --------------------------------------------------------- |
| curated  | curated/v1 **utterances**     |        発話 | RAW    | 必須: `conversation_id/speaker_id/text`（任意: start/end_time, utterance_id, corpus, unit_type） | 入力なので分母なし                                                 |
| gold     | gold/v13 **segments**         |     発話+タグ | SIMPLE | `sfp_group`（NE/YO/NE_Q等） / `is_question` を付与、`utt_index` を付与                               | 分母=発話数（会話×話者の `n_utt`）                                    |
| gold     | gold/v13 **pairs**            |    話者交替ペア | SIMPLE | 話者交替のみ抽出し、`resp_is_aizuchi` / `resp_first_token` / `prev_sfp_group` 等を付与                   | 分母= `n_pairs_total`、条件付きは `n_pairs_after_NE` など           |
| gold     | gold/v13 **metrics_sfp**      |     会話×話者 | SIMPLE | segments 由来の「SFP比率」「疑問率」「coverage」等                                                        | 分母= `n_utt`（発話数）                                          |
| gold     | gold/v13 **metrics_resp**     |     会話×話者 | NEW    | pairs 由来の「NE後相槌率」「応答1語目entropy」「カウント」                                                      | 分母= `n_pairs_after_NE/YO`（analysisで `min_ne_events` で足切り） |
| gold     | gold/v13 **metrics_pausegap** |     会話×話者 | NEW    | TextGrid由来の pause/gap/overlap/speech の統計（Phase4）                                           | 分母= `n_segments` / `n_resp_events` / `total_time` 等       |
| analysis | analysis/v1 **summary**       | dataset集計 | SIMPLE | dataset別の件数、率、分母の俯瞰                                                                        | “空欄”は再集計で埋める運用                                            |
| analysis | analysis/v1 **rank**          |     会話×話者 | NEW    | 指標（例: `RESP_NE_AIZUCHI_RATE`）で上位下位ランキング                                                    | reliable（例: `n_pairs_after_NE>=20`）のみ                     |
| analysis | analysis/v1 **examples**      |        例文 | NEW    | rank上位/下位から具体例抽出（NE直後応答など）                                                                 | reliable前提＋`k-per-speaker`                                |
| analysis | analysis/v1 **labels（LLM）**   |      例×説明 | NEW    | LLM要約/解釈 + **根拠provenance**（`prompt_features_used_json`）                                   | 監査可能（根拠列を保持）                                              |

> 詳細（列名や式）は表の下の `<details>` に畳み込んでいます。先生にはまずこの表だけで全体像が通る構成です。

---

### 1.3 “raw列がどれだけ gold で使われるか”の対応（最小）

curated/v1 utterances（実体確認済み）に存在する列と、gold生成での扱い：

* **必須（gold生成で必ず使う）**

  * `conversation_id`, `speaker_id`, `text`
* **任意（ある場合だけ使う：安定ソート等）**

  * `start_time`, `end_time`（会話内の並び順の安定化）
  * `utterance_id`（tie-breaker用途）
* **任意（メタ情報として保持/参照可能）**

  * `corpus`, `unit_type`（分析での補助、または将来拡張のフック）

---

<details>
<summary><strong>【実体確認】curated utterances の列（CEJC/CSJ）</strong></summary>

今回確認した curated/v1 utterances の列（CEJC/CSJともに cols=8）：

```text
conversation_id
utterance_id
speaker_id
start_time
end_time
text
corpus
unit_type
```

</details>

---

<details>
<summary><strong>【エビデンス】gold生成の計算ロジック（build_pragmatics_gold_from_utterances.py）</strong></summary>

### segments（発話+タグ）
- 出力列: conversation_id, utt_index, speaker_id, start_time, end_time, text, sfp_group, is_question
- 会話内ソート後、utt_index は必ず cumcount() で再採番（入力utt_indexがあっても出力は会話内0..）。
- is_question は「?終端」または末尾が (か/かな/かね/でしょう/でしょ/だろう/だろ/の) のとき True。
- sfp_group は末尾形（ね/よね/よ/の/な/もん系）+ 疑問判定で NE/NE_Q/YO/NO/NA/MON を決定。角タグのみは NONE、(…) 始まりは NONLEX。

### pairs（話者交替 prev→resp）
- 同一会話内の連続発話で speaker_id が変わる箇所だけ抽出（同一話者連続は除外）。
- resp_first_token は resp_text を相槌用正規化して先頭トークンを採用（日本語トークン [ぁ-んァ-ン一-龥ー]+、長音「ー」保持）。
- resp_is_aizuchi は辞書 + ルールで判定。--loose-aizuchi で辞書が拡張される。

### metrics_sfp（会話×話者）
- n_utt = count(segments)
- n_sfp_* = count_if(sfp_group==*)
- rate_sfp_X = n_sfp_X / n_utt
- n_valid = n_utt - n_sfp_OTHER - n_sfp_NONLEX - n_sfp_NONE
- coverage = n_valid / n_utt
- rate_question = mean(is_question)

### metrics_resp（会話×応答側話者）
- n_pairs_total = count(pairs)
- n_pairs_after_NE = count_if(prev_sfp_group in {NE, NE_Q})
- RESP_NE_AIZUCHI_RATE = mean(resp_is_aizuchi | prev_sfp_group in {NE, NE_Q})
- RESP_NE_ENTROPY = -Σ p(token)log2 p(token)  （resp_first_tokenの空は除外）
</details>

---

<details>
<summary><strong>【エビデンス】analysis生成（summary / rank / PG_* 付与）のロジック（analyze_gold_to_analysis_v1.py）</strong></summary>

### reliable（信頼性フィルタ）
- reliable は `n_pairs_after_NE >= min_ne_events` を満たす行のみ。
- `min_ne_events` は実行時引数 `--min-ne-events`（デフォルト=10）。運用で20にする場合は引数で20指定。

### rank（NE後相槌率ランキング）
- score列は固定で `RESP_NE_AIZUCHI_RATE`。
- reliable内で降順 top50 / 昇順 bottom50 を作成し、S3へ parquet 出力。

### summary（dataset別の平均値）
- conversation_id / speaker_id / dataset を除いた numeric列について `<col>_mean` を1行に集約。

### Phase4: pausegap の安全マージ + PG_* 列の作成
- metrics_pausegap を metrics_resp に LEFT JOIN。
- speaker_id の `A01F0055:L` と `L` の不一致を吸収するため、両者のキーを `:` 以降のsuffixに正規化してマージ。
- pausegap由来の主要列を、summary用に `PG_*` 列へコピー（例: `total_time -> PG_total_time`）。
</details>

---

<details>
<summary><strong>【エビデンス】FILL（フィラー）特徴量の計算式（build_fill_metrics_for_labels.py）</strong></summary>

### フィラー辞書（登録状況）
- eto=(えっと|えーっと|ええと|えーと)
- e=(えー+|ええ+)
- ano=(あの), sono=(その), maa=(まあ|まぁ), nanka=(なんか), hora=(ほら)
※ eto を除去してから e を数えることで二重カウントを回避。

### 集計粒度
- speaker_key（labelsの speaker_id に合わせる）
- labels側 speaker_id が `conversation_id:speaker_id` 形式である前提で utterances を conversation_id で絞り込み、speaker_id単体/連結キーのどちらが合うかを自動判定して一致行のみ集計。

### 定義（話者単位）
- FILL_text_len = Σ len(text)
- FILL_n_rows   = 発話行数
- FILL_has_any  = フィラーが1回以上出た発話行数（0/1フラグの合計）
- FILL_cnt_*    = 各フィラーの総出現回数
- FILL_cnt_total = Σ(FILL_cnt_e, FILL_cnt_eto, FILL_cnt_ano, FILL_cnt_sono, FILL_cnt_maa, FILL_cnt_nanka, FILL_cnt_hora)
- FILL_rate_per_100chars = FILL_cnt_total / (FILL_text_len/100)
- FILL_z_log_rate_per_100chars = zscore(log(FILL_rate_per_100chars + 1e-12))（対象話者集合内でのμ,σ）
</details>

---

<details>
<summary><strong>【エビデンス】labels HTML/UI が参照するデータ構造と統計（patch_labels_html_safe_plus.py）</strong></summary>

### UIが読む構造（DATA/STATS）
- parquet各行を sanitize() して rows(JSON) に変換し、HTML内の <script id="DATA"> を差し替える。
- FILL_*, PG_*, IX_* 列は、UI互換のため入れ子に復元：
  - r.fill = {FILL_*}, r.pg = {PG_*}, r.ix = {IX_*}

### PCA/クラスタ表示（計算ではなくUI仕様）
- PCAカードを注入し、CL_pca_x/y がある行を散布図表示。
- 点の色分けは CL_fillpg_cluster（凡例も cluster id から生成）。

### 上部summaryカード（STATS）で算出される統計
- pg_summary: PG_pause_mean / PG_resp_gap_mean / PG_overlap_rate / PG_resp_overlap_rate / PG_speech_ratio の平均値。
- fill_summary: FILL_rate_per_100chars の mean/median/p90、FILL_cnt_* の上位タイプ、FILL_has_any の平均など。

※注意：FILL_has_any は「フィラーが出た発話行数（count）」として集計されているため、
UIの any_turn_rate_mean は割合ではなく mean(FILL_has_any) になっている（率が必要なら FILL_has_any / FILL_n_rows を別途定義）。
</details>

---

## 2) metrics_resp の定義（式まで：1行で理解できる）

**metrics_resp は pairs を条件（NE/YO等）で絞って、応答側話者単位に集計**します。

### metrics_resp の式（1行で理解できる説明）

* `n_pairs_total`：その話者が **応答側**になった話者交替ペア数
* `n_pairs_after_NE`：直前発話が **NE/NE_Q** のペア数（条件付き分母）
* `RESP_NE_AIZUCHI_RATE`：NE/NE_Q直後に `resp_is_aizuchi==True` で返した割合

  * `RESP_NE_AIZUCHI_RATE = mean(resp_is_aizuchi | prev_sfp_group ∈ {NE, NE_Q})`
* `RESP_NE_ENTROPY`：NE/NE_Q直後の `resp_first_token` 分布の **Shannon entropy(log2)**

  * 応答が「うん/はい/そう」などに固定化していると低くなりやすい（多様なら高い）
* `RESP_YO_ENTROPY`：YO直後の `resp_first_token` 分布の entropy

### reliability（信頼性足切り）

analysis/rank/examples では原則 **`min_ne_events=20`（= `n_pairs_after_NE >= 20`）** を採用し、観測が薄い話者を除外します。

<details>
<summary><strong>【実体確認】gold/v13 metrics_resp の列（CEJC/CSJ）</strong></summary>

metrics_resp（cols=8、CEJC/CSJで同一）：

```text
conversation_id
speaker_id
n_pairs_total
n_pairs_after_NE
n_pairs_after_YO
RESP_NE_AIZUCHI_RATE
RESP_NE_ENTROPY
RESP_YO_ENTROPY
```

</details>

---

## 3) dataset split（cejc_dyad / csj_dialog 等）はどこで決まるか

* gold（metrics_resp等）自体は `dataset` 列を持ちません（実体確認: `has_dataset=False`）。
* analysis 側で `segments` を使い、会話ごとの **話者数 `n_speakers = nunique(speaker_id)`** から split します：

  * `cejc_dyad`: `n_speakers == 2`
  * `csj_dialog`: `n_speakers >= 2`

---

## 4) (2) 組み合わせてできること（スコア化／クラスタリング／LLM解釈＋根拠）

ここからが先生のリクエスト(2)に対応する部分です。「できる」だけでなく、**すでに手元で確認した根拠（数値）**も添えます。

### 4.1 信頼性フィルタ（reliable）

* 研究運用では **`min_ne_events=20`** を採用

  * `reliable = metrics_resp[n_pairs_after_NE >= 20]`
* 今回の確認: **reliable rows = 526（CEJC+CSJ合算）**

---

### 4.2 スコア化（例：相槌率↑ + 低エントロピー↑）

一例として「NE後は相槌が多い」かつ「応答語彙が固定化している（entropy低）」を強調する合成スコア：

* `score_example = z(RESP_NE_AIZUCHI_RATE) + (-z(RESP_NE_ENTROPY))`

上位例（手元確認の抜粋）：

```text
corpus conversation_id speaker_id  n_pairs_after_NE  RESP_NE_AIZUCHI_RATE  RESP_NE_ENTROPY  score_example
cejc   T006_005        IC01        39               1.000000              1.696182         5.527754
cejc   S002_005        IC02        20               0.850000              1.816642         4.386513
cejc   C001_004        IC01        21               0.857143              2.030087         4.114151
cejc   K009_012        IC03        24               0.833333              1.976287         4.041697
cejc   T006_009        IC01        23               0.826087              1.994841         3.967581
```

→ ここから `examples`（NE直後の具体例）を紐付けると、「なぜ高い/低いか」を例文で説明できます。

---

### 4.3 クラスタリング（タイプ分け）

CEJC reliable（`n_pairs_after_NE>=20`）で、以下の3指標を使ってタイプ分けの例を実施：

* 特徴: `[RESP_NE_AIZUCHI_RATE, RESP_NE_ENTROPY, RESP_YO_ENTROPY]`
* 標準化 → PCA(2次元) → KMeans(4クラスタ)

クラスタ件数（手元確認）：

```text
cluster  count
0        132
1        119
2        180
3         89
```

→ 各クラスタの平均プロファイル + 代表会話（examples）を出せば、**“タイプの言語学的説明”** に落とせます。

---

### 4.4 LLMサマライズ解釈 + provenance（根拠追跡）

LLM（labels）は「説明」だけでなく **根拠の監査（provenance）** が肝です。

* labels parquet（例）：

  * `artifacts/.../labels_tb500_UIFINAL_...__FIXED.parquet`
* `prompt_features_used_json` が **500/500 非空（non-null rate=1.0）**
  → 「LLMが何の特徴を根拠に説明したか」を追跡できます
* `labels_json` / `top_contrib_json` も保持
  → “説明文 + 根拠特徴 + 寄与上位” をセットで提示可能

---

## 5) 先生に見せる時の「一言まとめ」（読み上げ用）

* **gold は、rawを直接触らず curated（発話テーブル）から再現可能に生成する中間成果物**。
* gold の最小構成（segments/pairs/metrics_*）により、
  **(1) 特徴量の定義（粒度と分母）を明確化**し、
  **(2) スコア化・クラスタ・LLM解釈（根拠provenance付き）**まで一気通貫で回せる。

---

