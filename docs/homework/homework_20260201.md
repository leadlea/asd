# 宿題（統合版）: 特徴量テーブル & 組み合わせてできること（2026-02-01）
> **先生へ：この1ファイルだけ見ていただければOK** です。  
> 「(1) 特徴量リスト（定義・出力粒度・分母）」→「(2) 組み合わせてできること（スコア化／クラスタ／LLM解釈＋根拠）」の順で、**再現可能な根拠**まで含めて整理しました。

---

## 0) gold の意味（raw と S3 の関係）
**gold = raw（原本）を直接触らず、curated（utterances）から “再現可能に生成する” 中間成果物**です。  
研究で扱いやすい最小構成（segments / pairs / metrics_*）に変換して、analysis（summary/rank/examples/labels）へ接続します。

```mermaid
flowchart TD
  %% goldの位置づけ（rawを直接触らず、curatedから再現可能に生成）
  subgraph RAW["raw（格納庫：原本/バックアップ）"]
    raw1["CEJC/CSJ 原本（S3）"]
  end

  subgraph CUR["curated/v1（発話テーブル）"]
    utt["utterances.parquet（発話単位）"]
  end

  subgraph GOLD["gold/v13（再現可能な中間成果物：最小構成）"]
    seg["segments（発話+タグ）\n- sfp_group\n- is_question"]
    pr["pairs（話者交替 prev→resp）\n- resp_is_aizuchi\n- resp_first_token\n- prev_sfp_group など"]
    msfp["metrics_sfp（会話×話者 集計）\n- SFP比率/疑問率/coverage等"]
    mresp["metrics_resp（会話×話者 集計）\n- RESP_NE_AIZUCHI_RATE\n- RESP_NE_ENTROPY/YO_ENTROPY\n- n_pairs_after_NE など"]
    mpg["metrics_pausegap（会話×話者 集計）\n- pause/gap/overlap/speech 等（Phase4）"]
  end

  subgraph ANA["analysis/v1（研究アウトプット）"]
    sum["summary（分母/品質の俯瞰）"]
    rank["rank（外れ/上位下位）"]
    ex["examples（具体例の抽出）"]
    lab["labels（LLM要約/解釈） + provenance（prompt_features_used_json）"]
  end

  raw1 -. "原本は直接加工しない" .-> utt
  utt --> seg
  seg --> pr
  seg --> msfp
  pr  --> mresp
  mpg --> sum
  msfp --> sum
  mresp --> rank
  rank --> ex
  ex --> lab
````

---

## 1) (1) 特徴量リスト（定義・出力粒度・分母まで）

まずは「どのテーブルが、どの粒度で、何を、どの分母で出しているか」を **横スクロール無しで**見える形に整理しました。

### 1.1 生成タイプ（3分類）

* **RAW**：rawデータそのまま（列の再配置や抽出のみ）
* **SIMPLE**：ちょっとだけ加工（単純集計/比率/1語目抽出など）
* **NEW**：まるっきり新規アイデアで計算（entropy / scoring / clustering / LLM provenance）

---

### 1.2 特徴量テーブル（一覧）

| 層        | テーブル                          |      出力粒度 | 生成タイプ  | 何が入るか（最小要約）                                                                                | 分母/安定性（重要）                                                |
| -------- | ----------------------------- | --------: | ------ | ------------------------------------------------------------------------------------------ | --------------------------------------------------------- |
| curated  | curated/v1 **utterances**     |        発話 | RAW    | 必須: `conversation_id/speaker_id/text`（任意: start/end_time, utterance_id, corpus, unit_type） | 入力なので分母なし                                                 |
| gold     | gold/v13 **segments**         |     発話+タグ | SIMPLE | `sfp_group`（NE/YO/NE_Q等） / `is_question` を付与、`utt_index` を付与                               | 分母=発話数（会話×話者の `n_utt`）                                    |
| gold     | gold/v13 **pairs**            |    話者交替ペア | SIMPLE | 話者交替のみ抽出し、`resp_is_aizuchi` / `resp_first_token` / `prev_sfp_group` 等を付与                   | 分母= `n_pairs_total`、条件付きは `n_pairs_after_NE` など           |
| gold     | gold/v13 **metrics_sfp**      |     会話×話者 | SIMPLE | segments 由来の「SFP比率」「疑問率」「coverage」等                                                        | 分母= `n_utt`（発話数）                                          |
| gold     | gold/v13 **metrics_resp**     |     会話×話者 | NEW    | pairs 由来の「NE後相槌率」「応答1語目entropy」「カウント」                                                      | 分母= `n_pairs_after_NE/YO`（analysisで `min_ne_events` で足切り） |
| gold     | gold/v13 **metrics_pausegap** |     会話×話者 | NEW    | TextGrid由来の pause/gap/overlap/speech の統計（Phase4）                                           | 分母= `n_segments` / `n_resp_events` / `total_time` 等       |
| analysis | analysis/v1 **summary**       | dataset集計 | SIMPLE | dataset別の件数、率、分母の俯瞰                                                                        | “空欄”は再集計で埋める運用                                            |
| analysis | analysis/v1 **rank**          |     会話×話者 | NEW    | 指標（例: `RESP_NE_AIZUCHI_RATE`）で上位下位ランキング                                                    | reliable（例: `n_pairs_after_NE>=20`）のみ                     |
| analysis | analysis/v1 **examples**      |        例文 | NEW    | rank上位/下位から具体例抽出（NE直後応答など）                                                                 | reliable前提＋`k-per-speaker`                                |
| analysis | analysis/v1 **labels（LLM）**   |      例×説明 | NEW    | LLM要約/解釈 + **根拠provenance**（`prompt_features_used_json`）                                   | 監査可能（根拠列を保持）                                              |

> 詳細（列名や式）は表の下の `<details>` に畳み込んでいます。先生にはまずこの表だけで全体像が通る構成です。

---

### 1.3 “raw列がどれだけ gold で使われるか”の対応（最小）

curated/v1 utterances（実体確認済み）に存在する列と、gold生成での扱い：

* **必須（gold生成で必ず使う）**

  * `conversation_id`, `speaker_id`, `text`
* **任意（ある場合だけ使う：安定ソート等）**

  * `start_time`, `end_time`（会話内の並び順の安定化）
  * `utterance_id`（tie-breaker用途）
* **任意（メタ情報として保持/参照可能）**

  * `corpus`, `unit_type`（分析での補助、または将来拡張のフック）

---

<details>
<summary><strong>【実体確認】curated utterances の列（CEJC/CSJ）</strong></summary>

今回確認した curated/v1 utterances の列（CEJC/CSJともに cols=8）：

```text
conversation_id
utterance_id
speaker_id
start_time
end_time
text
corpus
unit_type
```

</details>

---

## 2) metrics_resp の定義（式まで：1行で理解できる）

**metrics_resp は pairs を条件（NE/YO等）で絞って、応答側話者単位に集計**します。

### metrics_resp の式（1行で理解できる説明）

* `n_pairs_total`：その話者が **応答側**になった話者交替ペア数
* `n_pairs_after_NE`：直前発話が **NE/NE_Q** のペア数（条件付き分母）
* `RESP_NE_AIZUCHI_RATE`：NE/NE_Q直後に `resp_is_aizuchi==True` で返した割合

  * `RESP_NE_AIZUCHI_RATE = mean(resp_is_aizuchi | prev_sfp_group ∈ {NE, NE_Q})`
* `RESP_NE_ENTROPY`：NE/NE_Q直後の `resp_first_token` 分布の **Shannon entropy(log2)**

  * 応答が「うん/はい/そう」などに固定化していると低くなりやすい（多様なら高い）
* `RESP_YO_ENTROPY`：YO直後の `resp_first_token` 分布の entropy

### reliability（信頼性足切り）

analysis/rank/examples では原則 **`min_ne_events=20`（= `n_pairs_after_NE >= 20`）** を採用し、観測が薄い話者を除外します。

<details>
<summary><strong>【実体確認】gold/v13 metrics_resp の列（CEJC/CSJ）</strong></summary>

metrics_resp（cols=8、CEJC/CSJで同一）：

```text
conversation_id
speaker_id
n_pairs_total
n_pairs_after_NE
n_pairs_after_YO
RESP_NE_AIZUCHI_RATE
RESP_NE_ENTROPY
RESP_YO_ENTROPY
```

</details>

---

## 3) dataset split（cejc_dyad / csj_dialog 等）はどこで決まるか

* gold（metrics_resp等）自体は `dataset` 列を持ちません（実体確認: `has_dataset=False`）。
* analysis 側で `segments` を使い、会話ごとの **話者数 `n_speakers = nunique(speaker_id)`** から split します：

  * `cejc_dyad`: `n_speakers == 2`
  * `csj_dialog`: `n_speakers >= 2`

---

## 4) (2) 組み合わせてできること（スコア化／クラスタリング／LLM解釈＋根拠）

ここからが先生のリクエスト(2)に対応する部分です。「できる」だけでなく、**すでに手元で確認した根拠（数値）**も添えます。

### 4.1 信頼性フィルタ（reliable）

* 研究運用では **`min_ne_events=20`** を採用

  * `reliable = metrics_resp[n_pairs_after_NE >= 20]`
* 今回の確認: **reliable rows = 526（CEJC+CSJ合算）**

---

### 4.2 スコア化（例：相槌率↑ + 低エントロピー↑）

一例として「NE後は相槌が多い」かつ「応答語彙が固定化している（entropy低）」を強調する合成スコア：

* `score_example = z(RESP_NE_AIZUCHI_RATE) + (-z(RESP_NE_ENTROPY))`

上位例（手元確認の抜粋）：

```text
corpus conversation_id speaker_id  n_pairs_after_NE  RESP_NE_AIZUCHI_RATE  RESP_NE_ENTROPY  score_example
cejc   T006_005        IC01        39               1.000000              1.696182         5.527754
cejc   S002_005        IC02        20               0.850000              1.816642         4.386513
cejc   C001_004        IC01        21               0.857143              2.030087         4.114151
cejc   K009_012        IC03        24               0.833333              1.976287         4.041697
cejc   T006_009        IC01        23               0.826087              1.994841         3.967581
```

→ ここから `examples`（NE直後の具体例）を紐付けると、「なぜ高い/低いか」を例文で説明できます。

---

### 4.3 クラスタリング（タイプ分け）

CEJC reliable（`n_pairs_after_NE>=20`）で、以下の3指標を使ってタイプ分けの例を実施：

* 特徴: `[RESP_NE_AIZUCHI_RATE, RESP_NE_ENTROPY, RESP_YO_ENTROPY]`
* 標準化 → PCA(2次元) → KMeans(4クラスタ)

クラスタ件数（手元確認）：

```text
cluster  count
0        132
1        119
2        180
3         89
```

→ 各クラスタの平均プロファイル + 代表会話（examples）を出せば、**“タイプの言語学的説明”** に落とせます。

---

### 4.4 LLMサマライズ解釈 + provenance（根拠追跡）

LLM（labels）は「説明」だけでなく **根拠の監査（provenance）** が肝です。

* labels parquet（例）：

  * `artifacts/.../labels_tb500_UIFINAL_...__FIXED.parquet`
* `prompt_features_used_json` が **500/500 非空（non-null rate=1.0）**
  → 「LLMが何の特徴を根拠に説明したか」を追跡できます
* `labels_json` / `top_contrib_json` も保持
  → “説明文 + 根拠特徴 + 寄与上位” をセットで提示可能

---

## 5) 先生に見せる時の「一言まとめ」（読み上げ用）

* **gold は、rawを直接触らず curated（発話テーブル）から再現可能に生成する中間成果物**。
* gold の最小構成（segments/pairs/metrics_*）により、
  **(1) 特徴量の定義（粒度と分母）を明確化**し、
  **(2) スコア化・クラスタ・LLM解釈（根拠provenance付き）**まで一気通貫で回せる。

---

