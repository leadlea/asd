# 人間向け辞書（名称表）：ASD会話特徴量（日本語版）
> **目的**：コード上の列名（segments/pairs/metrics_resp/PG/FILL/IX）を、  
> **「専門家以外が読める日本語」**に置き換え、研究議論（先生）で共有しやすくする。  
> **方針**：各特徴量を「5点セット」で説明する。  
>
> - (1) わかりやすい日本語名（人間向け）  
> - (2) 何を測っているか（直感）  
> - (3) どうやって見つけた／発想したか（着想の出どころ）  
> - (4) 既存（先行研究で一般的）か／オリジナル（福原の設計）か  
> - (5) 算出の要点（粒度・分母・入力・簡易式）

---

## 0) まず大枠：この研究で「何をやっているか」

![ASD会話特徴量の研究パイプライン（概要）](pipeline_v1.png)

- **ビッグ5のような粗い性格分類を当てる研究ではなく**、会話の中の「相互行為の仕組み（相槌・修復・間・応答の型）」を **再現可能な測定**として定量化する。
- その上で、ASDの仮説（会話の特徴がある）に対して、**具体的にどの相互行為の要素がどう違うのか**を議論できるようにする。
- 特徴量は **会話×話者** または **話者交替ペア（prev→resp）** の粒度で設計する。


### 0-1) 研究テーマ（再確認）
- **当事者視点**：私自身がASD当事者であり、当事者として「会話のどこが難しい／特徴になりやすいか」を仮説化できる。
- **中心仮説**：**ASDの会話には特徴がある**（ただし「性格」ではなく、会話の中の**相互行為**として現れる）。
- **方法**：会話テキスト（＋可能なら音声タイミング）から、相互行為に関わる特徴量を **再現可能に**計算する。
- **狙い**：既存指標の再現に留まらず、**私ならではの新規性ある特徴（オリジナル）**を発見し、論文化に耐える主張にする。

### 0-2) この研究が狙う「測定対象」
- ビッグ5のような粗い性格分類を当てるのではなく、会話の中の：
  - **投げ方**（NE/YO/質問など：相手に反応を促す／提示する）
  - **返し方**（相槌／応答の型／修復（OIR）／話題のつながり）
  - **タイミング**（pause/gap/overlap：間、テンポ、被り）
  を **相互行為の測定**として定量化する。

### 0-3) 強い新規性（主張候補：何が“論文っぽく強い”か）
- **新規性A：応答の「型」を最小仮定で測る（形態素なしでも頑健）**
  - `resp_first_token` を基礎に、`RESP_NE_ENTROPY / RESP_YO_ENTROPY` で **型の固定化 vs 多様性** を測る。
- **新規性B：指標→例文→LLM解釈を“監査可能（provenance）”にする**
  - LLMの解釈を「雰囲気」で終わらせず、**使った特徴量（used_features）と根拠（examples）を残す**設計にする。
- **新規性C：相互行為を“統合プロファイル”で議論できる**
  - PG（timing）×FILL（言い淀み）×IX（修復・逸脱）×（できればmetrics_resp）を同一フレームで統合し、クラスタやタイプで議論できる。

### 0-4) 先行研究（Big5×LLM）との差分（言い方の例）
- 先行研究は「**性格（Big5）という粗い潜在変数**」を、LLM推定と自己申告で照合する枠組み。
- 私たちは「**会話の相互行為のメカニズム**」を、テキスト（＋タイミング）から **再現可能に測定**する枠組み。
- つまり、私たちは **“性格推定”ではなく、“会話の計測”** をやっている（ここが論点の軸）。

### 0-5) 次ミーティングで合意したいこと（アジェンダ案）
1. **研究の主張軸の合意**：性格ではなく「相互行為の計測」で行く（用語の置き方）
2. **主要仮説（H1〜）の優先順位**：まず何を一本目にするか
3. **新規性の核**：entropy（応答型）＋修復（OIR）＋タイミング統合のどれを看板にするか
4. **“監査可能LLM”の仕様**：used_features整合、used_examplesリンクを必須にするか
5. **評価設計**：分母、信頼性フィルタ、データ分割、妥当性の説明

---

## 1) 仮説 → 指標 → 検証計画（短い表：議論用）

> 記号：  
> - ✅＝すでに手元のJSON/ダッシュボードで確認できる（実装・出力あり）  
> - 🟡＝実装されている可能性が高いが、現状の「まとめJSON」やダッシュボードに出ていない／要確認  
> - ⬜＝未実装（今後入れる）

| 仮説ID | 仮説（何がどう違う？） | 主要指標（主に見る） | 補助指標（解釈の補強） | 期待される方向（例） | 検証のしかた（最小） | 注意点（交絡/限界） |
|---|---|---|---|---|---|---|
| H1 | **NE直後の応答が型化している**（固定的な返しが増える） | 🟡 `RESP_NE_ENTROPY` | ✅ `RESP_NE_AIZUCHI_RATE` / ✅ `IX_yesno_rate` | entropy↓、相槌率↑ or YES/NO↑ | 会話×話者で比較、分母で足切り（min events） | NEの定義・辞書依存。分母が小さいとentropyが不安定 |
| H2 | **YO直後でも型化が起きる／文脈依存が弱い** | 🟡 `RESP_YO_ENTROPY` | ✅ `IX_topic_drift_mean` | YOでもentropy↓ | NEとYOを同じ指標で比較（差分を見る） | YO条件の分母確保が必要 |
| H3 | **修復（OIR）が多い**（聞き返し・修復開始が増える） | ✅ `IX_oirmarker_rate` | ✅ `IX_oirmarker_after_question_rate`（※未出力なら⬜） | OIR↑ | 会話×話者でOIR率比較 | 辞書の網羅性。質問条件が0だとafter_questionが欠損 |
| H4 | **修復が“成功しにくい／コストが高い”** | ⬜ 修復成功率 / 修復コスト / 修復軌跡 | ✅ timing（PG） | 成功率↓、コスト↑ | OIR後の次ターンで回復したかを定義して測る | ここが“世紀の発見”候補だが定義設計が要る |
| H5 | **話題のつながりが弱い（逸脱が大きい）** | ✅ `IX_topic_drift_mean` | ✅ `IX_lex_overlap_mean` | drift↑ / overlap↓ | Jaccard（形態素or2gram）で会話×話者比較 | 語彙だけだと意味のつながりは弱い（拡張余地） |
| H6 | **タイミングが特徴的（間・応答遅れ・被り）** | ✅ `PG_pause_*` / ✅ `PG_resp_gap_*` / ✅ `PG_overlap_rate` | ✅ `PG_speech_ratio` | pause↑、gap↑、overlap↑ など | 会話×話者で比較、分母（総時間・イベント数）で品質管理 | 音声境界ノイズ、`gap_tol`の影響 |
| H7 | **フィラーが多い（言い淀みの頻発）** | ✅ `FILL_z_log_rate_per_100chars` | ✅ `PG_pause_p50` | FILL↑、pause↓（埋め合わせ）など | FILLとPGの関係を相関・回帰で見る | テキスト表記ゆらぎ・タグ混入への耐性 |
| H8 | **複合的な“会話タイプ”がある（クラスタで分かれる）** | ✅ `CL_fillpg_cluster` / ✅ `CL_pca_x/y` | ✅ PG/FILL/IX | 特定クラスタに偏る | PCA→KMeans、クラスタ特徴を言語化 | 指標セットの選び方でクラスタが変わる |
| H9 | **LLM解釈は“仮説生成”として有効だが監査可能にする** | ✅ labels.summary / used_features | ⬜ used_examples（証拠リンク） | 説明の再現性↑ | “whyが言及した特徴量はused_featuresに必ず含める”等の制約 | ここを徹底すると論文の信頼性が上がる |

---

## 2) 実装ステータス（再点検表：ダッシュボード/JSON根拠つき）

> **根拠の見方**：ユーザー提示の「まとめJSON例」に **キーとして存在**していれば、少なくとも “出力はされている”。  
> 逆に、MDに書いてあってもJSONに無いなら、(a)未実装、(b)別ファイルにはあるがこのJSONには載せていない、(c)列名が違う、のいずれか。  
>
> **ステータス**：✅ 実装・出力確認 / 🟡 実装されていそう（要確認） / ⬜ 未実装（今後）

### 2-1) まとめ（結論）
- ✅ **PG / FILL / IX / クラスタ / LLMラベル**は、ダッシュボードとJSONから見て **出力されている**。
- 🟡 **metrics_resp（RESP_*）**は、このJSONには見当たらないため、**(1)別テーブルにあるが統合JSONに未同梱**の可能性が高い（要確認）。
- ⬜ **LLMの used_examples（根拠例のリンク）**が空で、ダッシュボードにも “missing: examples不足” が出ているため、**証拠リンク統合**が未完。

### 2-2) 指標群ごとのチェック表

| 指標群 | 項目（例） | ステータス | 根拠（JSON/画面） | 次アクション（必要なら） |
|---|---|---:|---|---|
| PG（timing） | `PG_total_time` `PG_speech_ratio` `PG_pause_mean/p50/p90` `PG_resp_gap_mean/p50/p90` `PG_overlap_rate` `PG_resp_overlap_rate` | ✅ | JSONに多数キーあり（例：`PG_total_time` 等）＋ダッシュボードにPause/Gap summary | - |
| FILL（フィラー） | `FILL_text_len` `FILL_cnt_total` `FILL_cnt_eto` `FILL_rate_per_100chars` `FILL_z_log_rate_per_100chars` 等 | ✅ | JSONに多数キーあり（例：`FILL_cnt_eto` 等）＋ダッシュボードにFiller summary | - |
| IX（相互行為） | `IX_oirmarker_rate` `IX_yesno_rate` `IX_lex_overlap_mean` `IX_topic_drift_mean` 等 | ✅ | JSONにキーあり（例：`IX_oirmarker_rate` 等） | - |
| IX（質問条件つき） | `IX_oirmarker_after_question_rate` `IX_yesno_after_question_rate` `IX_lex_overlap_after_question_mean` | ⬜（または要確認） | JSON例には **存在しない**（`IX_n_pairs_after_question`はある） | **実装するなら**：prev_is_question=1で条件集計列を追加してJSON統合へ |
| metrics_resp（応答型） | `RESP_NE_AIZUCHI_RATE` `RESP_NE_ENTROPY` `RESP_YO_ENTROPY` `n_pairs_after_NE/YO` | 🟡 | JSON例には `RESP_*`が無い（examples内に `RESP_NE_AIZUCHI_RATE`は出る） | **統合JSONに同梱**：話者集計行に `RESP_*` を入れる（labelsのused_featuresにも入れる） |
| examples（証拠） | `examples[]`（prev_text/resp_textなど） | ✅（部分） | JSONに `examples` 配列あり。ダッシュボードにも Examples(evidence) が表示 | “labels.used_examples” へ参照を繋ぐ（下記） |
| LLM labels | `labels.summary` `labels.labels[].why` `labels.labels[].used_features` `needs_more_context` `missing` | ✅（ただし整合性課題） | JSONに `labels` が存在。ダッシュボードにも Summary/Primary label 等 | **整合性チェック**：whyで言及した特徴量がused_featuresに必ず入るよう強制 |
| used_examples（LLM側） | `labels.labels[].used_examples` | ⬜ | JSONで `used_examples: []`、ダッシュボードでも missing が出ている | **必須化**：LLMプロンプトに「引用した例文ID/参照先を必ず列挙」→保存 |
| クラスタ | `CL_pca_x` `CL_pca_y` `CL_fillpg_cluster` | ✅ | JSONに `CL_*` が存在＋PCA散布図が表示 | - |

---

## 3) LLM（解釈）を“科学っぽく”強くするための整合性ルール（超重要）

> ここは先生に刺さる可能性が高い（「ヒューリスティック」批判への回答にもなる）

### 3-1) ルール案（実装できる制約）
1. **whyで言及した特徴量名は、必ず used_features に含める**（不整合を0にする）
2. **whyで言及した根拠例文は、必ず used_examples に含める**（例文ID/パス/発話番号など）
3. **missing があるときは、何が足りないかを機械的に列挙し、次の取得処理に繋ぐ**
4. **ラベルは診断ではなく“機能仮説”**として出す（文章に明記）

### 3-2) JSON例から見える改善点（観察）
- 例：HESITATIONの why で **eto回数**に触れているのに、used_features には `FILL_cnt_eto` が入っていない  
  → これを自動で検知して修正（“監査可能性”が上がる）

---

## 4) TODO（研究の新規性を“世紀の大発見”寄りにする拡張アイデア）

> いちばん強いのは「修復（repair）」を **成功率・コスト・軌跡** まで落とすやつです。

### 4-1) 修復（OIR）を“率”から“ダイナミクス”へ（世紀枠）
- ⬜ **修復成功率**：OIRが出たあと、次の1〜2ターンで会話が回復（合意・理解）したか  
- ⬜ **修復コスト**：回復までに必要なターン数、文字量、ポーズ増加、フィラー増加  
- ⬜ **修復戦略タイプ**：聞き返し（え？）→言い換え→確認、などのパターン分類  
- ✅ 既存のPG/FILL/IXを使って “コスト” は比較的作りやすい

### 4-2) 質問→応答を「答えているか」で測る（QA適合）
- ⬜ YES/NO率だけでなく、質問に対して内容が合っているか（ルール＋LLM監査）
- これも “監査可能LLM” と相性が良い（根拠例文が必要）

---

# ここから下は「辞書の詳細（現状）」：既存の本文を省略せず残します
---

## 0) まず大枠：この研究で「何をやっているか」
- **ビッグ5のような粗い性格分類を当てる研究ではなく**、会話の中の「相互行為の仕組み（相槌・修復・間・応答の型）」を **再現可能な測定**として定量化する。
- その上で、ASDの仮説（会話の特徴がある）に対して、**具体的にどの相互行為の要素がどう違うのか**を議論できるようにする。
- 特徴量は **会話×話者** または **話者交替ペア（prev→resp）** の粒度で設計する。

---

## 1) 用語ミニ辞書（先にここだけ読めばOK）
- **NE / NE_Q**：文末が「ね（よね含む）」系。NE_Q は疑問（? / か等）を伴うケース。  
  直感的には「同意・共有の確認」「相手の反応を促す」寄りの投げ方。
- **YO**：文末が「よ」系。直感的には「提示・断定・情報提供」寄り。
- **相槌（aizuchi）**：はい／うん／そう／なるほど…のような、会話を進めるための短い返答。
- **OIR**：**Other-Initiated Repair**（相手が修復を開始する）  
  例：え？／ん？／もう一回／どういうこと？ などの「聞き返し・修復開始」。
- **entropy（エントロピー）**：分布の「多様さ」。低い＝型が固定化、高い＝多様。

---

## 2) テーブル別：人間向け辞書（名称表）

# 2-A) segments（発話＋タグ）で定義される特徴量
> **粒度**：発話（utterance）  
> **役割**：文末のタイプ（NE/YOなど）と疑問を「軽量に」タグ付けして、後段（pairs/metrics）につなぐ。

| 元の列名 | 人間向け名称（日本語） | (2) 何を測る？（直感） | (3) どう見つけた／発想した？ | (4) 既存/オリジナル | (5) 算出の要点（粒度・分母・入力・簡易式） |
|---|---|---|---|---|---|
| `sfp_group` | **文末タイプ（終助詞カテゴリ）** | 発話が「ね系/よ系/の系…」のどれで終わるか（相互行為の投げ方） | 日本語会話で文末表現が相互行為（同意要求・提示・断定等）に強く関与するため、まず最小限の分類を作った | **既存概念（会話分析/語用論）＋実装は自作** | **入力**：text。**粒度**：発話。**式**：末尾正規表現で `NE/NE_Q/YO/NO/NA/MON/OTHER/NONE/NONLEX` に分類 |
| `is_question` | **疑問フラグ（質問っぽい終わり）** | 質問（?、か、かな等）かどうか | 会話の「質問→応答」や「修復（OIR）」は質問条件で挙動が変わるため、まず軽量に拾う | **既存**（質問判定）＋実装は自作 | **入力**：text。**粒度**：発話。**式**：末尾が `? / ？ / (か,かな,かね,でしょう,でしょ,だろう,だろ,の)` なら True |
| `utt_index` | **発話順インデックス（会話内）** | 会話内で何番目の発話か（順序の固定） | ペア（prev→resp）や系列（直後）を作るには、順序が必要 | **工学的要請**（研究の道具） | **入力**：start/end/utterance_id等。**粒度**：発話。**式**：会話内ソート→0..で再採番（分母なし） |
| `text` | **発話本文** | そのまま | 元データ | - | 解析入力として保持 |
| `start_time`,`end_time` | **発話時間（ある場合）** | 間（pause/gap）など時系列解析の基礎 | 音声境界から timing 指標を作るため | 既存（音声研究） | タイミング系の入力。存在する場合のみ利用 |

---

# 2-B) pairs（話者交替 prev→resp）で定義される特徴量
> **粒度**：話者交替ペア（前の発話 prev と、それへの応答 resp）  
> **役割**：相互行為の「最小単位（隣接ペア）」を作り、応答の型・修復・話題逸脱を測る。

| 元の列名 | 人間向け名称（日本語） | (2) 何を測る？（直感） | (3) どう見つけた／発想した？ | (4) 既存/オリジナル | (5) 算出の要点（粒度・分母・入力・簡易式） |
|---|---|---|---|---|---|
| `prev_sfp_group` | **直前発話の文末タイプ** | 相手が「ね系/よ系…」で投げた直後かどうか | 「投げ方（NE/YO）」で応答が変わる、という仮説の入口 | 既存（条件付き分析） | **入力**：segments.sfp_group。**粒度**：ペア。**式**：prev側のタグを引き継ぐ |
| `resp_is_aizuchi` | **相槌フラグ（短い受け）** | 「はい／うん／そう／なるほど…」のような短い返答か | 会話分析で相槌は“会話を前に進める潤滑油”。ASDでは相槌の出方が特徴になりうるため | **既存概念（相槌）＋辞書実装は自作** | **入力**：resp_text。**粒度**：ペア。**式**：相槌語彙辞書で先頭一致（句読点/空白/文末境界） |
| `resp_first_token` | **応答の先頭語（1語目）** | 応答が「はい/うん/そう/え…」など、何から始まるか | “型の固定化”を最小仮定で取るため、形態素なしでも頑健な 1語目抽出を採用 | **設計としてオリジナル（実装意図）** | **入力**：resp_text（正規化後）。**粒度**：ペア。**式**：日本語文字列 regex で先頭語を抽出、なければ空 |
| `prev_text`,`resp_text` | **前発話/応答本文** | そのまま | 元データ | - | pairs の可読性・例文抽出用に保持 |
| `prev_utt_index`,`resp_utt_index` | **ペア位置（順序）** | どの発話同士のペアか | 例文抽出・監査・再現性のため | 工学的要請 | 会話内順序インデックスを保持 |

---

# 2-C) metrics_resp（会話×応答側話者）で定義される主要指標
> **粒度**：会話×話者（応答側）  
> **役割**：相互行為を“話者の傾向”として集約し、比較・ランキング・クラスタに使う。

## 2-C-1) コア指標（あなたの強みが出るところ）
| 元の列名 | 人間向け名称（日本語） | (2) 何を測る？（直感） | (3) どう見つけた／発想した？ | (4) 既存/オリジナル | (5) 算出の要点（粒度・分母・入力・簡易式） |
|---|---|---|---|---|---|
| `RESP_NE_AIZUCHI_RATE` | **「ね」直後の相槌率** | 相手が「ね（同意促し）」で投げた後に、相槌で返しやすいか | NE は相互行為（同意要求）寄りなので、相槌の出方が“対人調整”の proxy になると考えた | **既存概念（相槌）×条件付き比率は準既存** | **入力**：pairs。**粒度**：会話×応答話者。**分母**：`n_pairs_after_NE`。**式**：mean(resp_is_aizuchi \| prev_sfp_group ∈ {NE,NE_Q}) |
| `RESP_NE_ENTROPY` | **「ね」直後の応答多様性（先頭語）** | 「ね」直後の返しが、毎回同じ型（はい/うん/そう）に固定化しているか | 相槌率だけだと「型の固定化」が見えないので、最小仮定で多様性（entropy）を追加した | **設計としてオリジナル（強み）** | **入力**：pairs。**粒度**：会話×応答話者。**分母**：NE条件ペア内の `resp_first_token` 分布。**式**：Shannon entropy(log2) |
| `RESP_YO_ENTROPY` | **「よ」直後の応答多様性（先頭語）** | 相手が提示・断定（YO）した後の返しが型化しているか | NE だけだと片手落ちなので、別タイプの投げ方（YO）でも同じ測定をして比較可能にした | **設計としてオリジナル（比較軸の拡張）** | **入力**：pairs。**粒度**：会話×応答話者。**分母**：YO条件ペア内の `resp_first_token` 分布。**式**：Shannon entropy(log2) |

## 2-C-2) 分母（信頼性を担保する鍵）
| 元の列名 | 人間向け名称（日本語） | (2) 何を測る？（直感） | (3) どう見つけた／発想した？ | (4) 既存/オリジナル | (5) 算出の要点 |
|---|---|---|---|---|---|
| `n_pairs_total` | **応答ペア総数** | その話者が応答側になった回数 | 指標の信頼性（観測量）を示す最低限の分母 | 既存 | count(pairs) |
| `n_pairs_after_NE` | **「ね」直後ペア数（分母）** | NE条件で観測がどれくらいあるか | NE直後指標は、この分母が小さいと不安定 | 既存（分母管理） | count_if(prev_sfp_group ∈ {NE,NE_Q}) |
| `n_pairs_after_YO` | **「よ」直後ペア数（分母）** | YO条件で観測がどれくらいあるか | YO直後 entropy の安定性のため | 既存（分母管理） | count_if(prev_sfp_group ∈ {YO}) |

---

# 2-D) PG（pause/gap/overlap：timing系）特徴量
> **粒度**：会話×話者  
> **役割**：「間」「テンポ」「被り」を定量化。ASD仮説と結びつきやすい（会話のリズム／ターン交替）。

| 元の列名（例） | 人間向け名称（日本語） | (2) 何を測る？（直感） | (3) どう見つけた／発想した？ | (4) 既存/オリジナル | (5) 算出の要点（粒度・分母・入力・簡易式） |
|---|---|---|---|---|---|
| `pause_mean` | **自分の沈黙の平均長** | 発話と発話の間の“間”が長い/短い | 音声会話の基礎指標。会話が詰まる/流れるを反映 | **既存（音声/会話研究）** | **入力**：speech区間。**粒度**：会話×話者。**式**：pause_list の平均 |
| `pause_p50` | **自分の沈黙の中央値** | 典型的な間の長さ | 平均は外れ値に弱いので中央値も持つ | 既存 | median(pause_list) |
| `pause_p90` | **自分の“長い沈黙”の代表値（90%点）** | たまに起こる長い間の大きさ | 長い沈黙がコミュニケーションに影響しやすい | 既存 | quantile(pause_list, 0.90) |
| `resp_gap_mean` | **相手→自分の応答遅れ（平均）** | 相手の発話終了から自分が話し始めるまでの遅れ | ターン交替の滑らかさ | 既存 | speaker change の g>=0 を平均 |
| `resp_gap_p50` | **応答遅れ（中央値）** | 典型的な応答遅れ | 外れ値に頑健 | 既存 | median(resp_gap_list) |
| `resp_gap_p90` | **大きい応答遅れ（90%点）** | “遅れるとき”の遅れの大きさ | 詰まり/負荷の兆候 | 既存 | quantile(resp_gap_list, 0.90) |
| `resp_overlap_rate` | **被り率（相手に被せて話す割合）** | 相手が終わる前に自分が入ってしまう頻度 | 会話の同期の取り方の特徴 | 既存 | overlaps / n_resp_events |
| `speech_ratio` | **発話率（話している時間割合）** | 会話時間のうち自分が話している割合 | 寡黙/多弁の粗い proxy（ただし性格ではなく会話行動） | 既存 | speech_time / total_time |
| `total_time` | **会話の総時間** | 観測時間 | 分母・品質管理 | 既存 | 音声区間の総和など |

> 注：`gap_tol=0.05s` は「境界ノイズでpauseを過剰カウントしない」ための工学的閾値（理由は Appendix C 相当）。

---

# 2-E) FILL（フィラー）特徴量
> **粒度**：話者（speaker）または 会話×話者（運用に合わせる）  
> **役割**：「えっと」「えー」などの言い淀みを定量化。発話計画の負荷の proxy になり得る。

| 元の列名（例） | 人間向け名称（日本語） | (2) 何を測る？（直感） | (3) どう見つけた／発想した？ | (4) 既存/オリジナル | (5) 算出の要点 |
|---|---|---|---|---|---|
| `FILL_cnt_total` | **フィラー総数** | えっと/えー/あの…がどれくらい出るか | 言い淀みは古くから議論される。まずカウントで土台を作る | **既存概念**＋辞書実装は自作 | text に対して辞書regexで count（eto→除去→e の順で二重カウント回避） |
| `FILL_rate_per_100chars` | **100文字あたりフィラー率** | 文章量の違いをならして比較する | 長く話す人ほど数が増えるので正規化が必要 | 既存（正規化） | `FILL_cnt_total / (FILL_text_len/100)` |
| `FILL_has_any` | **フィラーが出た発話の割合** | “頻繁にフィラーが入る”傾向 | 回数だけでなく出現の広がりを見る | 準既存 | フィラーが1回以上出た行数の合計 |
| `FILL_z_log_rate_per_100chars` | **フィラー率（log→標準化）** | 極端に多い人を安定に比較する | 分布が歪むので log + z で安定化 | 既存（統計処理） | `zscore(log(rate + epsilon))` |
| `FILL_cnt_eto` | **「えっと」系回数** | 代表的フィラーの頻度 | 「えっと」は独立に見たい | 既存概念 | regex count |
| `FILL_cnt_e` | **「えー」系回数** | 引き伸ばしの頻度 | eto と重なるので除去後に数える | 実装としてオリジナル要素あり | eto除去後に count |
| `FILL_cnt_ano` / `sono` / `maa` / `nanka` / `hora` | **各フィラー種別回数** | どのタイプのフィラーを使うか | 種類によって機能が違う可能性 | 準既存 | 各辞書regexで count |
| `FILL_text_len` | **総文字数（分母）** | 正規化のための分母 | 比率の分母 | 既存 | Σ len(text) |

---

# 2-F) IX（相互行為：修復・YES/NO・話題逸脱）特徴量
> **粒度**：会話×応答側話者  
> **役割**：会話分析で重要な「修復（OIR）」「質問応答」「話題のつながり」を proxy として測る。

| 元の列名（例） | 人間向け名称（日本語） | (2) 何を測る？（直感） | (3) どう見つけた／発想した？ | (4) 既存/オリジナル | (5) 算出の要点 |
|---|---|---|---|---|---|
| `IX_oirmarker_rate` | **聞き返し（修復開始）率：OIR率** | 「え？」「もう一回」などで修復を開始する頻度 | 修復は会話分析の王道。ASD仮説にも直結しやすい | **既存（CA）＋辞書実装は自作** | pairsの resp_text に OIR辞書 regex を search → mean |
| `IX_oirmarker_after_question_rate` | **質問直後のOIR率** | 質問されたときに聞き返す頻度 | 質問条件で修復が増える可能性 | 既存（条件付き分析） | prev_is_question=1 に限定して mean |
| `IX_yesno_rate` | **YES/NO応答率** | はい/いいえ/うん…で返す割合（短い同意・否定） | “応答の型”の別軸として導入 | 既存概念 | YESNO辞書で先頭一致 → mean |
| `IX_yesno_after_question_rate` | **質問直後のYES/NO率** | 質問への返しが YES/NO に偏るか | 質問応答の型を見る | 準既存 | prev_is_question=1 で mean |
| `IX_lex_overlap_mean` | **語彙のつながり平均（重なり）** | 相手の語と自分の語がどれだけ共通か（つながり） | “話題のつながり”の最小 proxy | 既存（類似度） | tokenize(prev), tokenize(resp) → Jaccard の平均 |
| `IX_topic_drift_mean` | **話題の逸脱度（平均）** | 相手の話からどれだけ逸れるか | つながりの裏返しで解釈しやすい | 設計は準オリジナル | `1 - lex_overlap` の平均 |
| `IX_lex_overlap_p10` | **語彙つながり：低い側（10%点）** | “つながらない応答”の強さ | 平均だけだと見えない端を残す | 既存（分位点） | quantile(0.10) |
| `IX_topic_drift_p90` | **逸脱：高い側（90%点）** | “大きく逸れる”ケースの強さ | 外れ値の代表を残す | 既存（分位点） | quantile(0.90) |
| `IX_prev_question_rate` | **相手が質問してくる割合** | 観測条件の違い | 条件が違うと比較が歪むため | 既存（品質管理） | mean(prev_is_question) |
| `IX_n_pairs` | **IX算出に使ったペア数（分母）** | 観測量 | 信頼性 | 既存 | count(pairs) |
| `IX_n_pairs_after_question` | **質問直後ペア数（分母）** | 質問条件の観測量 | 信頼性 | 既存 | count_if(prev_is_question=1) |

---

## 3) 既存 vs オリジナル：まとめ（一言で説明する用）
- **既存（先行研究で一般的）**：相槌、修復（OIR）、質問条件、timing（pause/gap/overlap）、フィラー概念  
- **準オリジナル（既存概念×自前の定義）**：NE/YO/終助詞カテゴリを軸にした条件付き指標、topic drift（1-overlap）  
- **オリジナル（福原の設計として主張しやすい）**：  
  - **RESP_NE_ENTROPY / RESP_YO_ENTROPY**（“応答の型”を最小仮定でentropy化：形態素なしでも頑健）  
  - **resp_first_token の採用**（計測としての割り切りと再現性）  
  - （今後強化すると強い）修復の「成功率・コスト・軌跡」、質問→応答の適合（監査可能LLM）

---

## 4) この辞書の使い方（先生向け）
- 指標は「性格」ではなく **会話の相互行為の“測定”**。  
- ASD仮説に対しては、  
  1) **投げ方（NE/YO/質問）**  
  2) **返し方（相槌／先頭語の型／修復／つながり／間）**  
  を同じ枠組みで比較できることが重要。

---

## 5) TODO（次のミーティングで議論したい更新候補）
- OIR（修復）を「出るか」だけでなく、**修復が成功して会話が回復したか**まで測る（成功率・コスト）。
- 質問→応答を「YES/NO率」だけでなく、**質問に答えているか（QA適合）**を入れる（ルール＋LLM監査）。
- timing（PG）×修復×相槌の統合で「会話の交通ルール」を測る。
