# CEJCï¼ˆè‡ªå®…ãƒ»å°‘äººæ•°ï¼‰æŠ½å‡º â†’ æ“¬ä¼¼æ—¥è¨˜ï¼ˆTop1è©±è€…ï¼‰ â†’ IPIP-NEO-120(æ—¥æœ¬èª) ã§ Big5 æ¡ç‚¹ â†’ è¤‡æ•°LLMå¹³å‡ï¼ˆå†ç¾ãƒ­ã‚°ï¼‰ï¼‹ CSJï¼ˆå¯¾è©±Dï¼‰æ¤œè¨¼ãƒ­ã‚°
Date: 2026-02-16  
Owner: ç¦åŸç„  
Last updated: 2026-02-17

---

## 0) ã“ã‚Œã‚’ä¸€è¨€ã§ï¼ˆä½•ã‚‚çŸ¥ã‚‰ãªã„äººå‘ã‘ï¼‰
**ã€Œæ—¥å¸¸ä¼šè©±ã®æ–‡å­—èµ·ã“ã—ã€ã‹ã‚‰ã€æ€§æ ¼ãƒ†ã‚¹ãƒˆï¼ˆBig Fiveï¼‰120å•ã‚’LLMã«å›ç­”ã•ã›ã¦ç‚¹æ•°åŒ–ã—ã€4ã¤ã®LLMã®å¹³å‡ã‚’â€œæœ€çµ‚ã‚¹ã‚³ã‚¢â€ã¨ã—ã¦ä½œã‚‹**å®Ÿé¨“ã§ã™ã€‚  
è«–æ–‡ãŒä¸»å¼µã™ã‚‹ã€Œ**è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®å¹³å‡ãŒå¼·ã„ï¼ˆå®‰å®šã™ã‚‹ï¼‰**ã€ã‚’ã€ä»Šå›ã®æ—¥æœ¬èªä¼šè©±ãƒ‡ãƒ¼ã‚¿ã§ã‚‚ **Cronbachâ€™s Î±ï¼ˆå†…éƒ¨ä¸€è²«æ€§ï¼‰**ã§ç¢ºã‹ã‚ã¾ã—ãŸã€‚

---

## 1) ä»Šå›â€œå®Œäº†â€ã¨åˆ¤æ–­ã—ãŸè«–æ–‡æ¤œè¨¼ã®ç¯„å›²ï¼ˆä½•ãŒè¨€ãˆã¦ã€ä½•ãŒã¾ã ã‹ï¼‰
æœ¬mdã§å®Œäº†ã—ãŸã®ã¯ã€è«–æ–‡ã®ä¸»å¼µã®ã†ã¡æ¬¡ã®éƒ¨åˆ†ã§ã™ï¼š

- âœ… **è«–æ–‡ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆparticipantã¨ã—ã¦å›ç­”ï¼å›ºå®š5æŠï¼ä½™è¨ˆãªæ–‡å­—ç¦æ­¢ï¼invalidã¯ç ´æ£„ï¼‰**ã«å¯„ã›ã¦ã€  
  itemãƒ¬ãƒ™ãƒ«ï¼ˆ120å•Ã—è¢«é¨“è€…ï¼‰ã‚’æ©Ÿæ¢°çš„ã«æ¡ç‚¹ã§ãã‚‹â€œå†ç¾ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³â€ã‚’æ§‹ç¯‰ã—ãŸã€‚
- âœ… **è¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¹³å‡ï¼ˆensembleï¼‰ãŒå˜ä½“ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šå†…éƒ¨ä¸€è²«æ€§ï¼ˆÎ±ï¼‰ãŒé«˜ã„**ã“ã¨ã‚’ç¢ºèªã—ãŸ  
  â†’ ä»Šå›ã®ä¸»çµæœï¼ˆÂ§8ï¼‰ï¼‹ CSJã§ã‚‚åŒæ§˜ã®å‚¾å‘ã‚’è¿½è©¦ï¼ˆÂ§14ï¼‰ã€‚

ä¸€æ–¹ã€è«–æ–‡ã®ã‚‚ã†ä¸€ã¤ã®å¤§ããªä¸»å¼µã§ã‚ã‚‹
- â³ **è‡ªå·±å ±å‘Šï¼ˆself-reportï¼‰ã¨ã®ç›¸é–¢ãŒé«˜ã„**
ã¯ã€å¤–éƒ¨åŸºæº–ï¼ˆè‡ªå·±è©•å®šï¼äººæ‰‹è©•å®šï¼‰ã‚’ä»˜ä¸ã—ã¦ã„ãªã„ãŸã‚ã€**æœ¬mdã§ã¯æœªæ¤œè¨¼**ï¼ˆå°†æ¥ã‚¹ãƒ†ãƒƒãƒ—ï¼‰ã€‚

---

## 2) å…¨ä½“ãƒ•ãƒ­ãƒ¼ï¼ˆå›³ï¼‰
```mermaid
flowchart TD
  A[CEJC convlistï¼ˆä¼šè©±ãƒ¡ã‚¿ï¼‰å–å¾—] --> B[æ¡ä»¶æŠ½å‡º: è‡ªå®… & è©±è€…æ•°2-3]
  B --> C[utterances ã‹ã‚‰ Top1è©±è€…ã‚’æŠ½å‡º]
  C --> D[Top1è©±è€…ã®ç™ºè©±ã‚’é€£çµã—ã¦æ“¬ä¼¼ãƒ¢ãƒãƒ­ãƒ¼ã‚°åŒ–]
  D --> E[æ“¬ä¼¼ãƒ¢ãƒãƒ­ãƒ¼ã‚°ã‚’ v1 ã¨ã—ã¦å›ºå®šï¼ˆsha256ä»˜ä¸ï¼‰]
  E --> F[IPIP-NEO-120 æ—¥æœ¬èª 120å•]
  F --> G[Bedrockã§4ãƒ¢ãƒ‡ãƒ«æ¡ç‚¹ï¼ˆ0-4, reverseå¯¾å¿œï¼‰]
  G --> H[QC: fallback=0, rowsä¸€è‡´, n_models=4]
  H --> I[4ãƒ¢ãƒ‡ãƒ«å¹³å‡ensembleã‚’ä½œæˆ]
  I --> J[Î±ï¼ˆå˜ä½“ vs ensembleï¼‰ã§â€œå¹³å‡ãŒå¼·ã„â€ã‚’æ¤œè¨¼]
````

---

## 3) ãªãœ CSJ ã§ã¯ãªã CEJC ã‚’é¸ã‚“ã ã‹ï¼ˆã‚³ãƒ¼ãƒ‘ã‚¹é¸å®šã®ç†ç”±ï¼‰

* ç›®æ¨™ãŒã€Œ**daily diary / idiographic narrativeï¼ˆâ€œæ—¥è¨˜ã£ã½ã„ç‹¬ã‚Šèªã‚Šâ€ï¼‰**ã€ã«è¿‘ã„æ¡ä»¶ã§ã‚ã‚‹ãŸã‚ã€‚
* **CEJC ã¯ä¼šè©±ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã« â€œå ´æ‰€ï¼ˆä¾‹ï¼šè‡ªå®…ï¼‰/ æ´»å‹• / è©±è€…æ•°â€ ç­‰ãŒã‚ã‚Š**ã€
  ã€Œè‡ªå®…ãƒ»å°‘äººæ•°ã€ã‚’ **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ã§å†ç¾å¯èƒ½ã«æŠ½å‡º**ã§ãã‚‹ã€‚
* CSJ ã¯ï¼ˆå°‘ãªãã¨ã‚‚ã“ã®ç›®çš„ã«å¯¾ã—ã¦ï¼‰ã‚¹ãƒ”ãƒ¼ãƒå¯„ã‚Šæ¡ä»¶ã«ãªã‚Šã‚„ã™ãã€
  â€œæ—¥è¨˜ã£ã½ã•â€æ¡ä»¶ã®è¨­è¨ˆãƒ»å†ç¾ãŒé›£ã—ã„ã€‚

> â€»ãŸã ã—ã€æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€Œç™ºè©±é‡ç¢ºä¿ã€ã€Œå½¢å¼å·®ï¼ˆå¯¾è©±/è¬›æ¼”ï¼‰ã®å½±éŸ¿ã€ã‚’è¦‹ã‚‹ãŸã‚ã«ã€CSJï¼ˆå¯¾è©±Dï¼‰ã‚‚è¿½è©¦å¯¾è±¡ã¨ã—ãŸï¼ˆÂ§14ï¼‰ã€‚

---

## 4) ä»Šå›ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©ï¼ˆå›ºå®šåŒ–ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ï¼‰

### 4.1 50 subjectï¼ˆä¼šè©±Ã—è©±è€…ï¼‰ã‚’ä½œã‚‹æ–¹æ³•

* CEJCã®ä¼šè©±ã‹ã‚‰ **ã€Œè‡ªå®…ã€ã‹ã¤ã€Œè©±è€…æ•°2ã€œ3ã€**ã®ä¼šè©±IDã‚’æŠ½å‡º
* utterances ã‹ã‚‰ **ä¼šè©±å†…ã§æœ€ã‚‚æ”¯é…çš„ï¼ˆdominanceãŒæœ€å¤§ï¼‰ãª Top1è©±è€…**ã ã‘æ®‹ã™
* Top1è©±è€…ã®ç™ºè©±ãƒ†ã‚­ã‚¹ãƒˆã‚’æ™‚ç³»åˆ—ã«é€£çµã—ã€**æ“¬ä¼¼ãƒ¢ãƒãƒ­ãƒ¼ã‚°ï¼ˆæ“¬ä¼¼æ—¥è¨˜ï¼‰**ã¨ã—ã¦æ‰±ã†
* é€Ÿåº¦ã¨ç­‹ã®ãƒãƒ©ãƒ³ã‚¹ã§ **ä¸Šä½50ä¼šè©±**ã«é™å®šï¼ˆrows=50, unique_conversations=50ï¼‰

### 4.2 v1å›ºå®šï¼ˆsha256ã‚’ä»˜ã‘ã‚‹ï¼‰

* ç”Ÿæˆã—ãŸæ“¬ä¼¼ãƒ¢ãƒãƒ­ãƒ¼ã‚°parquetã‚’ **`monologues_diary_home_top1_v1.parquet`**ã¨ã—ã¦å›ºå®š
* **sha256** ã‚’ä»˜ä¸ã—ã¦ã€ŒåŒã˜å…¥åŠ›ã‹ã‚‰åŒã˜çµæœã€ã‚’ä¸»å¼µã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹

å®Ÿæ¸¬ sha256ï¼š

* `a71b14ef91c180798ba47c836621ce591b1ab06c70cf30c2a8debf20117708ba`

ãƒ•ã‚¡ã‚¤ãƒ«ï¼š

* `artifacts/cejc/monologues_diary_home_top1_v1.parquet`
* `artifacts/cejc/monologues_diary_home_top1_v1.sha256.txt`

> â€» shaãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã§ `tee` ã‚’èª¤ç”¨ã—ã¦è©°ã¾ã£ãŸå ´åˆã¯ã€ä¸‹ã®â€œæ­£ã—ã„ä¸€ç™ºâ€ã‚’ä½¿ã†ï¼ˆÂ§7.5ï¼‰ã€‚

---

## 5) è³ªå•ç´™ï¼ˆitemsï¼‰ã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆè«–æ–‡äº’æ›æ€§ã®è¦ï¼‰

### 5.1 items ã¯ IPIP-NEO-120ï¼ˆæ—¥æœ¬èª 120é …ç›®ï¼‰

* ä»Šå›ã®â€œè«–æ–‡æ¯”è¼ƒå¯èƒ½æ€§â€ã®ä¸­å¿ƒã¯ã€**120å•ï¼ˆå„ç‰¹æ€§24å•ï¼‰**ã‚’ä½¿ã†ã“ã¨ã€‚
* å®Ÿè¡Œã«ä½¿ç”¨ã—ãŸ itemsï¼ˆä¾‹ï¼‰ï¼š

  * `artifacts/big5/items_ipipneo120_ja.csv`ï¼ˆ120å•ï¼‰

> æ³¨æ„ï¼šéå»ã®è©¦è¡Œã§ `items.csv` ãŒ 30å•ã®è»½é‡ç‰ˆã ã£ãŸæ™‚æœŸãŒã‚ã‚‹ãŸã‚ã€
> æœ¬mdã®ã€Œæœ€çµ‚çµæœã€ã¯ **å¿…ãš 120å•ç‰ˆï¼ˆipipneo120ja120ï¼‰**ã‚’æŒ‡ã™ã‚ˆã†ã€å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã§ã‚‚è­˜åˆ¥ã—ã¦ã„ã‚‹ï¼ˆÂ§6.2ï¼‰ã€‚

### 5.2 0â€“4ã®5ä»¶æ³•ï¼ˆreverseå¯¾å¿œï¼‰

* é¸æŠè‚¢ï¼ˆå›ºå®š5æŠï¼‰ï¼š

  * Very Inaccurate / Moderately Inaccurate / Neither Accurate nor Inaccurate / Moderately Accurate / Very Accurate
* ã‚¹ã‚³ã‚¢å¤‰æ›ï¼ˆ0ã€œ4ï¼‰ï¼š

  * Very Inaccurate = 0, â€¦ , Very Accurate = 4
* reverseé …ç›®ã¯ **score = 4 - base** ã«å¤‰æ›

---

## 6) LLMæ¡ç‚¹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆè«–æ–‡ã«å¯„ã›ãŸè¨­è¨ˆï¼‰

è«–æ–‡å´ã®è¦ç‚¹ï¼ˆæœ¬å®Ÿè£…ã§å¿…é ˆåŒ–ã—ãŸç‚¹ï¼‰ï¼š

* **participant ã¨ã—ã¦å›ç­”**ï¼ˆæ¡ç‚¹è€…ã§ã¯ãªãâ€œæœ¬äººã«ãªã‚Šãã‚‹â€ï¼‰
* **é¸æŠè‚¢ã¯å›ºå®š5æŠ**
* **å‡ºåŠ›ã¯é¸æŠè‚¢ã®å®Œå…¨ä¸€è‡´ã®ã¿ï¼ˆèª¬æ˜ãƒ»å¥èª­ç‚¹ãƒ»ä½™è¨ˆãªæ–‡å­—ç¦æ­¢ï¼‰**
* invalidï¼ˆè¨±å®¹ã•ã‚Œãªã„å‡ºåŠ›ï¼‰ã¯ **ç ´æ£„ã—ã¦å†è©¦è¡Œ**
* item ã¯ç‹¬ç«‹ã«æŠ•ã’ã‚‹ï¼ˆnew conversationé‹ç”¨ï¼‰

æœ¬å®Ÿè£…ã§ã¯ã€ã“ã®æ–¹é‡ã‚’ **strict** ã¨ã—ã¦å›ºå®šã—ã€
â€œä¸‹æµã§ fallback ã«ãªã£ãŸâ€ãªã©ã‚’æ¤œå‡ºã§ãã‚‹ã‚ˆã†ã€QCï¼ˆÂ§9ï¼‰ã‚‚å¿…ãšæ®‹ã™ã€‚

---

## 7) å†ç¾æ‰‹é †ï¼ˆã‚³ãƒãƒ³ãƒ‰ï¼‰â€” æœ€åˆã‹ã‚‰æœ€å¾Œã¾ã§

å‰æï¼š

* Python 3.12 / venv
* AWS èªè¨¼æƒ…å ±ï¼ˆ`AWS_PROFILE` ç­‰ï¼‰
* Bedrock region: `ap-northeast-1`

### 7.1 å…¥åŠ›ãƒ»å‰æç¢ºèª

```bash
python -V
aws sts get-caller-identity
```

### 7.2 CEJC ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆconvlist.parquetï¼‰ç¢ºèª

```bash
ls -la artifacts/tmp_meta/cejc_convlist.parquet

python - <<'PY'
import pandas as pd
p="artifacts/tmp_meta/cejc_convlist.parquet"
df=pd.read_parquet(p)
print("shape=", df.shape)
print("cols =", list(df.columns))
print(df.head(3).to_string(index=False))
PY
```

ï¼ˆconvlist.parquet ãŒç„¡ã„å ´åˆï¼šscrapeï¼‰

```bash
python scripts/cejc/scrape_cejc_convlist_no_lxml.py \
  --out_parquet artifacts/tmp_meta/cejc_convlist.parquet \
  --out_top_tsv artifacts/tmp_meta/cejc_diary_candidates_top200.tsv \
  --topk 200 \
| tee artifacts/tmp_meta/cejc_meta_profile.txt
```

### 7.3 diary-likeï¼ˆè‡ªå®…ãƒ»å°‘äººæ•°ï¼‰IDãƒªã‚¹ãƒˆä½œæˆï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ï¼‰

```bash
python - <<'PY'
import pandas as pd, re, os
inp="artifacts/tmp_meta/cejc_convlist.parquet"
out_ids="artifacts/tmp_meta/cejc_diary_home_small_ids.txt"
out_preview="artifacts/tmp_meta/cejc_diary_home_small_preview.tsv"
df=pd.read_parquet(inp)

# è©±è€…æ•°ã®æ•°å€¤åŒ–ï¼ˆåˆ—åã¯ç’°å¢ƒå·®ãŒã‚ã‚Šå¾—ã‚‹ãŸã‚å­˜åœ¨åˆ—ã§å‡¦ç†ï¼‰
if "speaker_n" not in df.columns:
    src = "è©±è€…æ•°" if "è©±è€…æ•°" in df.columns else None
    if src:
        def to_int(x):
            s=str(x).strip()
            s=re.sub(r'^[^0-9]*','',s)
            s=re.sub(r'[^0-9].*$','',s)
            return int(s) if s.isdigit() else None
        df["speaker_n"]=df[src].map(to_int)

# è‡ªå®… & å°‘äººæ•°ï¼ˆ2-3ï¼‰
place_col = "å ´æ‰€" if "å ´æ‰€" in df.columns else None
if place_col is None:
    raise SystemExit("å ´æ‰€ åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚æŠ½å‡ºæ¡ä»¶ã‚’èª¿æ•´ã—ã¦ãã ã•ã„")

sub=df.copy()
sub=sub[sub[place_col].astype(str).str.contains("è‡ªå®…", na=False)]
sub=sub[sub["speaker_n"].isin([2,3])]

os.makedirs("artifacts/tmp_meta", exist_ok=True)
id_col = "ä¼šè©±ID" if "ä¼šè©±ID" in sub.columns else "conversation_id"
sub[id_col].dropna().astype(str).to_csv(out_ids, index=False, header=False)

keep=[c for c in ["ä¼šè©±ID","ä¼šè©±æ¦‚è¦","è©±è€…æ•°","å½¢å¼","å ´æ‰€","æ´»å‹•","è©±è€…é–“ã®é–¢ä¿‚æ€§","speaker_n"] if c in sub.columns]
sub[keep].head(100).to_csv(out_preview, sep="\t", index=False)

print("OK:", out_ids, "n_unique=", sub[id_col].nunique())
print("OK:", out_preview)
PY
```

### 7.4 utterances ã‹ã‚‰ Top1 è©±è€…ã‚’æŠ½å‡ºã—æ“¬ä¼¼ãƒ¢ãƒãƒ­ãƒ¼ã‚°åŒ–ï¼ˆTop1ï¼‰

```bash
python - <<'PY'
import pandas as pd, os
utt_path="artifacts/_tmp_utt/cejc_utterances/part-00000.parquet"
ids_path="artifacts/tmp_meta/cejc_diary_home_small_ids.txt"
out_parquet="artifacts/cejc/monologues_diary_home_top1.parquet"
os.makedirs("artifacts/cejc", exist_ok=True)

utt=pd.read_parquet(utt_path)
ids=set(pd.read_csv(ids_path, header=None)[0].astype(str).tolist())
u=utt[utt["conversation_id"].astype(str).isin(ids)].copy()

u["dur"]=(u["end_time"].astype(float)-u["start_time"].astype(float)).clip(lower=0.0)

g=(u.groupby(["conversation_id","speaker_id"], as_index=False)
     .agg(speaker_dur=("dur","sum"), n_utt=("utterance_id","count"),
          n_chars=("text", lambda s: int("".join(map(str,s)).__len__()))))
tot=(u.groupby("conversation_id", as_index=False).agg(total_dur=("dur","sum")))
g=g.merge(tot,on="conversation_id",how="left")
g["dominance"]=g["speaker_dur"]/g["total_dur"].replace({0: pd.NA})

top1=(g.sort_values(["conversation_id","dominance"], ascending=[True,False])
        .groupby("conversation_id", as_index=False).head(1))

u=u.merge(top1[["conversation_id","speaker_id"]], on=["conversation_id","speaker_id"], how="inner")
u=u.sort_values(["conversation_id","start_time","end_time"])
text=(u.groupby(["conversation_id","speaker_id"], as_index=False)
        .agg(text=("text", lambda s: "\n".join(map(str,s)))))

out=top1.merge(text,on=["conversation_id","speaker_id"],how="left")
out=out.rename(columns={"speaker_dur":"main_dur"})
out=out[["conversation_id","speaker_id","text","dominance","total_dur","main_dur","n_utt","n_chars"]]

# é€Ÿåº¦ãƒ»ç­‹ã®ãƒãƒ©ãƒ³ã‚¹ã§ä¸Šä½50ä¼šè©±ã«é™å®š
out=out.sort_values(["dominance","n_chars"], ascending=[False,False]).head(50).reset_index(drop=True)
out.to_parquet(out_parquet, index=False)
print("OK:", out_parquet, "n_conversations=", out["conversation_id"].nunique(), "rows=", len(out))
print(out.head(5).to_string(index=False))
PY
```

### 7.5 v1å›ºå®šï¼ˆã‚³ãƒ”ãƒ¼ï¼‹sha256ä»˜ä¸ï¼‰â€” æ­£ã—ã„ä¸€ç™º

```bash
cd ~/cpsy
cp -a artifacts/cejc/monologues_diary_home_top1.parquet \
      artifacts/cejc/monologues_diary_home_top1_v1.parquet

python - <<'PY' | tee artifacts/cejc/monologues_diary_home_top1_v1.sha256.txt
import hashlib, pathlib
p=pathlib.Path("artifacts/cejc/monologues_diary_home_top1_v1.parquet")
h=hashlib.sha256(p.read_bytes()).hexdigest()
print("sha256", h)
PY
```

### 7.6 Bedrock ã§ Big5 æ¡ç‚¹ï¼ˆ4ãƒ¢ãƒ‡ãƒ« Ã— 120 itemsï¼‰

#### ãƒ¢ãƒ‡ãƒ«

```bash
cat > artifacts/big5/models.txt <<'TXT'
qwen.qwen3-235b-a22b-2507-v1:0
global.anthropic.claude-sonnet-4-20250514-v1:0
deepseek.v3-v1:0
openai.gpt-oss-120b-1:0
TXT
nl -ba artifacts/big5/models.txt
```

#### å®Ÿè¡Œï¼ˆdatasetåã« sha ã¨ items ã‚’åŸ‹ã‚è¾¼ã‚€ï¼‰

```bash
MONO="artifacts/cejc/monologues_diary_home_top1_v1.parquet"
ITEMS="artifacts/big5/items_ipipneo120_ja.csv"   # 120 items ã¯ã“ã¡ã‚‰
ROOT="artifacts/big5/llm_scores"
SHA="a71b14ef"  # sha256å…ˆé ­8æ¡ï¼ˆè¦‹ã‚„ã™ã•ç”¨ï¼‰

DATASET="dataset=cejc_diary_home_top1_v1__sha=${SHA}__items=ipipneo120ja120"
OUTROOT="$ROOT/$DATASET"

while IFS= read -r MODEL; do
  [ -z "$MODEL" ] && continue
  SAFE="$(echo "$MODEL" | tr ':/' '__')"
  OUTDIR="$OUTROOT/model=$SAFE"
  echo "== RUN $SAFE ($MODEL) =="

  python scripts/big5/score_big5_bedrock.py \
    --monologues_parquet "$MONO" \
    --items_csv "$ITEMS" \
    --model_id "$MODEL" \
    --region "ap-northeast-1" \
    --out_dir "$OUTDIR" \
  || exit 1
done < artifacts/big5/models.txt
```

#### è©°ã¾ã‚Šãƒã‚¤ãƒ³ãƒˆï¼ˆå†ç¾ãƒ¡ãƒ¢ï¼‰

* `ValidationException: on-demand throughput isnâ€™t supported`

  * â†’ `global.` prefix ä»˜ãã® model id ã‚’ä½¿ã†ï¼ˆClaude Sonnet 4 ã¯ `global.anthropic...`ï¼‰

---

## 8) ä¸»çµæœï¼ˆè«–æ–‡ä¸»å¼µã€Œè¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¹³å‡ãŒå¼·ã„ã€ã‚’ â€œå†…éƒ¨ä¸€è²«æ€§(Î±)â€ ã§ã‚‚æ¤œè¨¼ï¼‰

### 8.0 åŸè‘—ï¼ˆSample2: daily diariesï¼‰ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹ Î±ï¼ˆæ¯”è¼ƒç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰

åŸè‘—ã¯ item-level å¿œç­”ã‚’ä½¿ã£ã¦ã€å„traitÃ—å„LLMã® Cronbachâ€™s Î± ã‚’ç®—å‡ºã—ã¦ã„ã‚‹ã€‚è¦ç‚¹ã¯ä»¥ä¸‹ï¼š

* **Sample2ï¼ˆdaily diariesï¼‰**ï¼šLLMç”Ÿæˆtraitã®å†…éƒ¨ä¸€è²«æ€§ã¯ **å¹³å‡Î±=0.88**ã€ã‹ã¤ **å…¨ãƒ¢ãƒ‡ãƒ«Ã—å…¨å°ºåº¦ã§æœ€å°Î±=0.70**ã€‚self-report ã®å¹³å‡Î±ã‚‚ **0.88**ã€‚
  ã€è«–æ–‡æ ¹æ‹ ï¼šSample2 å¹³å‡Î±=0.88ã€self-reportå¹³å‡Î±=0.88ã€æœ€å°Î±=0.70ã€‘
* **Sample1ï¼ˆspontaneous thoughtsï¼‰**ï¼šå¹³å‡Î±=0.76ï¼ˆself-reportå¹³å‡Î±=0.78ï¼‰ã€‚ãŸã ã— **Openness ã®Î±ãŒLLMé–“ã§ä½ä¸‹ï¼ˆ0.26â€“0.79ï¼‰**ã€‚
  ã€è«–æ–‡æ ¹æ‹ ï¼šSample1 å¹³å‡Î±=0.76 / self-report0.78 / Oã®ãƒ¬ãƒ³ã‚¸0.26â€“0.79ã€‘

> æ³¨ï¼šåŸè‘—ã®ã€Œå¹³å‡Î±=0.88ã€ã¯ **â€œå…¨traitÃ—å…¨LLMã‚’ã¾ã¨ã‚ãŸå¹³å‡â€**ã€‚æœ¬mdã® ensemble ã¯ **â€œ4ãƒ¢ãƒ‡ãƒ«å¹³å‡ã§1ã¤ã®ã‚¹ã‚³ã‚¢ç³»åˆ—ã‚’ä½œã£ã¦ã‹ã‚‰ traitåˆ¥Î±â€**ãªã®ã§ã€å³å¯†ã«åŒä¸€é›†è¨ˆã§ã¯ãªã„ãŒã€ç›®å®‰ã¨ã—ã¦æ¯”è¼ƒå¯èƒ½ã€‚

---

### 8.1 å˜ä½“ãƒ¢ãƒ‡ãƒ«ã® Cronbachâ€™s Î±ï¼ˆ120 items = å„trait24å•ï¼‰

å‡¡ä¾‹ï¼šğŸŸ©>=0.70 / ğŸŸ¨0.50â€“0.70 / ğŸŸ¥<0.50

| Model (Bedrock) |          A |          C |          E |          N |          O |
| --------------- | ---------: | ---------: | ---------: | ---------: | ---------: |
| Qwen3-235B      | ğŸŸ¥0.470250 | ğŸŸ©0.739250 | ğŸŸ©0.816709 | ğŸŸ©0.704363 | ğŸŸ¨0.641231 |
| Claude Sonnet 4 | ğŸŸ©0.760230 | ğŸŸ©0.818102 | ğŸŸ©0.779544 | ğŸŸ©0.835077 | ğŸŸ©0.859147 |
| DeepSeek V3     | ğŸŸ¥0.293894 | ğŸŸ©0.704180 | ğŸŸ©0.736994 | ğŸŸ©0.794459 | ğŸŸ¨0.689223 |
| GPT-OSS 120B    | ğŸŸ©0.824672 | ğŸŸ©0.899156 | ğŸŸ©0.796702 | ğŸŸ©0.842254 | ğŸŸ©0.780861 |

è¦³å¯Ÿï¼š

* å˜ä½“ãƒ¢ãƒ‡ãƒ«ã ã¨ã€ç‰¹ã« **Aï¼ˆå”èª¿æ€§ï¼‰**ãŒãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ä¸å®‰å®šï¼ˆğŸŸ¥ãŒå‡ºã‚‹ï¼‰
* ãŸã ã—æ¬¡ã® **ensembleï¼ˆ4ãƒ¢ãƒ‡ãƒ«å¹³å‡ï¼‰**ã§ä¸€æ®µå®‰å®šã™ã‚‹ï¼ˆæ¬¡ç¯€ï¼‰

---

### 8.2 4ãƒ¢ãƒ‡ãƒ«å¹³å‡ï¼ˆensembleï¼‰ã® Cronbachâ€™s Î±ï¼ˆä»Šå›ã®æ ¸å¿ƒï¼‰

**ensemble=item_mean_4models**ï¼ˆitemã”ã¨ã«4ãƒ¢ãƒ‡ãƒ«å¹³å‡â†’traité›†è¨ˆï¼‰

| Ensemble          |          A |          C |          E |          N |          O |
| ----------------- | ---------: | ---------: | ---------: | ---------: | ---------: |
| item_mean_4models | ğŸŸ©0.781606 | ğŸŸ©0.904440 | ğŸŸ©0.874387 | ğŸŸ©0.875451 | ğŸŸ©0.862863 |

çµè«–ï¼ˆã“ã®mdå†…ã§ã®è«–æ–‡æ¤œè¨¼ã¨ã—ã¦è¨€ãˆã‚‹ã“ã¨ï¼‰ï¼š

* **å˜ä½“ãƒ¢ãƒ‡ãƒ«ã§å´©ã‚Œã‚‹ç‰¹æ€§ï¼ˆä¾‹ï¼šAï¼‰ã‚‚å«ã‚ã€4ãƒ¢ãƒ‡ãƒ«å¹³å‡ã§ã¯å…¨ç‰¹æ€§ã§ Î±>=0.70 ã‚’æº€ãŸã—ãŸ**
* ã‚ˆã£ã¦ã€Œ**è¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¹³å‡ãŒå¼·ã„**ã€ã¯ã€å°‘ãªãã¨ã‚‚ **å†…éƒ¨ä¸€è²«æ€§ï¼ˆÎ±ï¼‰ã®è¦³ç‚¹ã§ã‚‚**ã€æ—¥æœ¬èªä¼šè©±ï¼ˆCEJCæ“¬ä¼¼æ—¥è¨˜ï¼‰ã§å†ç¾ã§ããŸ

> å‚è€ƒï¼šåŸè‘—ãŒä¸»ã«è©•ä¾¡ã—ã¦ã„ã‚‹ â€œself-report ã¨ã®ç›¸é–¢ï¼ˆåæŸå¦¥å½“æ€§ï¼‰â€ ã¯æœ¬mdã§ã¯æœªæ¤œè¨¼ï¼ˆå¤–éƒ¨åŸºæº–æœªä»˜ä¸ï¼‰ã€‚

---

### 8.3 è«–æ–‡ï¼ˆSample2ï¼‰ã¨ã® â€œÎ±â€ å®šé‡æ¯”è¼ƒï¼ˆå…ˆç”Ÿå‘ã‘ãƒ¯ãƒ³ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰

ã“ã“ã§ã¯ã€æ¯”è¼ƒã—ã‚„ã™ã„ã‚ˆã†ã«ã€Œå¹³å‡ã€ã¨ã€Œæœ€å°ã€ã‚’ä¸¦ã¹ã‚‹ã€‚

* æœ¬å®Ÿé¨“ï¼ˆensembleï¼‰ã® **traitå¹³å‡Î± = 0.860**ï¼ˆ= (A,C,E,N,O)/5ï¼‰ã€**æœ€å°Î± = 0.782**ï¼ˆAï¼‰
* åŸè‘— Sample2 ã¯ **å¹³å‡Î±=0.88**ã€**æœ€å°Î±=0.70**ï¼ˆå…¨ãƒ¢ãƒ‡ãƒ«Ã—å…¨å°ºåº¦ã®æœ€å°ï¼‰
  ã€è«–æ–‡æ ¹æ‹ ï¼šSample2 å¹³å‡Î±=0.88 / æœ€å°Î±=0.70ã€‘

| Setting    | å¯¾è±¡                                                                      | Î±ã®é›†è¨ˆ                                     |   å¹³å‡Î± |   æœ€å°Î± |
| ---------- | ----------------------------------------------------------------------- | ---------------------------------------- | ----: | ----: |
| åŸè‘— Sample2 | nightly daily diariesï¼ˆN=108, IPIP-NEO-120ï¼‰                              | å…¨traitÃ—å…¨LLMå¹³å‡                            |  0.88 |  0.70 |
| æœ¬å®Ÿé¨“        | CEJCã€Œè‡ªå®…ãƒ»å°‘äººæ•°ã€Top1æ“¬ä¼¼ãƒ¢ãƒãƒ­ãƒ¼ã‚°ï¼ˆN=50, IPIP-NEO-120 æ—¥æœ¬èªç‰ˆ120é …ç›®, 4models ensembleï¼‰ | traitåˆ¥Î±ï¼ˆIPIP-NEO-120 120é …ç›®ã® ensemble ç³»åˆ—ï¼‰ | 0.860 | 0.782 |

è§£é‡ˆï¼ˆæ§ãˆã‚ãªä¸»å¼µï¼‰ï¼š

* **â€œdaily diaryãã®ã‚‚ã®â€ ã§ã¯ãªã„ï¼ˆä¼šè©±Top1æŠ½å‡ºï¼‰**ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ensembleå¾Œã® Î± ã¯ **åŸè‘— Sample2 ã®æ°´æº–ã«ã‹ãªã‚Šè¿‘ã„**ã€‚
* ãŸã ã—åŸè‘—ã¯ â€œself-report ç›¸é–¢â€ ãŒä¸»è©•ä¾¡ã®ãŸã‚ã€æ¬¡ã¯ãã“ã‚’æƒãˆã‚‹ã¨è­°è«–ãŒä¸€æ°—ã«å¼·ããªã‚‹ã€‚

---

### 8.4 ï¼ˆå‚è€ƒï¼‰åŸè‘—ã®ã€Œè¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¹³å‡ãŒå¼·ã„ã€ã¯ â€œç›¸é–¢ râ€ ã§ã‚‚ç¢ºèªã•ã‚Œã¦ã„ã‚‹

åŸè‘— Sample2 ã§ã¯ã€self-report ã¨ã®åæŸç›¸é–¢ã«ã¤ã„ã¦ï¼š

* å€‹åˆ¥LLMã® â€œç›¸é–¢å¹³å‡â€ ã¯ **0.37ã€œ0.45** ç¨‹åº¦
* **LLM average ã®å¹³å‡ç›¸é–¢ã¯ 0.44**
* ã•ã‚‰ã« â€œå…¨LLMÃ—å…¨trait ã®ç›¸é–¢å¹³å‡â€ ã¯ **r=0.415**ï¼ˆSample1/2ã§åŒä¸€ï¼‰
  ã€è«–æ–‡æ ¹æ‹ ï¼šSample2 ã®ç›¸é–¢å¹³å‡ãƒ¬ãƒ³ã‚¸ / LLM average=0.44 / r=0.415ã€‘

> æœ¬mdã¯ç›¸é–¢ï¼ˆå¤–éƒ¨åŸºæº–ï¼‰æœªæ¤œè¨¼ã ãŒã€ä»Šå› **Î±ãŒensembleã§æ”¹å–„**ã—ã¦ã„ã‚‹ã®ã¯ã€åŸè‘—ãŒè¿°ã¹ã‚‹ â€œwisdom of the crowdsï¼ˆè¤‡æ•°raterå¹³å‡ï¼‰â€ ã¨æ•´åˆçš„ã€‚

---

## 9) QCï¼ˆå†ç¾æ€§ãƒ»ç›£æŸ»ã®ãŸã‚ã®ãƒã‚§ãƒƒã‚¯ï¼‰

### 9.1 è¡Œæ•°ãƒ»fallback ã®æ¤œè¨¼ï¼ˆ4ãƒ¢ãƒ‡ãƒ«ã™ã¹ã¦OKï¼‰

* n_subjects = 50
* n_items = 120 â†’ æœŸå¾…è¡Œæ•°ã¯ 50Ã—120 = 6000 / ãƒ¢ãƒ‡ãƒ«

ä»¥ä¸‹ã®ã‚ˆã†ãªæ¤œè¨¼ã‚’å¿…ãšæ®‹ã™ï¼š

```bash
python - <<'PY'
import pandas as pd
from pathlib import Path

root = Path("artifacts/big5/llm_scores/dataset=cejc_diary_home_top1_v1__sha=a71b14ef__items=ipipneo120ja120")
items = pd.read_csv("artifacts/big5/items_ipipneo120_ja.csv")
n_items = len(items)

print("root =", root)
print("n_items =", n_items)
print()

for d in sorted(root.glob("model=*")):
    item_pq = d/"item_scores.parquet"
    if not item_pq.exists():
        continue

    df = pd.read_parquet(item_pq)
    n_subj = df[["conversation_id","speaker_id"]].drop_duplicates().shape[0]
    expected = n_subj * n_items
    n_rows = len(df)

    fb = 0
    for col in ["choice_raw","choice_norm"]:
        if col in df.columns:
            fb += int((df[col].astype(str)=="NEUTRAL_FALLBACK").sum())

    ok = (n_rows==expected and fb==0)
    print(d.name)
    print(f"  subjects={n_subj}  expected_rows={expected}  item_rows={n_rows}  fallback={fb}  OK={ok}")
PY
```

### 9.2 ensembleã® â€œn_models ãŒå¸¸ã«4â€ ã‚’ç¢ºèªï¼ˆç©´ãªã—ï¼‰

```bash
python - <<'PY'
import pandas as pd
from pathlib import Path

root = Path("artifacts/big5/llm_scores/dataset=cejc_diary_home_top1_v1__sha=a71b14ef__items=ipipneo120ja120")
ens = root/"ensemble=item_mean_4models"/"item_scores_ensemble_mean.parquet"
df = pd.read_parquet(ens)

print(df[["n_models"]].describe())
print("n_models_min =", df["n_models"].min())
PY
```

---

## 10) ç”Ÿæˆç‰©ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼‰

### 10.1 å˜ä½“ãƒ¢ãƒ‡ãƒ«

`artifacts/big5/llm_scores/dataset=cejc_diary_home_top1_v1__sha=a71b14ef__items=ipipneo120ja120/model=<MODEL_SAFE>/`

* `item_scores.parquet`
* `trait_scores.parquet`
* `cronbach_alpha.csv`

### 10.2 ensemble

`.../ensemble=item_mean_4models/`

* `item_scores_ensemble_mean.parquet`
* `trait_scores_ensemble_mean.parquet`
* `cronbach_alpha_ensemble_mean.csv`

---

## 11) Appendix Aï¼ˆ2026-02-15ï¼‰Smoke strict_v2ï¼šNEUTRAL_FALLBACK å¤šç™ºã®ä¿®æ­£ãƒ­ã‚°ï¼ˆè¨¼è·¡ï¼‰

> æœ¬ç•ªã® 120itemsÃ—50subjects ã¨ã¯åˆ¥ã«ã€åˆæœŸã® smoke å®Ÿè¡Œã§ç™ºç”Ÿã—ãŸä¸å…·åˆã®â€œåŸå› â†’å¯¾å‡¦â†’å¾©æ—§â€ã‚’æ®‹ã™ã€‚
> çµè«–ã¨ã—ã¦ã€æœ¬ç•ªç³»ï¼ˆÂ§8ã€œÂ§10ï¼‰ã¯ fallback=0 ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚

### A.1 äº‹è±¡ï¼ˆç—‡çŠ¶ï¼‰

smokeï¼ˆ120 items, 1 subjectï¼‰ã§ `NEUTRAL_FALLBACK` ãŒå¤§é‡ç™ºç”Ÿã€‚

* beforeï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— `item_scores.jsonl.bak`ï¼‰ï¼š`NEUTRAL_FALLBACK` **83/120**
* afterï¼ˆä¿®æ­£ç‰ˆ `item_scores.jsonl`ï¼‰ï¼š`NEUTRAL_FALLBACK` **0/120**

### A.2 åŸå› ï¼ˆroot causeï¼‰

`attempts.jsonl` ã«ä¿å­˜ã•ã‚Œã‚‹ `choice_raw / choice_norm` ãŒ **é€”ä¸­ã§åˆ‡ã‚Šæ¨ã¦ï¼ˆtruncateï¼‰**ã•ã‚Œã€
å›ºå®šé¸æŠè‚¢ã¨å®Œå…¨ä¸€è‡´ã›ãš `valid:false` æ‰±ã„ â†’ downstream ã§ fallback ã«ãªã£ã¦ã„ãŸã€‚

ä¾‹ï¼š

* æœ¬æ¥ `Neither Accurate nor Inaccurate` ãªã®ã« `Neither Accurate nor In` ã§åˆ‡ã‚Œã‚‹ã€ç­‰ã€‚

### A.3 å¯¾å‡¦ï¼ˆå¾©æ—§ï¼‰

* `attempts.jsonl` å´ã® `choice_*` ã‚’ **prefixä¸€è‡´ã§æ­£è¦åŒ–**ã—ã€
* `item_scores_fixed.* / trait_scores_fixed.* / cronbach_alpha_fixed.csv` ã‚’å†ç”Ÿæˆ
* çµæœã¨ã—ã¦ fallback ã‚’ 0 ã«å¾©æ—§

ï¼ˆè©³ç´°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€å½“è©² OUTDIR å†…ã«æ®‹ã—ã¦ã„ã‚‹ã‚‚ã®ã‚’å‚ç…§ï¼‰

---

## 12) Appendix Bï¼ˆ2026-02-16ï¼‰æœ¬ç•ªç³»ï¼šNaN 1ä»¶ï¼ˆGPT-OSS / item21ï¼‰ã®ä¿®å¾©ãƒ­ã‚°ï¼ˆbakä»˜ãï¼‰

### B.1 äº‹è±¡

* `ipipneo120ja120` æœ¬ç•ªç³»ã§ã€GPT-OSS ã® N trait ã« **NaN ãŒ1ä»¶**æ··å…¥
* è©²å½“ï¼š

  * `conversation_id=S001_011, speaker_id=IC02, item_id=21ï¼ˆNï¼‰, reverse=0`

ç—‡çŠ¶ï¼š

* 1è¡Œã ã‘ `choice_norm / score` ãŒ NaNï¼ˆchoice_raw ã«é•·ã„ãƒ­ã‚°ãŒæ··å…¥ã—ã¦ãƒ‘ãƒ¼ã‚¹ä¸èƒ½ã«ãªã£ãŸï¼‰

### B.2 å¯¾å‡¦æ–¹é‡ï¼ˆè«–æ–‡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«åˆã‚ã›ãŸæ‰±ã„ï¼‰

* ãã®1å•ã ã‘ã‚’ **å˜ç™ºã§å†å®Ÿè¡Œ**ã—ã¦ã€æ­£ã—ã„1è¡Œã‚’å¾—ã‚‹
* å…ƒ `item_scores.parquet` ã¯ **bak ã‚’æ®‹ã—ãŸä¸Šã§**ã€è©²å½“1è¡Œã ã‘å·®ã—æ›¿ãˆã‚‹
* ãã®å¾Œã€`trait_scores.parquet` ã¨ `cronbach_alpha.csv` ã‚’å†è¨ˆç®—

### B.3 è¨¼è·¡ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨æœ€çµ‚å‡ºåŠ›ï¼‰

ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒæ®‹ã£ã¦ã„ã‚‹ã“ã¨ï¼š

* `item_scores.parquet.bak_nanfix`ï¼ˆå­˜åœ¨ç¢ºèªOKï¼‰

ensemble å‡ºåŠ›ï¼š

* `cronbach_alpha_ensemble_mean.csv`
* `item_scores_ensemble_mean.parquet`
* `trait_scores_ensemble_mean.parquet`

### B.4 ä¿®å¾©æ‰‹é †ï¼ˆã‚³ãƒ”ãƒšç”¨ï¼š1å›ã§å®Œçµã™ã‚‹å®‰å…¨ç‰ˆï¼‰

> ã“ã“ã¯â€œå…ˆç”Ÿã«è¦‹ã›ã‚‹â€ã¨ã„ã†ã‚ˆã‚Šã€Œå†ç¾æ€§ãƒ»ç›£æŸ»ã€ã®ãŸã‚ã®ä½œæ¥­ãƒ­ã‚°ã€‚
> å¿…è¦ãªã‚‰ãã®ã¾ã¾å†å®Ÿè¡Œã§ãã‚‹å½¢ã«ã—ã¦ã‚ã‚‹ã€‚

```bash
cd ~/cpsy

python - <<'PY'
import pandas as pd
from pathlib import Path
import shutil

ROOT = Path("artifacts/big5/llm_scores/dataset=cejc_diary_home_top1_v1__sha=a71b14ef__items=ipipneo120ja120")
MODEL_DIR = ROOT/"model=openai.gpt-oss-120b-1_0"

orig_p = MODEL_DIR/"item_scores.parquet"
bak_p  = MODEL_DIR/"item_scores.parquet.bak_nanfix"

# å˜ç™ºå†å®Ÿè¡Œã§å¾—ãŸ â€œæ­£ã—ã„1è¡Œã ã‘â€ ã®parquetï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã§ç”Ÿæˆæ¸ˆã¿ã®ã‚‚ã®ã‚’æŒ‡å®šï¼‰
fix_p  = Path("artifacts/tmp_fix/out_item21_gptoss/item_scores.parquet")

# 1) fixãŒ1è¡Œã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
fix = pd.read_parquet(fix_p)
assert len(fix)==1, f"fix rows={len(fix)}"
r = fix.iloc[0]
assert r["conversation_id"]=="S001_011" and r["speaker_id"]=="IC02" and int(r["item_id"])==21, "fix row key mismatch"

# 2) ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæœªä½œæˆãªã‚‰ä½œã‚‹ï¼‰
if not bak_p.exists():
    shutil.copy2(orig_p, bak_p)

# 3) ç½®æ›ï¼ˆè©²å½“1è¡Œã‚’è½ã¨ã—ã¦fixã‚’è¿½åŠ ï¼‰
df = pd.read_parquet(orig_p)
key = (df["conversation_id"]=="S001_011") & (df["speaker_id"]=="IC02") & (df["item_id"]==21)
print("target_rows_in_orig =", int(key.sum()))
assert int(key.sum())==1, "target row not found or duplicated"

df2 = pd.concat([df[~key], fix], ignore_index=True)

# NaNãŒæ®‹ã£ã¦ãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆscoreï¼‰
na = int(df2["score"].isna().sum())
print("score_na_after_patch =", na)
assert na==0, "score NaN still exists after patch"

# 4) item_scores ã‚’æ›¸ãæˆ»ã—
df2.to_parquet(orig_p, index=False)

# 5) trait_scores å†ç”Ÿæˆ
trait = (df2.groupby(["conversation_id","speaker_id","trait"], as_index=False)
           .agg(trait_score=("score","mean")))
trait.to_parquet(MODEL_DIR/"trait_scores.parquet", index=False)

# 6) cronbach_alpha å†ç”Ÿæˆï¼ˆcomplete-caseï¼‰
def cronbach_alpha(wide: pd.DataFrame) -> float:
    wide = wide.dropna(axis=1, how="all").dropna(axis=0, how="any")
    k = wide.shape[1]
    if k < 2:
        return float("nan")
    item_vars = wide.var(axis=0, ddof=1)
    total_var = wide.sum(axis=1).var(ddof=1)
    if total_var == 0 or pd.isna(total_var):
        return float("nan")
    return (k/(k-1)) * (1 - item_vars.sum()/total_var)

rows=[]
for t in sorted(df2["trait"].unique()):
    sub = df2[df2["trait"]==t]
    wide = sub.pivot_table(index=["conversation_id","speaker_id"], columns="item_id", values="score")
    rows.append({
        "trait": t,
        "alpha": cronbach_alpha(wide),
        "n_subjects": wide.dropna(axis=0, how="any").shape[0],
        "k_items": wide.shape[1]
    })

alpha_df = pd.DataFrame(rows).sort_values("trait")
alpha_df.to_csv(MODEL_DIR/"cronbach_alpha.csv", index=False)

print("\n== updated cronbach_alpha ==")
print(alpha_df.to_string(index=False))
print("\nbackup =", bak_p)
PY
```

ä¿®å¾©å¾Œã®è©²å½“è¡Œï¼ˆä¾‹ï¼‰ï¼š

* `conversation_id=S001_011, speaker_id=IC02, item_id=21, trait=N`
* `choice_norm=Moderately Inaccurate, score=1.0`

---

## 13) ãƒ‡ãƒ¼ã‚¿å–ã‚Šæ‰±ã„ï¼ˆé‡è¦ï¼‰

* corpora ã®æœ¬æ–‡ï¼ˆç™ºè©±ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚„å¤§ããª parquet æœ¬ä½“ã¯ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãƒ»å®¹é‡ã®è¦³ç‚¹ã§ **git ç®¡ç†å¯¾è±¡ã«ã—ãªã„**
* git ã«æ®‹ã™ã®ã¯ **å†ç¾ã‚³ãƒãƒ³ãƒ‰ï¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼QCãƒ­ã‚°ï¼ã“ã®md** ã‚’ä¸­å¿ƒã«ã™ã‚‹
* æœ¬mdã§ã¯ **dataset sha** ã«ã‚ˆã‚Šã€å…¥åŠ›å›ºå®šã‚’æ˜ç¤ºã—ã¦ã„ã‚‹

---

## 14) CSJãƒãƒ£ãƒ¬ãƒ³ã‚¸ï¼ˆå¯¾è©±Dï¼‰: è‡ªç„¶å¯„ã‚Š side æŠ½å‡º â†’ Big5 æ¡ç‚¹ â†’ å®‰å®šæ€§/æ„Ÿåº¦åˆ†æï¼ˆN=6 â†’ N=36ï¼‰

### 14.0 ç›®çš„ï¼ˆCEJCã®æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

* CSJã® **å¯¾è©±ï¼ˆDï¼‰** ã‹ã‚‰ã€ï¼ˆå¯èƒ½ãªç¯„å›²ã§ï¼‰è‡ªç„¶å¯„ã‚Šã®ç™ºè©±ã‚’æŠ½å‡ºã—ã€
  IPIP-NEO-120ï¼ˆæ—¥æœ¬èª120é …ç›®ï¼‰ã‚’ **Bedrockè¤‡æ•°LLM** ã§æ¡ç‚¹ã—ã¦ Big5 ã‚’æ¨å®šã™ã‚‹ã€‚
* ã¾ãšã¯ **CSJã§ã‚‚ã€Œè¤‡æ•°ãƒ¢ãƒ‡ãƒ«å¹³å‡ï¼ˆensembleï¼‰ãŒå¼·ã„ã€**ãŒå‡ºã‚‹ã‹ã‚’ã€Cronbachâ€™s Î±ï¼ˆå†…éƒ¨ä¸€è²«æ€§ï¼‰ã§ç¢ºèªã™ã‚‹ã€‚
* è¿½åŠ ã§ã€

  * **ãƒ¢ãƒ‡ãƒ«æ„Ÿåº¦ï¼ˆleave-one-outï¼‰**ï¼šç‰¹å®šãƒ¢ãƒ‡ãƒ«ãŒÎ±ã‚’å£Šã—ã¦ã„ãªã„ã‹
  * **ç™ºè©±é‡ï¼ˆé•·ã•ï¼‰æ„Ÿåº¦ï¼ˆtop-k by n_charsï¼‰**ï¼šçŸ­ã„ç™ºè©±ã‚’æ··ãœã‚‹ã¨ã©ã®ç‰¹æ€§ãŒå´©ã‚Œã‚‹ã‹
    ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚

---

### 14.1 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾©

#### 14.1.1 Pilotï¼ˆN=6ï¼‰

* ç›®çš„ï¼šCSJã§ã‚‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå•é¡Œãªãå›ã‚Šã€ensembleã®æ”¹å–„ãŒè¦‹ãˆã‚‹ã‹ã‚’ **ä½ã‚³ã‚¹ãƒˆã§ç¢ºèª**
* ç”Ÿæˆæ¸ˆã¿å‡ºåŠ›ï¼ˆBig5ï¼‰rootï¼š

  * `artifacts/big5/llm_scores/dataset=csjD_side_v4_pass6_v1__sha=767447f2__items=ipipneo120ja120/`

#### 14.1.2 ix36 all sidesï¼ˆN=36ï¼‰

* ç›®çš„ï¼šCSJå´ã§ **æ¯æ•°ã‚’å¢—ã‚„ã—**ã€çµæœã®å®‰å®šæ€§ã‚’ç¢ºèª
* å¯¾è±¡ï¼š`metrics_interaction_csj_v1.parquet` ã«è¼‰ã£ã¦ã„ã‚‹ **18ä¼šè©±Ã—L/R = 36 side**
* å…¥åŠ›ï¼š

  * `artifacts/phase7/metrics_interaction_csj_v1.parquet`
  * `artifacts/_tmp_utt/csj_utterances/part-00000.parquet`
* monologues v1ï¼š

  * `artifacts/csj/monologues_csj_ix36_all_sides_v1.parquet`
  * sha256: `de3fd2e3734054a280fe3d4a01c6a0860f81855665a2a393e833757dcecf129d`
* ç™ºè©±é‡ï¼ˆå‚è€ƒï¼‰ï¼š

  * n_charsï¼ˆ36ä»¶ï¼‰: mean=3510 / median=2877 / max=7672ï¼ˆCEJCã‚ˆã‚ŠçŸ­ã‚ï¼‰
* å‡ºåŠ›ï¼ˆBig5ï¼‰rootï¼š

  * `artifacts/big5/llm_scores/dataset=csj_ix36_all_sides_v1__sha=de3fd2e3__items=ipipneo120ja120/`

---

### 14.2 å†ç¾æ‰‹é †ï¼ˆix36ï¼šmonologuesä½œæˆâ†’v1å›ºå®šï¼‰

#### 14.2.1 monologuesç”Ÿæˆï¼ˆ36 sideã‚’å…¨æ–‡é€£çµï¼‰

```bash
cd ~/cpsy
python - <<'PY'
import pandas as pd
from pathlib import Path

utt_path="artifacts/_tmp_utt/csj_utterances/part-00000.parquet"
ix_path ="artifacts/phase7/metrics_interaction_csj_v1.parquet"
out_parquet="artifacts/csj/monologues_csj_ix36_all_sides.parquet"

utt=pd.read_parquet(utt_path).copy()
utt["conversation_id"]=utt["conversation_id"].astype(str)
utt["speaker_id"]=utt["speaker_id"].astype(str)
utt["text"]=utt["text"].fillna("").astype(str)

ix=pd.read_parquet(ix_path).copy()
ix["conversation_id"]=ix["conversation_id"].astype(str)
ix["speaker_id"]=ix["speaker_id"].astype(str)

ids = ix[["conversation_id","speaker_id"]].drop_duplicates()

u=utt.merge(ids, on=["conversation_id","speaker_id"], how="inner").copy()
u=u.sort_values(["conversation_id","speaker_id","start_time","end_time"], kind="mergesort")

g=(u.groupby(["conversation_id","speaker_id"], as_index=False)
     .agg(n_utt=("text","count"),
          n_chars=("text", lambda s: int(sum(map(len, s.tolist())))),
          text=("text", lambda s: "\n".join(s.tolist()).strip())))

Path("artifacts/csj").mkdir(parents=True, exist_ok=True)
g.to_parquet(out_parquet, index=False)

prev=g.copy()
prev["head200"]=prev["text"].str.replace("\n"," ", regex=False).str.slice(0,200)
prev[["conversation_id","speaker_id","n_chars","n_utt","head200"]].to_csv(
    "artifacts/csj/monologues_csj_ix36_all_sides_preview.tsv", sep="\t", index=False
)

print("OK:", out_parquet, "rows=", len(g))
print("OK: artifacts/csj/monologues_csj_ix36_all_sides_preview.tsv")
print(g[["n_chars"]].describe().to_string())
PY
```

#### 14.2.2 v1å›ºå®šï¼ˆã‚³ãƒ”ãƒ¼ï¼‹sha256ä»˜ä¸ï¼‰

```bash
cd ~/cpsy
cp -a artifacts/csj/monologues_csj_ix36_all_sides.parquet \
      artifacts/csj/monologues_csj_ix36_all_sides_v1.parquet

python - <<'PY' | tee artifacts/csj/monologues_csj_ix36_all_sides_v1.sha256.txt
import hashlib, pathlib
p=pathlib.Path("artifacts/csj/monologues_csj_ix36_all_sides_v1.parquet")
print("sha256", hashlib.sha256(p.read_bytes()).hexdigest())
PY
```

---

### 14.3 Big5æ¡ç‚¹ï¼ˆix36ï¼š4ãƒ¢ãƒ‡ãƒ«Ã—120itemsï¼‰

```bash
cd ~/cpsy

MONO="artifacts/csj/monologues_csj_ix36_all_sides_v1.parquet"
ITEMS="artifacts/big5/items_ipipneo120_ja.csv"
ROOT="artifacts/big5/llm_scores"
SHA="de3fd2e3"

DATASET="dataset=csj_ix36_all_sides_v1__sha=${SHA}__items=ipipneo120ja120"
OUTROOT="$ROOT/$DATASET"

while IFS= read -r MODEL; do
  [ -z "$MODEL" ] && continue
  SAFE="$(echo "$MODEL" | tr ':/' '__')"
  OUTDIR="$OUTROOT/model=$SAFE"
  echo "== RUN $SAFE ($MODEL) =="

  python scripts/big5/score_big5_bedrock.py \
    --monologues_parquet "$MONO" \
    --items_csv "$ITEMS" \
    --model_id "$MODEL" \
    --region "ap-northeast-1" \
    --out_dir "$OUTDIR" \
  || exit 1
done < artifacts/big5/models.txt
```

---

### 14.4 çµæœï¼ˆPilot N=6ï¼‰

#### 14.4.1 4ãƒ¢ãƒ‡ãƒ«å¹³å‡ï¼ˆensembleï¼‰ Cronbachâ€™s Î±ï¼ˆN=6ï¼‰

| Ensemble(all4)    |        A |        C |        E |        N |        O |
| ----------------- | -------: | -------: | -------: | -------: | -------: |
| item_mean_4models | 0.541556 | 0.961744 | 0.843843 | 0.854445 | 0.720214 |

è¦³å¯Ÿï¼ˆN=6ã§ã‚‚è¦‹ãˆã‚‹ï¼‰ï¼š

* CSJã§ã‚‚ **ensembleã«ã‚ˆã‚Šå…¨ä½“ã«å®‰å®šåŒ–**ï¼ˆç‰¹ã« C/E/N/Oï¼‰ã€‚
* Aã¯ãªãŠå¼±ã„ãŒã€å˜ä½“ã§å‡ºãŸè² Î±ã¯å›é¿ã§ããŸï¼ˆãƒ¢ãƒ‡ãƒ«å¹³å‡ã®åŠ¹æœï¼‰ã€‚

---

### 14.5 çµæœï¼ˆix36 all sides N=36ï¼‰

#### 14.5.1 å˜ä½“ãƒ¢ãƒ‡ãƒ« Cronbachâ€™s Î±ï¼ˆN=36, k_items=24ï¼‰

| Model           |         A |        C |        E |        N |        O |
| --------------- | --------: | -------: | -------: | -------: | -------: |
| Qwen3-235B      | -0.178830 | 0.732876 | 0.805688 | 0.757652 | 0.747209 |
| Claude Sonnet 4 |  0.603728 | 0.906816 | 0.764628 | 0.839628 | 0.831913 |
| DeepSeek V3     |  0.326002 | 0.866219 | 0.756029 | 0.798751 | 0.799292 |
| GPT-OSS 120B    |  0.687978 | 0.923408 | 0.770580 | 0.893105 | 0.778073 |

è¦³å¯Ÿï¼š

* C/E/N/O ã¯æ¦‚ã­é«˜ã„ä¸€æ–¹ã€**Aã¯ãƒ¢ãƒ‡ãƒ«ä¾å­˜ãŒå¼·ã„**ï¼ˆQwenã§è² Î±ã€DeepSeekã§ã‚‚ä½ã‚ï¼‰ã€‚
* ix36 ã¯ n_chars ãŒçŸ­ã‚ï¼ˆmedian=2877ï¼‰ã§ã€Aã®æ‰‹ãŒã‹ã‚Šä¸è¶³ãŒå‡ºã‚„ã™ã„å¯èƒ½æ€§ã€‚

#### 14.5.2 ensemble(all4) Cronbachâ€™s Î±ï¼ˆN=36ï¼‰

| Ensemble(all4)    |        A |        C |        E |        N |        O |
| ----------------- | -------: | -------: | -------: | -------: | -------: |
| item_mean_4models | 0.590261 | 0.947658 | 0.869241 | 0.915664 | 0.883791 |

çµè«–ï¼š

* CSJ ix36 ã§ã‚‚ **ensembleã§é«˜ã„å†…éƒ¨ä¸€è²«æ€§**ï¼ˆC/E/N/Oã¯ç‰¹ã«é ‘å¥ï¼‰ã€‚
* Aã¯0.59ã¾ã§å›å¾©ã™ã‚‹ãŒã€ç›¸å¯¾çš„ã«ã¯å¼±ã„ã€‚

---

### 14.6 æ„Ÿåº¦åˆ†æï¼ˆleave-one-outï¼šã©ã®ãƒ¢ãƒ‡ãƒ«ãŒåŠ¹ã„ã¦ã„ã‚‹ã‹ï¼‰

å‡ºåŠ›ï¼š`ensemble_leave1out_alpha.tsv`

| variant       |            A |        C |        E |        N |        O |
| ------------- | -----------: | -------: | -------: | -------: | -------: |
| all4          |     0.590261 | 0.947658 | 0.869241 | 0.915664 | 0.883791 |
| drop DeepSeek |     0.624589 | 0.946937 | 0.841302 | 0.914533 | 0.874604 |
| drop Claude   |     0.581409 | 0.933294 | 0.859361 | 0.897980 | 0.865850 |
| drop GPT-OSS  | **0.372993** | 0.925835 | 0.860233 | 0.886028 | 0.869685 |
| drop Qwen     | **0.630030** | 0.945168 | 0.852622 | 0.911565 | 0.869690 |

è¦ç‚¹ï¼ˆç‰¹ã«Aï¼‰ï¼š

* **GPT-OSSã‚’æŠœãã¨AãŒå¤§ããæ‚ªåŒ–ï¼ˆ0.373ï¼‰** â†’ Aã®å®‰å®šåŒ–ã« GPT-OSS ãŒå¼·ãå¯„ä¸
* **Qwenã‚’æŠœãã¨AãŒæ”¹å–„ï¼ˆ0.630ï¼‰** â†’ Qwenã¯Aã‚’å£Šã—æ°—å‘³
* C/E/N/O ã¯ drop ã—ã¦ã‚‚å¤§ããã¯å‹•ã‹ãšã€**ãƒ¢ãƒ‡ãƒ«æ··åˆã«é ‘å¥**

---

### 14.7 ç™ºè©±é‡ï¼ˆé•·ã•ï¼‰æ„Ÿåº¦ï¼ˆtop-k by n_charsï¼š25/50/75/100%ï¼‰

å‡ºåŠ›ï¼š`ensemble_alpha_by_topk_chars.tsv`
å®šç¾©ï¼šix36ã‚’ n_chars é™é †ã«ä¸¦ã¹ã€top9/top18/top27/top36ï¼ˆ=25/50/75/100%ï¼‰ã§ ensemble Î± ã‚’ç®—å‡ºã€‚

| topk |        A |        C |        E |        N |        O |
| ---: | -------: | -------: | -------: | -------: | -------: |
|    9 | 0.754656 | 0.945333 | 0.805720 | 0.888911 | 0.844351 |
|   18 | 0.678777 | 0.932697 | 0.851317 | 0.930902 | 0.839405 |
|   27 | 0.635316 | 0.937458 | 0.855933 | 0.914748 | 0.843385 |
|   36 | 0.590261 | 0.947658 | 0.869241 | 0.915664 | 0.883791 |

è¦³å¯Ÿï¼ˆé‡è¦ï¼‰ï¼š

* C/E/N/O ã¯ topk ã‚’å¢—ã‚„ã—ã¦ã‚‚æ¦‚ã­å®‰å®šã€‚
* **Aã ã‘ãŒ topkå¢—åŠ ã§å˜èª¿ã«ä½ä¸‹ï¼ˆ0.755â†’0.590ï¼‰**ã€‚

  * ä»Šå›ã®â€œå¢—ã‚„ã™â€ã¯ã€ŒçŸ­ã„ç™ºè©±ã‚’è¿½åŠ ã—ã¦ã„ã‚‹ã€ãŸã‚ã€
    **çŸ­ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’æ··ãœã‚‹ã»ã© A ã®æ‰‹ãŒã‹ã‚Šä¸è¶³ã§é …ç›®é–“æ•´åˆãŒå´©ã‚Œã€Î±ãŒä¸‹ãŒã‚‹**å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚

---

### 14.8 CSJã®QCï¼ˆå†ç¾æ€§ãƒ»ç›£æŸ»ï¼‰

ï¼ˆCEJCã¨åŒå‹ã€‚æœŸå¾…è¡Œæ•°ã¯ N_subjectsÃ—120ï¼‰

```bash
python - <<'PY'
import pandas as pd
from pathlib import Path

root = Path("artifacts/big5/llm_scores/dataset=csj_ix36_all_sides_v1__sha=de3fd2e3__items=ipipneo120ja120")
items = pd.read_csv("artifacts/big5/items_ipipneo120_ja.csv")
n_items = len(items)

print("root =", root)
print("n_items =", n_items)
print()

for d in sorted(root.glob("model=*")):
    item_pq = d/"item_scores.parquet"
    if not item_pq.exists():
        continue

    df = pd.read_parquet(item_pq)
    n_subj = df[["conversation_id","speaker_id"]].drop_duplicates().shape[0]
    expected = n_subj * n_items
    n_rows = len(df)

    fb = 0
    for col in ["choice_raw","choice_norm"]:
        if col in df.columns:
            fb += int((df[col].astype(str)=="NEUTRAL_FALLBACK").sum())

    ok = (n_rows==expected and fb==0)
    print(d.name)
    print(f"  subjects={n_subj}  expected_rows={expected}  item_rows={n_rows}  fallback={fb}  OK={ok}")
PY
```

---

### 14.9 ã“ã“ã¾ã§ã®æš«å®šçµè«–ï¼ˆå…ˆç”Ÿå‘ã‘ãƒ¯ãƒ³ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰

* CSJï¼ˆå¯¾è©±D, sideæ“¬ä¼¼ãƒ¢ãƒãƒ­ãƒ¼ã‚°ï¼‰ã§ã‚‚ã€
  **4ãƒ¢ãƒ‡ãƒ«å¹³å‡ï¼ˆensembleï¼‰ã§å†…éƒ¨ä¸€è²«æ€§ãŒä¸ŠãŒã‚Šã€C/E/N/Oã¯é«˜Î±ã§é ‘å¥**ã€‚
* ä¸€æ–¹ **Aï¼ˆå”èª¿æ€§ï¼‰ã¯ãƒ¢ãƒ‡ãƒ«ä¾å­˜ãƒ»ç™ºè©±é‡ä¾å­˜ãŒå¼·ã„**ï¼š

  * leave-one-outã§ **GPT-OSSã‚’æŠœãã¨AãŒå¤§å¹…æ‚ªåŒ–**ã€**Qwenã‚’æŠœãã¨æ”¹å–„**
  * topkï¼ˆé•·ã„â†’çŸ­ã„ã‚’è¿½åŠ ï¼‰ã§ **Aã®ã¿å˜èª¿ä½ä¸‹**
* æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€CSJå´ã§

  * **n_charsä¸‹é™ï¼ˆä¾‹ï¼š>=5000 or >=6000ï¼‰ã§å†å®šç¾©**ã—ã¦AãŒæŒã¡ä¸ŠãŒã‚‹ã‹ç¢ºèª
  * CSJå…¨ä½“ã‹ã‚‰ **N=50ã€œ100** ã‚’æ§‹ç¯‰ã—ã€CEJCã¨åŒç¨‹åº¦ã®ç™ºè©±é‡ã§æ¯”è¼ƒ
  * Aã«ã¤ã„ã¦ã¯ **ãƒ¢ãƒ‡ãƒ«æ··åˆã®æ–¹é‡ï¼ˆä¾‹ï¼šQwené™¤å¤–3ãƒ¢ãƒ‡ãƒ«å¹³å‡ã‚‚ä½µè¨˜ï¼‰**ã‚’æ¤œè¨
    ãŒå„ªå…ˆã€‚

---

### 14.10 CSJç”Ÿæˆç‰©ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼‰

#### 14.10.1 monologues

* `artifacts/csj/monologues_csj_ix36_all_sides.parquet`
* `artifacts/csj/monologues_csj_ix36_all_sides_preview.tsv`
* `artifacts/csj/monologues_csj_ix36_all_sides_v1.parquet`
* `artifacts/csj/monologues_csj_ix36_all_sides_v1.sha256.txt`

#### 14.10.2 Big5ï¼ˆå˜ä½“ãƒ¢ãƒ‡ãƒ«ï¼‰

`artifacts/big5/llm_scores/dataset=csj_ix36_all_sides_v1__sha=de3fd2e3__items=ipipneo120ja120/model=<MODEL_SAFE>/`

* `item_scores.parquet`
* `trait_scores.parquet`
* `cronbach_alpha.csv`

#### 14.10.3 Big5ï¼ˆensembleï¼‹åˆ†æï¼‰

`.../ensemble=item_mean_4models/`

* `item_scores_ensemble_mean.parquet`
* `trait_scores_ensemble_mean.parquet`
* `cronbach_alpha_ensemble_mean.csv`
* `ensemble_leave1out_alpha.tsv`
* `ensemble_alpha_by_topk_chars.tsv`

