# -*- coding: utf-8 -*-
import os, csv, hashlib, yaml, math, statistics, re
import pandas as pd
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from .cha_utils import iter_utterances
from .jp_tokenizer import JapaneseTokenizer
from .build_windows import nine_minute_window
from .pragmatics_ja import analyze_pragmatics

import re

def parse_age_months(cha_path: str) -> Optional[float]:
    """
    Robustly parse child age in months.
    1) Prefer '@Age: Y;MM.DD'
    2) Fallback: '@ID: ...|CHI|<AGE>|...' -> use the field right after 'CHI'
    Returns float months or None.
    """
    def _age_to_months(age: str) -> Optional[float]:
        age = age.strip()
        if ";" not in age:
            return None
        ys, rest = age.split(";", 1)
        try:
            y = int(ys)
        except Exception:
            return None
        m = d = 0
        if "." in rest:
            ms, ds = rest.split(".", 1)
            try: m = int(ms)
            except: m = 0
            try: d = int(re.sub(r"[^0-9]", "", ds))
            except: d = 0
        else:
            nums = re.sub(r"[^0-9]", "", rest)
            m = int(nums) if nums else 0
        return y*12 + m + d/30.0

    try:
        # 1) @Age: があれば最優先
        with open(cha_path, "r", encoding="utf-8", errors="ignore") as f:
            for line in f:
                if line.startswith("@Age:"):
                    m = AGE_LINE_RE.search(line)
                    if m:
                        y = int(m.group(1)); mo = int(m.group(2)); d = int(m.group(3) or 0)
                        return y*12 + mo + d/30.0

        # 2) @ID: の CHI の直後フィールド（=年齢）を分割で取得
        with open(cha_path, "r", encoding="utf-8", errors="ignore") as f:
            for line in f:
                if line.startswith("@ID:") and "|CHI|" in line:
                    parts = line.split("|")
                    # 例: ['@ID:\tjpn','MiiPro','CHI','1;01.29','female',...]
                    try:
                        idx = next(i for i,v in enumerate(parts) if v.strip()=="CHI")
                    except StopIteration:
                        continue
                    if idx+1 < len(parts):
                        val = _age_to_months(parts[idx+1])
                        if val is not None:
                            return val
    except Exception:
        return None
    return None


@dataclass
class SessionResult:
    child_id: str
    file: str
    age_months: Optional[float]
    n_utts_child_win: int
    n_tokens_child: int
    n_types_child: int
    mlu_child: float
    n_utts_parent_win: int
    n_tokens_parent: int
    n_types_parent: int
    mlu_parent: float
    chi_utt_low: bool = False

def read_yaml(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def md5_of_file(path: str) -> str:
    h = hashlib.md5()
    with open(path, "rb") as f:
        for b in iter(lambda: f.read(8192), b""):
            h.update(b)
    return h.hexdigest()

def load_fillers(path: str) -> set:
    s = set()
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                t = line.strip()
                if t:
                    s.add(t)
    return s

# Age parsing supports both @Age and @ID lines
AGE_ID_RE = re.compile(r"@ID:\s*CHI\|[^|]*\|[^|]*\|([^|]*)\|")
AGE_LINE_RE = re.compile(r"@Age:\s*([0-9]+);([0-9]{1,2})(?:\.([0-9]{1,2}))?")

def parse_age_months(cha_path: str) -> Optional[float]:
    try:
        with open(cha_path, "r", encoding="utf-8", errors="ignore") as f:
            txt = f.read()
        m = AGE_LINE_RE.search(txt)
        if m:
            y = int(m.group(1)); mo = int(m.group(2)); d = int(m.group(3) or 0)
            return y*12 + mo + d/30.0
        for line in txt.splitlines():
            if not line.startswith("@ID:"):
                continue
            m2 = AGE_ID_RE.search(line)
            if not m2:
                continue
            age = m2.group(1).strip()
            if ";" in age:
                ys, rest = age.split(";", 1)
                try: y = int(ys)
                except: y = 0
                ms = 0; ds = 0
                if "." in rest:
                    ms_s, ds_s = rest.split(".", 1)
                    try: ms = int(ms_s)
                    except: ms = 0
                    try: ds = int(re.sub(r"[^0-9]", "", ds_s))
                    except: ds = 0
                else:
                    nums = re.sub(r"[^0-9]", "", rest)
                    ms = int(nums) if nums else 0
                return y*12 + ms + ds/30.0
            return None
    except Exception:
        return None
    return None

def metrics_for_window(texts: List[str], tok: JapaneseTokenizer) -> Tuple[int,int,float,List[str]]:
    tokens_all: List[str] = []
    filler_hits_all: List[str] = []
    for ut in texts:
        lemmas, fillers = tok.tokenize_lemmas(ut)
        tokens_all.extend(lemmas)
        filler_hits_all.extend(fillers)
    n_tokens = len(tokens_all)
    n_types = len(set(tokens_all))
    mlu = (n_tokens/len(texts)) if texts else 0.0
    return n_tokens, n_types, mlu, filler_hits_all

def process_file(path: str, cfg: dict, tok: JapaneseTokenizer, log_rows: List[Dict],
                 min_utt_child: int, drop_if_below: bool,
                 dropped_rows: List[Dict], prag_rows: List[Dict]) -> Optional[SessionResult]:
    utts = iter_utterances(path)
    child_id = os.path.basename(path).split(".")[0]
    tiers = cfg["tiers"]
    child_tags = set(tiers.get("child", ["CHI"]))
    parent_tags = set(tiers.get("parent", ["MOT","MOM","FAT","FTH","FA","PAR"]))

    win = nine_minute_window(utts, child_tags, minutes=cfg["window"]["minutes"], assume_session_minutes=cfg["window"]["assume_session_minutes"])
    if win.end_idx < win.start_idx:
        return None

    chi_utts_text = [u.text for u in utts[win.start_idx:win.end_idx+1] if u.speaker in child_tags]
    par_utts_text = [u.text for u in utts[win.start_idx:win.end_idx+1] if u.speaker in parent_tags]

    n_tok_c, n_typ_c, mlu_c, fillers_c = metrics_for_window(chi_utts_text, tok)
    n_tok_p, n_typ_p, mlu_p, fillers_p = metrics_for_window(par_utts_text, tok)

    # Pragmatics for CHI & Parent
    pr_c = analyze_pragmatics(chi_utts_text, tok)
    pr_p = analyze_pragmatics(par_utts_text, tok)
    prag_rows.append({
        "file": os.path.basename(path), "child_id": child_id, "role": "CHI",
        "n_utts": pr_c.n_utts, "n_tokens": pr_c.n_tokens,
        "question_utts": pr_c.q_utts, "question_rate": pr_c.q_rate,
        "dm_hits": pr_c.dm_hits, "dm_per_100t": pr_c.dm_per_100t,
        "mental_hits": pr_c.mental_hits, "mental_per_100t": pr_c.mental_per_100t
    })
    prag_rows.append({
        "file": os.path.basename(path), "child_id": child_id, "role": "PARENT",
        "n_utts": pr_p.n_utts, "n_tokens": pr_p.n_tokens,
        "question_utts": pr_p.q_utts, "question_rate": pr_p.q_rate,
        "dm_hits": pr_p.dm_hits, "dm_per_100t": pr_p.dm_per_100t,
        "mental_hits": pr_p.mental_hits, "mental_per_100t": pr_p.mental_per_100t
    })

    if fillers_c or fillers_p:
        log_rows.append({"file": os.path.basename(path),
                         "fillers_child": "|".join(fillers_c),
                         "fillers_parent": "|".join(fillers_p)})

    chi_utt_low = len(chi_utts_text) < int(min_utt_child) if min_utt_child else False
    if drop_if_below and chi_utt_low:
        dropped_rows.append({
            "file": os.path.basename(path),
            "child_id": child_id,
            "reason": f"CHI_utts<{min_utt_child}",
            "n_utts_child_win": len(chi_utts_text),
            "n_tokens_child": n_tok_c,
            "n_types_child": n_typ_c,
            "mlu_child": mlu_c
        })
        return None

    age_months = parse_age_months(path)

    return SessionResult(child_id=child_id, file=os.path.basename(path), age_months=age_months,
                         n_utts_child_win=len(chi_utts_text), n_tokens_child=n_tok_c, n_types_child=n_typ_c, mlu_child=mlu_c,
                         n_utts_parent_win=len(par_utts_text), n_tokens_parent=n_tok_p, n_types_parent=n_typ_p, mlu_parent=mlu_p,
                         chi_utt_low=chi_utt_low)

def walk_cha_files(root: str) -> List[str]:
    out = []
    for d, _, files in os.walk(root):
        for fn in files:
            if fn.endswith(".cha"):
                out.append(os.path.join(d, fn))
    return sorted(out)

def hedges_g(m1, s1, n1, m2, s2, n2):
    sp2 = (((n1-1)*(s1**2)) + ((n2-1)*(s2**2))) / (n1 + n2 - 2) if (n1+n2-2) > 0 else 0.0
    sp = math.sqrt(sp2) if sp2 > 0 else 0.0
    d = (m1 - m2) / sp if sp > 0 else 0.0
    J = 1 - (3/(4*(n1+n2)-9)) if (n1+n2) > 2 else 1.0
    return d * J

def run(config_path: str):
    cfg = read_yaml(config_path)
    os.makedirs(cfg["output"]["outdir"], exist_ok=True)

    fillers = load_fillers(cfg["lexicon"]["filler_path"])
    tok = JapaneseTokenizer(filler_set=fillers)

    files = walk_cha_files(cfg["corpus_dir"])

    filters = cfg.get("filters", {})
    min_utt_child = int(filters.get("min_utt_child", 0) or 0)
    drop_if_below = bool(filters.get("drop_if_below_min_child_utts", False))

    results: List[SessionResult] = []
    filler_log: List[Dict] = []
    dropped_rows: List[Dict] = []
    prag_rows: List[Dict] = []

    for p in files:
        r = process_file(p, cfg, tok, filler_log, min_utt_child, drop_if_below, dropped_rows, prag_rows)
        if r:
            results.append(r)

    outdir = cfg["output"]["outdir"]

    # session-level CSV (included only)
    sess_csv = os.path.join(outdir, "jp_sessions.csv")
    with open(sess_csv, "w", encoding="utf-8", newline="") as f:
        w = csv.writer(f)
        w.writerow(["file","child_id","age_months",
                    "n_utts_child_win","n_tokens_child","n_types_child","mlu_child",
                    "n_utts_parent_win","n_tokens_parent","n_types_parent","mlu_parent",
                    "chi_utt_low"])
        for r in results:
            w.writerow([r.file, r.child_id, f"{r.age_months:.2f}" if r.age_months is not None else "",
                        r.n_utts_child_win, r.n_tokens_child, r.n_types_child, f"{r.mlu_child:.6f}",
                        r.n_utts_parent_win, r.n_tokens_parent, r.n_types_parent, f"{r.mlu_parent:.6f}",
                        int(r.chi_utt_low)])

    # Pragmatics CSV (all sessions, both roles; 透明性のため dropped も含む)
    prag_csv = os.path.join(outdir, "jp_pragmatics.csv")
    if prag_rows:
        pd.DataFrame(prag_rows).to_csv(prag_csv, index=False)

    # dropped log
    dropped_csv = os.path.join(outdir, "jp_dropped.csv")
    if dropped_rows:
        pd.DataFrame(dropped_rows).to_csv(dropped_csv, index=False)

    # descriptives (included only)
    def col(lst, attr): return [getattr(x, attr) for x in results if getattr(x, attr) is not None]
    def desc(vals):
        return {"n": len(vals),
                "mean": (sum(vals)/len(vals) if vals else 0.0),
                "sd": (statistics.pstdev(vals) if len(vals)>1 else 0.0),
                "min": (min(vals) if vals else 0.0),
                "max": (max(vals) if vals else 0.0)}

    desc_rows = [
        {"metric":"CHI_MLU", **desc(col(results,"mlu_child"))},
        {"metric":"CHI_NDW(types)", **desc(col(results,"n_types_child"))},
        {"metric":"CHI_Tokens", **desc(col(results,"n_tokens_child"))},
        {"metric":"MOT_MLU", **desc(col(results,"mlu_parent"))},
        {"metric":"MOT_Types", **desc(col(results,"n_types_parent"))},
        {"metric":"MOT_Tokens", **desc(col(results,"n_tokens_parent"))},
    ]
    desc_csv = os.path.join(outdir, "jp_descriptives.csv")
    pd.DataFrame(desc_rows).to_csv(desc_csv, index=False)

    # Age bins (included only, CHI)
    bins = cfg.get("age_bins", [24,36,48,60,72,84])  # months
    edges = list(bins)
    age_rows = []
    for r in results:
        a = r.age_months
        label = "NA"
        if a is not None and len(edges) >= 2:
            for i in range(len(edges)-1):
                if a >= edges[i] and a < edges[i+1]:
                    label = f"[{edges[i]}-{edges[i+1]})"
                    break
            else:
                if a >= edges[-1]:
                    label = f">={edges[-1]}"
        age_rows.append({"bin": label, "mlu_child": r.mlu_child, "ndw_child": r.n_types_child})
    if age_rows:
        df_age = pd.DataFrame(age_rows)
        df_age_desc = df_age.groupby("bin").agg(n=("mlu_child","count"),
                                                CHI_MLU_mean=("mlu_child","mean"),
                                                CHI_MLU_sd=("mlu_child","std"),
                                                CHI_NDW_mean=("ndw_child","mean"),
                                                CHI_NDW_sd=("ndw_child","std")).reset_index()
        df_age_desc.to_csv(os.path.join(outdir, "jp_age_bins.csv"), index=False)

    # meta: overall Hedges g for MOT vs CHI MLU (included only)
    m1 = desc_rows[3]["mean"]; s1 = desc_rows[3]["sd"]; n1 = desc_rows[3]["n"]
    m2 = desc_rows[0]["mean"]; s2 = desc_rows[0]["sd"]; n2 = desc_rows[0]["n"]
    g = 0.0
    try:
        sp2 = (((n1-1)*(s1**2)) + ((n2-1)*(s2**2))) / (n1 + n2 - 2) if (n1+n2-2) > 0 else 0.0
        sp = math.sqrt(sp2) if sp2 > 0 else 0.0
        d = (m1 - m2) / sp if sp > 0 else 0.0
        J = 1 - (3/(4*(n1+n2)-9)) if (n1+n2) > 2 else 1.0
        g = d * J
    except Exception:
        g = 0.0
    if n1>1 and n2>1:
        vg = (n1+n2)/(n1*n2) + (g**2)/(2*(n1+n2-2))
    else:
        vg = float("inf")

    meta_rows = [{
        "contrast": "MOT_MLU - CHI_MLU (Hedges g)",
        "g": g,
        "se": math.sqrt(vg) if vg!=float("inf") else float("nan"),
        "ci95_lo": g - 1.96*math.sqrt(vg) if vg!=float("inf") else float("nan"),
        "ci95_hi": g + 1.96*math.sqrt(vg) if vg!=float("inf") else float("nan"),
        "n_sessions": len(results),
        "dropped_n": len(dropped_rows),
        "min_utt_child": min_utt_child,
        "drop_if_below": int(drop_if_below)
    }]
    meta_csv = os.path.join(outdir, "jp_meta.csv")
    pd.DataFrame(meta_rows).to_csv(meta_csv, index=False)

    if filler_log:
        pd.DataFrame(filler_log).to_csv(os.path.join(outdir, "filler_hits.csv"), index=False)

    # dashboard
    dash_path = cfg["output"]["dashboard_html"]
    os.makedirs(os.path.dirname(dash_path), exist_ok=True)

    def md5_str(p):
        return (md5_of_file(p)[:10] if os.path.exists(p) else "NA")

    df_sess = pd.read_csv(sess_csv) if os.path.exists(sess_csv) else pd.DataFrame()
    df_desc = pd.read_csv(desc_csv) if os.path.exists(desc_csv) else pd.DataFrame()
    df_meta = pd.read_csv(meta_csv) if os.path.exists(meta_csv) else pd.DataFrame()
    df_drop = pd.read_csv(os.path.join(outdir,"jp_dropped.csv")) if os.path.exists(os.path.join(outdir,"jp_dropped.csv")) else pd.DataFrame()
    df_prag = pd.read_csv(os.path.join(outdir,"jp_pragmatics.csv")) if os.path.exists(os.path.join(outdir,"jp_pragmatics.csv")) else pd.DataFrame()
    df_agebin = pd.read_csv(os.path.join(outdir,"jp_age_bins.csv")) if os.path.exists(os.path.join(outdir,"jp_age_bins.csv")) else pd.DataFrame()

    import html as hmod
    html = f"""<!doctype html><meta charset='utf-8'>
<style>
body {{ font-family: -apple-system, BlinkMacSystemFont, "Hiragino Kaku Gothic ProN", Meiryo, Roboto, Arial, sans-serif; margin:24px; }}
h1 {{ font-size: 22px; margin: 0 0 12px; }}
h2 {{ font-size: 18px; margin: 18px 0 8px; }}
.tbl {{ border-collapse: collapse; width: 100%; margin: 6px 0 16px; font-size: 13px; }}
.tbl th, .tbl td {{ border: 1px solid #ddd; padding: 6px 8px; text-align: right; }}
.tbl th {{ background: #f6f6f6; text-align: center; }}
.tbl td:first-child, .tbl th:first-child {{ text-align: left; }}
.small {{ font-size: 12px; color:#666; }}
.badge {{ display:inline-block; padding:2px 6px; border-radius:6px; background:#eee; margin-left:6px; }}
.warn {{ background:#ffe0cc; }}
.ok {{ background:#e6f5e6; }}
</style>
<h1>MiiPro 日本語 9分窓ダッシュボード（JP, しきい＋年齢＋語用論）</h1>
<div class="small">短単位語（UniDic）× lemma 集計。フィラー除外。親（MOT等）と子（CHI）を同一窓で評価。</div>
<div class="small">フィルター: min_utt_child={min_utt_child}, drop_if_below={drop_if_below} / included={len(df_sess)} <span class='badge warn'>dropped={len(df_drop)}</span></div>
"""

    # Sessions
    html += """<h2>セッション集計（9分窓, included only）</h2>
<table class="tbl">
<thead><tr><th>file</th><th>age_mo</th><th>CHI utt</th><th>CHI tokens</th><th>CHI types(NDW)</th><th>CHI MLU</th><th>MOT utt</th><th>MOT tokens</th><th>MOT types</th><th>MOT MLU</th><th>CHI_utt_low</th></tr></thead>
<tbody>
"""
    for _, row in df_sess.head(200).iterrows():
        html += "<tr>" + "".join([
            f"<td>{hmod.escape(str(row['file']))}</td>",
            f"<td>{hmod.escape(str(row['age_months']))}</td>",
            f"<td>{int(row['n_utts_child_win'])}</td>",
            f"<td>{int(row['n_tokens_child'])}</td>",
            f"<td>{int(row['n_types_child'])}</td>",
            f"<td>{float(row['mlu_child']):.3f}</td>",
            f"<td>{int(row['n_utts_parent_win'])}</td>",
            f"<td>{int(row['n_tokens_parent'])}</td>",
            f"<td>{int(row['n_types_parent'])}</td>",
            f"<td>{float(row['mlu_parent']):.3f}</td>",
            f"<td>{int(row['chi_utt_low'])}</td>",
        ]) + "</tr>\n"
    html += "</tbody></table>"

    # Descriptives
    html += """<h2>記述統計（included only）</h2>
<table class="tbl">
<thead><tr><th>metric</th><th>n</th><th>mean</th><th>sd</th><th>min</th><th>max</th></tr></thead>
<tbody>
"""
    for _, row in df_desc.iterrows():
        html += "<tr>" + "".join([
            f"<td>{hmod.escape(str(row['metric']))}</td>",
            f"<td>{int(row['n'])}</td>",
            f"<td>{float(row['mean']):.3f}</td>",
            f"<td>{float(row['sd']):.3f}</td>",
            f"<td>{float(row['min']):.3f}</td>",
            f"<td>{float(row['max']):.3f}</td>",
        ]) + "</tr>\n"
    html += "</tbody></table>"

    # Meta
    html += """<h2>メタ解析（MOT MLU − CHI MLU, included only）</h2>
<table class="tbl">
<thead><tr><th>contrast</th><th>g</th><th>se</th><th>95% CI lo</th><th>95% CI hi</th><th>n_sessions</th><th>dropped</th></tr></thead>
<tbody>
"""
    for _, row in df_meta.iterrows():
        html += "<tr>" + "".join([
            f"<td>{hmod.escape(str(row['contrast']))}</td>",
            f"<td>{float(row['g']):.3f}</td>",
            f"<td>{float(row['se']) if not pd.isna(row['se']) else float('nan'):.3f}</td>",
            f"<td>{float(row['ci95_lo']) if not pd.isna(row['ci95_lo']) else float('nan'):.3f}</td>",
            f"<td>{float(row['ci95_hi']) if not pd.isna(row['ci95_hi']) else float('nan'):.3f}</td>",
            f"<td>{int(row['n_sessions'])}</td>",
            f"<td>{int(row['dropped_n'])}</td>",
        ]) + "</tr>\n"
    html += "</tbody></table>"

    # Age bins table
    df_agebin_path = os.path.join(outdir,"jp_age_bins.csv")
    if os.path.exists(df_agebin_path):
        for_age = pd.read_csv(df_agebin_path)
        if not for_age.empty:
            html += """<h2>年齢バケット別（CHI, included only）</h2>
<table class="tbl">
<thead><tr><th>bin</th><th>n</th><th>CHI_MLU_mean</th><th>CHI_MLU_sd</th><th>CHI_NDW_mean</th><th>CHI_NDW_sd</th></tr></thead>
<tbody>
"""
            for _, row in for_age.iterrows():
                html += "<tr>" + "".join([
                    f"<td>{hmod.escape(str(row['bin']))}</td>",
                    f"<td>{int(row['n'])}</td>",
                    f"<td>{float(row['CHI_MLU_mean']):.3f}</td>",
                    f"<td>{(float(row['CHI_MLU_sd']) if not pd.isna(row['CHI_MLU_sd']) else float('nan')):.3f}</td>",
                    f"<td>{float(row['CHI_NDW_mean']):.3f}</td>",
                    f"<td>{(float(row['CHI_NDW_sd']) if not pd.isna(row['CHI_NDW_sd']) else float('nan')):.3f}</td>",
                ]) + "</tr>\n"
            html += "</tbody></table>"

    # Pragmatics summary
    if not df_prag.empty:
        df_sum = df_prag.groupby("role").agg(
            n=("file","count"),
            q_rate_mean=("question_rate","mean"),
            dm_per100t_mean=("dm_per_100t","mean"),
            mental_per100t_mean=("mental_per_100t","mean")
        ).reset_index()
        html += """<h2>語用論サマリ（CHI/PARENT）</h2>
<table class="tbl">
<thead><tr><th>role</th><th>n</th><th>question_rate</th><th>dm_per_100t</th><th>mental_per_100t</th></tr></thead>
<tbody>
"""
        for _, row in df_sum.iterrows():
            html += "<tr>" + "".join([
                f"<td>{hmod.escape(str(row['role']))}</td>",
                f"<td>{int(row['n'])}</td>",
                f"<td>{float(row['q_rate_mean']):.3f}</td>",
                f"<td>{float(row['dm_per100t_mean']):.2f}</td>",
                f"<td>{float(row['mental_per100t_mean']):.2f}</td>",
            ]) + "</tr>\n"
        html += "</tbody></table>"

    # Source list
    html += f"""<h2>Source CSV</h2>
<ul class="small">
  <li>jp_sessions.csv (md5:{md5_str(sess_csv)})</li>
  <li>jp_descriptives.csv (md5:{md5_str(os.path.join(outdir,'jp_descriptives.csv'))})</li>
  <li>jp_meta.csv (md5:{md5_str(os.path.join(outdir,'jp_meta.csv'))})</li>
  <li>jp_dropped.csv (md5:{md5_str(os.path.join(outdir,'jp_dropped.csv'))})</li>
  <li>jp_age_bins.csv (md5:{md5_str(os.path.join(outdir,'jp_age_bins.csv'))})</li>
  <li>jp_pragmatics.csv (md5:{md5_str(os.path.join(outdir,'jp_pragmatics.csv'))})</li>
</ul>
<hr/>
<div class="small">Built with filters and pragmatics. Config md5: {md5_str(config_path)}</div>
"""
    with open(dash_path, "w", encoding="utf-8") as f:
        f.write(html)

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("Usage: python -m jp_pipeline.compute_metrics CONFIG_YAML")
        sys.exit(1)
    run(sys.argv[1])
